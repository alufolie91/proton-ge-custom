diff --git a/.github/workflows/artifacts.yml b/.github/workflows/artifacts.yml
index f61cecf..6ec8252 100644
--- a/.github/workflows/artifacts.yml
+++ b/.github/workflows/artifacts.yml
@@ -1,6 +1,6 @@
 name: Artifacts (Package)
 
-on: [push, pull_request, workflow_dispatch]
+on: [pull_request, workflow_dispatch]
 
 jobs:
   artifacts-mingw-w64:
diff --git a/.github/workflows/test-build-windows.yml b/.github/workflows/test-build-windows.yml
index eb8a451..80feca3 100644
--- a/.github/workflows/test-build-windows.yml
+++ b/.github/workflows/test-build-windows.yml
@@ -1,6 +1,6 @@
 name: Test Builds on Windows
 
-on: [push, pull_request, workflow_dispatch]
+on: [pull_request, workflow_dispatch]
 
 jobs:
   build-set-windows:
diff --git a/README.md b/README.md
index 6d44092..c250a43 100644
--- a/README.md
+++ b/README.md
@@ -1,15 +1,58 @@
-# DXVK
+# DXVK GPLAsync-LowLatency (DXVK-GPLALL)
 
-A Vulkan-based translation layer for Direct3D 8/9/10/11 which allows running 3D applications on Linux using Wine.
+A Vulkan 1.3-based translation layer for Direct3D 8/9/10/11 which allows running 3D applications on: 
 
-For the current status of the project, please refer to the [project wiki](https://github.com/doitsujin/dxvk/wiki).
+1. Windows 10/11, if GPU has Vulkan driver that is Vulkan 1.3 compliant. Requires SSE2 CPU.
+2. Linux using Wine, if GPU has Vulkan driver that is Vulkan 1.3 compliant. Requires SSE2 CPU.
+3. MacOS using Wine/CrossOver, if GPU has Vulkan driver that is Vulkan 1.3 compliant. Requires SSE2 CPU.
 
-The most recent development builds can be found [here](https://github.com/doitsujin/dxvk/actions/workflows/artifacts.yml?query=branch%3Amaster).
+For GPUs that do not have Vulkan 1.3 compliant driver, it is recommended to use [DXVK-Sarek](https://github.com/pythonlover02/DXVK-Sarek). It supports Windows 7/8/10/11, Linux/Mac, requires SSE2 CPU, GPU with Vulkan driver that is Vulkan 1.1 compliant. It has implemented Direct3D 8/9/10/11 and a build with Asynchronous pipeline compilation (Async).
 
-Release builds can be found [here](https://github.com/doitsujin/dxvk/releases).
+## Major changes compared to [upstream DXVK](https://github.com/doitsujin/dxvk)
 
-## How to use
-In order to install a DXVK package obtained from the [release](https://github.com/doitsujin/dxvk/releases) page into a given wine prefix, copy or symlink the DLLs into the following directories as follows, then open `winecfg` and manually add `native` DLL overrides for `d3d8`, `d3d9`, `d3d10core`, `d3d11` and `dxgi` under the Libraries tab.
+1. Implemented Low Latency frame pacing mode that aims to greatly reduce latency with minimal impact in fps. Author - [netborg-afps](https://github.com/netborg-afps/dxvk/releases)
+2. Implemented Asynchronous pipeline compilation (Async) that aims to greatly reduce shader compilation stutter by not blocking the main thread when compiling async pipelines. Authors - [jomihaka](https://github.com/jomihaka/dxvk-poe-hack) and [Sporif](https://github.com/Sporif/dxvk-async)
+3. Implemented the ability to use both (together or separately) Graphics Pipeline Library (GPL) and Asynchronous pipeline compilation (Async) on DXVK 2.1 and later. Author - [Ph42oN](https://gitlab.com/Ph42oN/dxvk-gplasync/). Contributor - [Britt Yazel](https://gitlab.com/Ph42oN/dxvk-gplasync/-/merge_requests/12)
+4. Implemented State Cache for DXVK 2.7 starting from DXVK-GPLALL 2.7-3. Author - [Laitinlok](https://github.com/Digger1955/dxvk-gplasync-lowlatency/pull/29)
+5. Implemented all of aforementioned in one DXVK package. Author - [Digger1955](https://github.com/Digger1955/dxvk-gplasync-lowlatency/releases)
+6. Provided various GCC (for any OS) builds of DXVK-GPLALL:
+
+   a) optimized for `SSE2` (`-march=x86-64, -mtune=x86-64`) CPUs with Link-Time Optimization (`LTO`, a.k.a. `-flto=auto`) and `-O3` optimization level;
+
+   b) optimized for `SSE4.2` (`-march=x86-64-v2, -mtune=intel`) and newer Intel CPUs with Link-Time Optimization (`LTO`, a.k.a. `-flto=auto`) and `-O3` optimization level.
+
+   c) optimized for `SSE4.2` (`-march=x86-64-v2, -mtune=generic`) and newer CPUs with Link-Time Optimization (`LTO`, a.k.a. `-flto=auto`) and `-O3` optimization level.
+
+Author - [Digger1955](https://github.com/Digger1955/dxvk-gplasync-lowlatency/releases)
+
+7. Provided various MSVC (requires [MSVCRT](https://www.techpowerup.com/download/visual-c-redistributable-runtime-package-all-in-one/)) builds of DXVK-GPLALL:
+
+   a) optimized for `SSE2` (`/arch:SSE2`) CPUs with Link-Time Optimization (`LTO`, a.k.a. `/LTCG`) and `/O2` optimization level;
+
+   b) optimized for `SSE4.2` (`/arch:SSE4.2`) and newer Intel (`/favor:INTEL64` a.k.a. `/favor:EM64T`) CPUs with Link-Time Optimization (`LTO`, a.k.a. `/LTCG`) and `/O2` optimization level;
+
+   c) optimized for `AVX2` (`/arch:AVX2`) and newer AMD (`/favor:AMD64`) CPUs with Link-Time Optimization (`LTO`, a.k.a. `/LTCG`) and `/O2` optimization level.
+
+Author - [Digger1955](https://github.com/Digger1955/dxvk-gplasync-lowlatency/releases)
+
+8. Maintaining DXVK 2.6.x branch for GPUs/drivers that do not meet [DXVK 2.7 requirements](https://github.com/doitsujin/dxvk/releases/tag/v2.7). Author - [Digger1955](https://github.com/Digger1955/dxvk-gplasync-lowlatency/releases)
+
+Detailed Changelog provided in [Wiki](https://github.com/Digger1955/dxvk-gplasync-lowlatency/wiki/Detailed-Changelog).
+
+Builds Reference Guide provided in [Wiki](https://github.com/Digger1955/dxvk-gplasync-lowlatency/wiki/Builds-Reference-Guide).
+
+Contributing Guidelines provided in [Wiki](https://github.com/Digger1955/dxvk-gplasync-lowlatency/wiki/Contributing-Guidelines).
+
+## How to use (Windows 10/11)
+
+1. Download DXVK package from [release](https://github.com/Digger1955/dxvk-gplasync-lowlatency/releases) page.
+2. Copy appropriate [DLL dependencies](https://github.com/Digger1955/dxvk-gplasync-lowlatency/tree/GPLALL-master-2.7?tab=readme-ov-file#dll-dependencies) to the location of application's main executable folder.
+3. Run application.
+
+**Important**: It is **STRONGLY RECOMMENDED** to create `dxvk.conf` at application's main executable folder (per-application configuration file - first priority) or at `%APPDATA%/dxvk.conf` (one global configuration file - second priority) with your desired DXVK settings.
+
+## How to use (Linux/MacOS)
+In order to install a DXVK package obtained from the [release](https://github.com/Digger1955/dxvk-gplasync-lowlatency/releases) page into a given wine prefix, copy or symlink the DLLs into the following directories as follows, then open `winecfg` and manually add `native` DLL overrides for `d3d8`, `d3d9`, `d3d10core`, `d3d11` and `dxgi` under the Libraries tab.
 
 In a default Wine prefix that would be as follows:
 ```
@@ -32,7 +75,9 @@ In order to remove DXVK from a prefix, remove the DLLs and DLL overrides, and ru
 
 Tools such as Steam Play, Lutris, Bottles, Heroic Launcher, etc will automatically handle setup of dxvk on their own when enabled.
 
-#### DLL dependencies 
+**Important**: It is **STRONGLY RECOMMENDED** to create `dxvk.conf` at application's main executable folder (per-application configuration file - first priority) or at `/home/$USER/.config/dxvk.conf` (one global configuration file - second priority) with your desired DXVK settings.
+
+## DLL dependencies 
 Listed below are the DLL requirements for using DXVK with any single API.
 
 - d3d8: `d3d8.dll` and `d3d9.dll`
@@ -40,15 +85,33 @@ Listed below are the DLL requirements for using DXVK with any single API.
 - d3d10: `d3d10core.dll`, `d3d11.dll` and `dxgi.dll`
 - d3d11: `d3d11.dll` and `dxgi.dll`
 
-### Notes on Vulkan drivers
+## Notes on Vulkan drivers
 Before reporting an issue, please check the [Wiki](https://github.com/doitsujin/dxvk/wiki/Driver-support) page on the current driver status and make sure you run a recent enough driver version for your hardware.
 
-### Online multi-player games
-Manipulation of Direct3D libraries in multi-player games may be considered cheating and can get your account **banned**. This may also apply to single-player games with an embedded or dedicated multiplayer portion. **Use at your own risk.**
+## Online multiplayer games
+Manipulation of Direct3D libraries in multiplayer games may be considered cheating and can get your account **banned**. This may also apply to singleplayer games with an embedded or dedicated multiplayer portion. 
+
+Async could theoretically trigger client-side anti-cheats, and as such, may be risky to use inside of multiplayer games. There is no information about someone getting banned for using DXVK or DXVK with Async, but - **Use at your own risk.**
+
+## `dxvk.conf` Config File Location
+
+By default, DXVK has [built-in configs](https://github.com/doitsujin/dxvk/blob/master/src/util/config/config.cpp) for specific games and GPU drivers. If user needs to change default DXVK settings, then it can be done by changing default settings in `dxvk.conf` configuration file or by using `DXVK_CONFIG` environment variable.
+
+User can create `dxvk.conf` configuration file at application's main executable folder (per-application configuration file - first priority) or at `%APPDATA%/dxvk.conf` (one global configuration file - second priority) for Windows OS or at `/home/$USER/.config/dxvk.conf` (one global configuration file - second priority) for Linux/MacOS.
 
-### HUD
+User can change default `dxvk.conf` global coniguration file location by specifying path in `DXVK_CONFIG_FILE` environment variable:
+
+- Example (Windows): `DXVK_CONFIG_FILE=%USERPROFILE%/Documents/dxvk.conf`
+- Example (Linux): `DXVK_CONFIG_FILE=$XDG_DATA_HOME/dxvk.conf`
+- Example (MacOS): `DXVK_CONFIG_FILE=$HOME/Library/dxvk.conf`
+
+User can create `DXVK_CONFIG` to set config variables through the environment instead of a configuration file using the same syntax as in `dxvk.conf`. `;` is used as a seperator.
+
+- Example: `DXVK_CONFIG="dxgi.hideAmdGpu = True; dxgi.syncInterval = 0"`
+
+## HUD
 The `DXVK_HUD` environment variable controls a HUD which can display the framerate and some stat counters. It accepts a comma-separated list of the following options:
-- `devinfo`: Displays the name of the GPU and the driver version.
+- `devinfo`: Displays the name of the GPU, Vulkan Headers version and Vulkan Driver version.
 - `fps`: Shows the current frame rate.
 - `frametimes`: Shows a frame time graph.
 - `submissions`: Shows the number of command buffers submitted per frame.
@@ -67,25 +130,37 @@ The `DXVK_HUD` environment variable controls a HUD which can display the framera
 - `swvp`: Shows whether or not the device is running in software vertex processing mode *[D3D9 Only]*
 - `scale=x`: Scales the HUD by a factor of `x` (e.g. `1.5`)
 - `opacity=y`: Adjusts the HUD opacity by a factor of `y` (e.g. `0.5`, `1.0` being fully opaque).
+- `renderlatency`: Start of frame (usually when the game starts processing input) until the GPU did finish rendering this frame. Note that this will not work when a game's fps limiter is enabled, as there is no way to detect when a game will stall processing before reading input. Average over 100 frames.
+- `latencydetails`: provides insights about GPU buffer and v-sync buffer statistics. Helpful for fine-tuning the `dxvk.lowLatencyOffset` variable to competely eliminate GPU buffering and for fine-tuning the VRR refresh rate to minimize v-sync buffering in the VRR mode.
 
 Additionally, `DXVK_HUD=1` has the same effect as `DXVK_HUD=devinfo,fps`, and `DXVK_HUD=full` enables all available HUD elements.
 
-### Logs
+## Logs
 When used with Wine, DXVK will print log messages to `stderr`. Additionally, standalone log files can optionally be generated by setting the `DXVK_LOG_PATH` variable, where log files in the given directory will be called `app_d3d11.log`, `app_dxgi.log` etc., where `app` is the name of the game executable.
 
 On Windows, log files will be created in the game's working directory by default, which is usually next to the game executable.
 
-### Frame rate limit
-The `DXVK_FRAME_RATE` environment variable can be used to limit the frame rate. A value of `0` uncaps the frame rate, while any positive value will limit rendering to the given number of frames per second. Alternatively, the configuration file can be used.
+## Frame rate limit
+The `DXVK_FRAME_RATE` environment variable can be used to limit the frame rate. 
+
+A value of `0` limits the frame rate to the selected display refresh rate when vertical synchronization is enabled if the actual display mode does not match the game's one. 
+
+Any positive value will limit rendering to the given number of frames per second. 
+
+A value of `-1` always disables the limiter.
 
-### Device filter
+`DXVK_FRAME_RATE` environment variable represented in `dxvk.conf`:
+- For D3D8 and D3D9 - `d3d9.maxFrameRate`. Default value is `d3d9.maxFrameRate = 0`
+- For D3D10 and D3D11 - `dxgi.maxFrameRate` . Default value is `dxgi.maxFrameRate = 0`
+
+## Device filter
 Some applications do not provide a method to select a different GPU. In that case, DXVK can be forced to use a given device:
 - `DXVK_FILTER_DEVICE_NAME="Device Name"` Selects devices with a matching Vulkan device name, which can be retrieved with tools such as `vulkaninfo`. Matches on substrings, so "VEGA" or "AMD RADV VEGA10" is supported if the full device name is "AMD RADV VEGA10 (LLVM 9.0.0)", for example. If the substring matches more than one device, the first device matched will be used.
-- `DXVK_FILTER_DEVICE_UUID="00000000000000000000000000000001"` Selects a device by matching its Vulkan device UUID, which can also be retrieved using tools such as `vulkaninfo`. The UUID must be a 32-character hexadecimal string with no dashes. This method provides more precise selection, especially when using multiple identical GPUs.
+- `DXVK_FILTER_DEVICE_UUID="00000000000000000000000000000001"` Selects a device by matching its Vulkan device UUID, which can also be retrieved using tools such as vulkaninfo. The UUID must be a 32-character hexadecimal string with no dashes. This method provides more precise selection, especially when using multiple identical GPUs.
 
 **Note:** If the device filter is configured incorrectly, it may filter out all devices and applications will be unable to create a D3D device.
 
-### Debugging
+## Debugging
 The following environment variables can be used for **debugging** purposes.
 - `VK_INSTANCE_LAYERS=VK_LAYER_KHRONOS_validation` Enables Vulkan debug layers. Highly recommended for troubleshooting rendering issues and driver crashes. Requires the Vulkan SDK to be installed on the host system.
 - `DXVK_LOG_LEVEL=none|error|warn|info|debug` Controls message logging.
@@ -97,18 +172,79 @@ The following environment variables can be used for **debugging** purposes.
 - `DXVK_SHADER_CACHE_PATH=/some/directory`: Path to internal shader cache files. By default, this will use `%LOCALAPPDATA%/dxvk` in a Windows
   or Wine environment, and `$HOME/.cache` or `$XDG_CACHE_HOME` in a native Linux environment.
 
-### Graphics Pipeline Library
+## Graphics Pipeline Library (GPL)
 On drivers which support `VK_EXT_graphics_pipeline_library` Vulkan shaders will be compiled at the time the game loads its D3D shaders, rather than at draw time. This reduces or eliminates shader compile stutter in many games when compared to the previous system.
 
 In games that load their shaders during loading screens or in the menu, this can lead to prolonged periods of very high CPU utilization, especially on weaker CPUs. For affected games it is recommended to wait for shader compilation to finish before starting the game to avoid stutter and low performance. Shader compiler activity can be monitored with `DXVK_HUD=compiler`.
 
+**Important**: Usage of Graphics Pipeline Library significantly increases VRAM usage, due to this if you are low on VRAM, it can be better to disable it. That can be done with option `dxvk.enableGraphicsPipelineLibrary = False` in `dxvk.conf`.
+
 **Note:** Games which only load their D3D shaders at draw time (e.g. most Unreal Engine games) will still exhibit some stutter, although it should still be less severe than without this feature.
 
+**IMPORTANT**: Disabled by default since DXVK-GPLALL 2.6.1-4. Reasons have been specified in [Wiki](https://github.com/Digger1955/dxvk-gplasync-lowlatency/wiki/dxvk.conf-Options-Guide#dxvkenablegraphicspipelinelibrary)
+
+## State cache
+DXVK-GPLALL caches pipeline state by default, so that shaders can be recompiled ahead of time on subsequent runs of an application, even if the driver's own shader cache got invalidated in the meantime. This cache is enabled by default, and generally reduces stuttering.
+
+State cache can be used together with GPL that is not possible on upstream DXVK, but it can be useful depending on game.
+
+The following environment variables can be used to control the cache:
+- `DXVK_STATE_CACHE`: Controls the state cache. The following values are supported:
+  - `disable`: Disables the cache entirely.
+  - `reset`: Clears the cache file.
+- `DXVK_STATE_CACHE_PATH=/some/directory` Specifies a directory where to put the cache files. Defaults to the current working directory of the application.
+
+**Important**: The state cache has been removed from the [upstream DXVK since version 2.7](https://github.com/doitsujin/dxvk/releases/tag/v2.7). It is not available in DXVK-GPLALL 2.7-1 and 2.7-2, but available in DXVK-GPLALL 2.7-3 and later.
+
+## Asynchronous pipeline compilation (Async)
+
+Originally started as hacky solution for shader compilation stutter in dxvk. Similar solution was later added to dxvk itself and promptly removed.
+
+Enabling this solution results in a lot less shader compilation stuttering by not blocking the main thread when compiling async pipelines and (not necessarily) miscellaneous graphical issues while shaders are compiling for the first time.
+
+Asynchronous pipeline compilation is enabled with `DXVK_ASYNC=1` environment variable and is equivalent to `dxvk.enableAsync = True` in `dxvk.conf`. It is enabled by default.
+
+Asynchronous pipeline compilation is disabled with `DXVK_ASYNC=0` environment variable and is equivalent to `dxvk.enableAsync = False` in `dxvk.conf`.
+
+## GPLAsync and State cache
+
+State cache fixes for GPL and Async are enabled with `DXVK_GPLASYNCCACHE=1` environment variable and is equivalent to `dxvk.gplAsyncCache = True` in `dxvk.conf`. It is enabled by default.
+
+State cache fixes for GPL and Async are disabled with `DXVK_GPLASYNCCACHE=0` environment variable and is equivalent to `dxvk.gplAsyncCache = False` in `dxvk.conf`.
+
+**Important**: The state cache has been removed from the [upstream DXVK since version 2.7](https://github.com/doitsujin/dxvk/releases/tag/v2.7). It is not available in DXVK-GPLALL 2.7-1 and 2.7-2, but available in DXVK-GPLALL 2.7-3 and later.
+
+## Low Latency frame pacing
+
+Enhances the original [dxvk](https://github.com/doitsujin/dxvk) with low-latency frame pacing capabilities to improve game responsiveness and input lag. It also improves latency stability over time, usually resulting in a more accurate playback speed of the generated video.
+
+Low-Latency frame pacing mode aims to reduce latency with minimal impact in fps. Effective when operating in the GPU-limit. Efficient to be used in the CPU-limit as well.
+
+Greatly reduces input lag variations when switching between CPU- and GPU-limit, and compared to the max-frame-latency approach, it has a much more stable input lag when GPU running times change dramatically, which can happen for example when rotating within a scene.
+
+Latency has been decreased dramatically in some games by speeding up the dxvk-internal flush heuristic delivering GPU submissions quicker, which was presumably tuned for bandwidth/fps.
+
+An interesting observation while playtesting was that not only the input lag was affected, but the video generated did progress more cleanly in time as well with regards to the wow and flutter effect.
+
+Optimized for Variable Refresh Rate (VRR) displays, `VK_PRESENT_MODE_IMMEDIATE_KHR` (V-Sync Off) and `VK_PRESENT_MODE_FIFO_KHR` (V-Sync On). It also comes with its own fps-limiter which is typically used to prevent the game's fps exceeding the monitor's refresh rate.
+
+### Usage
+
+`DXVK_FRAME_PACE` environment variable has the next options: `max-frame-latency`, `min-latency`, `low-latency` and `low-latency-vrr-x`. Default is `DXVK_FRAME_PACE=low-latency`.
+`low-latency-vrr-x` is a special option, which requires to specify display refresh rate, instead of `x`. For example, if user has 360 Hz VRR display, then option must be `low-latency-vrr-360`. **Important:** Care has to be taken that the system is configured such that the display is indeed using a variable refresh rate, otherwise this mode won't work properly.
+
+`DXVK_FRAME_PACE` environment variable represented in the `dxvk.conf` as `dxvk.framePace`. Default is `dxvk.framePace = "low-latency"`
+
+`dxvk.lowLatencyOffset` option in `dxvk.conf` allows for fine-tuning the `low-latency mode`. Values are in microseconds. Positive values might improve responsiveness even further, although only very slightly, this may be relevant for edge cases. Negative values might improve fps. Default is `dxvk.lowLatencyOffset = 0`
+
+`dxvk.lowLatencyAllowCpuFramesOverlap` option in `dxvk.conf` controls whether a frame is allowed to begin before finishing processing the cpu-part of the previous one, when low-latency frame pacing is used. Snappiness may be improved when disallowing overlap. On the other hand, this might also decrease fps in certain cases. Default is `dxvk.lowLatencyAllowCpuFramesOverlap = True`
+
+
 ## Build instructions
 
 In order to pull in all submodules that are needed for building, clone the repository using the following command:
 ```
-git clone --recursive https://github.com/doitsujin/dxvk.git
+git clone --recursive https://github.com/Digger1955/dxvk-gplasync-lowlatency
 ```
 
 ### Requirements:
@@ -164,13 +300,13 @@ does have `--enable-threads=posix` enabled during configure. If your distro does
 ship its mingw-w64-gcc binary with `--enable-threads=win32` you might have to
 recompile locally or open a bug at your distro's bugtracker to ask for it. 
 
-# DXVK Native
+## DXVK Native
 
 DXVK Native is a version of DXVK which allows it to be used natively without Wine.
 
 This is primarily useful for game and application ports to either avoid having to write another rendering backend, or to help with port bringup during development.
 
-[Release builds](https://github.com/doitsujin/dxvk/releases) are built using the Steam Runtime.
+[Release builds](https://github.com/Digger1955/dxvk-gplasync-lowlatency/releases) are built using the Steam Runtime.
 
 ### How does it work?
 
diff --git a/RELEASE b/RELEASE
index 860487c..10b8ff6 100644
--- a/RELEASE
+++ b/RELEASE
@@ -1 +1 @@
-2.7.1
+2.7.1-1
diff --git a/VP_DXVK_requirements.json b/VP_DXVK_requirements.json
index 833bdcd..e7aaf4c 100644
--- a/VP_DXVK_requirements.json
+++ b/VP_DXVK_requirements.json
@@ -108,7 +108,8 @@
         },
         "dxvk_common_optional": {
             "extensions": {
-                "VK_KHR_load_store_op_none": 1,
+                "VK_EXT_load_store_op_none": 1,
+                "VK_KHR_maintenance6": 1,
                 "VK_KHR_maintenance7": 1,
                 "VK_KHR_present_id": 1,
                 "VK_KHR_present_wait": 1,
diff --git a/dxvk.conf b/dxvk.conf
index 3b29a04..d95a137 100644
--- a/dxvk.conf
+++ b/dxvk.conf
@@ -1,3 +1,22 @@
+# dxvk.conf Config File Location
+
+# By default, DXVK has built-in configs 
+# https://github.com/doitsujin/dxvk/blob/master/src/util/config/config.cpp
+# for specific games and GPU drivers. If user needs to change default DXVK settings, 
+# then it can be done by changing default settings in dxvk.conf configuration file 
+# or by using DXVK_CONFIG environment variable.
+
+# User can create dxvk.conf configuration file at 
+# application's main executable folder (per-application configuration file - first priority) 
+# or at %APPDATA%/dxvk.conf (one global configuration file - second priority) for Windows OS 
+# or at /home/$USER/.config/dxvk.conf (one global configuration file - second priority) for Linux/MacOS.
+# User can change default dxvk.conf global coniguration file location 
+# by specifying path in DXVK_CONFIG_FILE environment variable:
+
+# Example (Windows): DXVK_CONFIG_FILE=%USERPROFILE%/Documents/dxvk.conf
+# Example (Linux): DXVK_CONFIG_FILE=$XDG_DATA_HOME/dxvk.conf
+# Example (MacOS): DXVK_CONFIG_FILE=$HOME/Library/dxvk.conf
+
 # Device filter. Only exposes devices whose Vulkan device name contains
 # the given string. May be useful to force an application to run on a
 # specific GPU, but not applications launched by that application.
@@ -17,6 +36,121 @@
 
 # dxgi.enableHDR = True
 
+# Originally started as hacky solution for shader compilation stutter in dxvk.
+# Similar solution was later added to dxvk itself and promptly removed.
+# This option allows to enable or disable that solution. 
+# Enabling this solution results in a lot less shader compilation stuttering
+# by not blocking the main thread when compiling async pipelines and 
+# (not necessarily) 
+# miscellaneous graphical issues while shaders are compiling for the first time.
+#
+# Default: True
+# Supported values: True, False
+#
+# DXVK_ASYNC environment variable provides control for this option too. 
+# DXVK_ASYNC=1 is equivalent to dxvk.enableAsync = True
+# DXVK_ASYNC=0 is equivalent to dxvk.enableAsync = False
+
+# dxvk.enableAsync = True
+
+
+# This option enables or disables fixes for DXVK state cache that allow 
+# to use both Async and GPL together or separately.
+# For Async it is always useful.
+# For GPL it can be useful depending on game. 
+# 
+# Default: True
+# Supported values: True, False
+# 
+# DXVK_GPLASYNCCACHE environment variable provides control for this option too.
+# DXVK_GPLASYNCCACHE=1 is equivalent to dxvk.gplAsyncCache = True
+# DXVK_GPLASYNCCACHE=0 is equivalent to dxvk.gplAsyncCache = False
+
+# dxvk.gplAsyncCache = True
+
+
+# Frame pacing mode managing CPU-GPU synchronization.
+#
+# "max-frame-latency" provides stable latency in the GPU-limit as long as GPU render times are stable. 
+# Latency generally is higher but offers great visual smoothness. 
+# "max-frame-latency" is the behaviour of upstream dxvk. 
+# Frame i won't start as long as frame (i-1)-x isn't finished, 
+# where x is the value of dxgi.maxFrameLatency / d3d9.#maxFrameLatency. 
+# This pacing usually looks smooth, but has latency issues when GPU bound. Optimized for highest fps.
+#
+# "min-latency" possibly provides the lowest latency (low-latency can be quicker in some situations), 
+# and offers less fps in the GPU-limit due to stalling the GPU between frames. 
+# Generally not recommended, but helpful to get insights to fine-tune the low-latency mode 
+# and possibly is useful for running games in the CPU-limit. 
+# "min-latency" is essential like max-frame-latency-0 (not selectable for the mode above), 
+# which means the start of a frame will wait until the previous one is finished. 
+# CPU/GPU no longer overlap during the transition from one frame to another 
+# and thus a lot of fps are sacrificed for prioritizing low latency. 
+# This mode is generally not recommended, but might be useful to get insights.
+#
+# "low-latency"  provides lower latency in the GPU-limit
+# and can be fine-tuned via dxvk.lowLatencyOffset and dxvk.lowLatencyAllowCpuFramesOverlap.
+#`"low-latency" is the default mode: 
+# It combines high fps throughput with excellent game responsiveness and low input lag. 
+# Looking at a scale of a few seconds, pacing is usually more accurate in time than max-frame-latency
+# since latency variations are minimized, especially when moving in and out of the GPU limit 
+# and when GPU frametimes vary a lot while being GPU bound. 
+# Looking at the pacing frame by frame, this mode relies on the game providing stable frame times for smoothness. 
+# When the game generates occasional stutters, 
+# these are filtered out nicely such that they don't interfere with the presentation of the other frames.
+#
+# "low-latency-vrr-x" is a special option, which requires to specify display refresh rate, instead of "x". 
+# For example, if user has 360 Hz VRR display, then option must be "low-latency-vrr-360". 
+# Important: Care has to be taken that the system is configured such 
+# that the display is indeed using a variable refresh rate, otherwise this mode won't work properly.
+# "low-latency-vrr-x" enhances the "low-latency"  mode by taking v-blank information into account, 
+# which prevents additional v-sync buffering latency. 
+# This mode automatically enables v-sync to get informed when v-blanks are happening. 
+# It will make the pacer predict future v-blanks based on the given refresh rate of "x" Hz. 
+# Replace "x" with the refresh rate of your monitor. 
+# This mode works with x11-flip and native Wayland (can be enabled in Wine via DISPLAY= and via PROTON_ENABLE_WAYLAND=1 in Proton), 
+# but cannot work on Xwayland because v-blank information is not available there (tested on Nvidia).
+#
+# Supported values: "max-frame-latency", "min-latency", "low-latency" and "low-latency-vrr-x", where "x" is VRR display refresh rate.
+
+# dxvk.framePace = "low-latency"
+
+
+# Allows fine-tuning the "low-latency" frame pacing mode. 
+#
+# Positive value will make frames start later by the given amount (in microseconds), 
+# which make it less likely to run into buffering and thus may improve latency. 
+# Positive value might improve responsiveness, although only very slightly, but may be relevant for edge cases. 
+# Negative values will make frames start earlier by the given amount (in microseconds), 
+# and thus those frames will more likely run into buffering, which in turns may increase fps.
+# In other words, this option has an effect on the percentage of frames which go into GPU buffering and/or v-sync buffering. 
+# A value of zero will make 50% of frames go (mostly slightly) into buffering, since for most games, 
+# the prediction is so accurate that it will average out to 0 microseconds.
+# For 360 fps gameplay, you may want to experiment with values in the range of -100 to 100. 
+# For less fps, you may want to use larger values respectively.
+# The offset is applied after predictions have been made to align the frame, but doesn't affect fps limiting.
+# It's recommended to check the GPU buffer display (`dxvk.hud = "latencydetails"`) to fine-tune this setting.
+#
+# Supported values: -10000 to 10000
+
+# dxvk.lowLatencyOffset = 0
+
+# Determines whether a frame is allowed to begin 
+# before finishing processing the cpu-part of the previous one, 
+# when low-latency frame pacing is used. 
+# Snappiness may be improved when disallowing overlap. 
+# On the other hand, this might also decrease fps in certain cases.
+# In case a game is generating a very high load (or specific load) on dxvk's CS thread (see DXVK_HUD=cs), 
+# setting dxvk.lowLatencyAllowCpuFramesOverlap = False 
+# will prevent the CS thread queue from creating additional latency. 
+# By default, this option is set to True, because setting it to False 
+# can lead to certain type of stutters being magnified, for example from shader compiling, 
+# which can lead to strong fps loss in those cases.
+#
+# Supported values: True, False
+
+# dxvk.lowLatencyAllowCpuFramesOverlap = True
+
 
 # Expose support for dcomp swap chains with a dummy window.
 #
@@ -104,8 +238,13 @@
 #         The implementation will either use VK_NV_low_latency2 if supported
 #         by the driver, or a custom algorithm.
 # - False: Disable Reflex support as well as built-in latency reduction.
+#         This build defaults to False to enable dxvk.framePace. You need to
+#         enable Reflex manually (Auto) until we support switching back and
+#         forth between Reflex and the low-latency frame pacing - for example
+#         via the ingame options - and more critically we want to enable
+#         low-latency frame pacing if the game doesn't support Reflex.
   
-# dxvk.latencySleep = Auto
+# dxvk.latencySleep = False
 
 
 # Tolerance for the latency sleep heuristic, in microseconds. Higher values
@@ -278,7 +417,7 @@
 # Overrides anisotropic filtering for all samplers. Set this to a positive
 # value to enable AF for all samplers in the game, or to 0 in order to
 # disable AF entirely. Negative values will have no effect.
-#
+# 
 # Forcing anisotropy is known to break passes that rely on
 # bilinear filtering, or in other situations when an application
 # relies on fine grained control over samplers. Please do not report
@@ -432,7 +571,7 @@
 # these threads will be reserved for high-priority work.
 #
 # Supported values:
-# - 0 to use all available CPU cores
+# - 0 to use (CPULogicalThreads - 2) compiler threads
 # - any positive number to enforce the thread count
 
 # dxvk.numCompilerThreads = 0
@@ -456,15 +595,16 @@
 # Controls graphics pipeline library behaviour
 #
 # Can be used to change VK_EXT_graphics_pipeline_library usage for
-# debugging purpose. Doing so will likely result in increased stutter
-# or degraded performance.
+# debugging purpose. This feature is replaced by Async, 
+# which does not require any specific driver/extension support
+# and provides better performance than using DXVK with GPL.
 #
 # Supported values:
 # - Auto: Enable if supported, and compile optimized pipelines in the background
 # - True: Enable if supported, but do not compile optimized pipelines
 # - False: Always disable the feature
 
-# dxvk.enableGraphicsPipelineLibrary = Auto
+# dxvk.enableGraphicsPipelineLibrary = False
 
 
 # Controls descriptor model
diff --git a/meson.build b/meson.build
index 64b6803..514c957 100644
--- a/meson.build
+++ b/meson.build
@@ -10,10 +10,16 @@ cc = meson.get_compiler('c')
 dxvk_is_msvc = cpp.get_argument_syntax() == 'msvc'
 
 compiler_args = [
+  '-O3',
+  '-pipe',
+  '-march=x86-64',
+  '-mtune=x86-64',
   '-msse',
   '-msse2',
-  '-msse3',
   '-mfpmath=sse',
+  '-fno-semantic-interposition',
+  '-flto=auto',
+  '-fuse-linker-plugin',
   '-Wimplicit-fallthrough',
   # gcc
   '-Wno-missing-field-initializers',
@@ -28,7 +34,9 @@ compiler_args = [
   '-Wno-missing-braces',
 ]
 
-link_args = []
+link_args = [
+  '-s',
+]
 
 if get_option('build_id')
   link_args += [
@@ -92,14 +100,24 @@ if platform == 'windows'
       ]
     endif
   else
-    # setup file alignment + enable PDB output for MSVC builds
-    # PDBs are useful for Windows consumers of DXVK 
+    # Windows (MSVC) Compiler Options
     compiler_args += [
-      '/Z7'
+      '/arch:SSE2',
+      '/O2',
+      '/Ob3',
+      '/GL',
+      '/Gw',
+      '/Qpar',
+      '/Qpar-report:2',
+      '/Qvec-report:2'
     ]
+    # MSVC Linker Options
     link_args += [
       '/FILEALIGN:4096',
-      '/DEBUG:FULL'
+      '/INCREMENTAL:NO',
+      '/OPT:REF,ICF',
+      '/LTCG',
+      '/DEBUG:NONE'
     ]
   endif
 
@@ -202,7 +220,7 @@ glsl_generator = generator(
 )
 
 dxvk_version = vcs_tag(
-  command: ['git', 'describe', '--dirty=+'],
+  command: ['git', 'describe', '--dirty=-gplall'],
   input:  'version.h.in',
   output: 'version.h',
 )
diff --git a/src/d3d11/d3d11_context.h b/src/d3d11/d3d11_context.h
index 1457745..d0f6c34 100644
--- a/src/d3d11/d3d11_context.h
+++ b/src/d3d11/d3d11_context.h
@@ -1179,7 +1179,7 @@ namespace dxvk {
     static DxvkBlendMode InitDefaultBlendState();
 
     template<bool AllowFlush = true, typename Cmd>
-    void EmitCs(Cmd&& command) {
+    void EmitCs(Cmd&& command, bool disableFlush=false ) {
       if (unlikely(m_csDataType != D3D11CmdType::None)) {
         m_csData = nullptr;
         m_csDataType = D3D11CmdType::None;
@@ -1190,7 +1190,8 @@ namespace dxvk {
         m_csChunk = AllocCsChunk();
 
         if constexpr (!IsDeferred && AllowFlush)
-          GetTypedContext()->ConsiderFlush(GpuFlushType::ImplicitWeakHint);
+          if (!disableFlush)
+            GetTypedContext()->ConsiderFlush(GpuFlushType::ImplicitWeakHint);
 
         m_csChunk->push(command);
       }
diff --git a/src/d3d11/d3d11_swapchain.cpp b/src/d3d11/d3d11_swapchain.cpp
index 0b963ae..67cad75 100644
--- a/src/d3d11/d3d11_swapchain.cpp
+++ b/src/d3d11/d3d11_swapchain.cpp
@@ -3,6 +3,7 @@
 #include "d3d11_swapchain.h"
 
 #include "../dxvk/dxvk_latency_builtin.h"
+#include "../dxvk/framepacer/dxvk_framepacer.h"
 
 #include "../util/util_win32_compat.h"
 
@@ -294,6 +295,12 @@ namespace dxvk {
     if (m_latencyHud)
       m_latencyHud->accumulateStats(latencyStats);
 
+    if (m_renderLatencyHud)
+      m_renderLatencyHud->updateLatencyTracker(m_latency);
+
+    if (m_latencyDetailsHud)
+      m_latencyDetailsHud->updateLatencyTracker(m_latency);
+
     return hr;
   }
 
@@ -354,6 +361,10 @@ namespace dxvk {
 
     if (m_presenter != nullptr)
       m_presenter->setFrameRateLimit(m_targetFrameRate, GetActualFrameLatency());
+
+    FramePacer* framePacer = dynamic_cast<FramePacer*>(m_latency.ptr());
+    if (framePacer != nullptr)
+      framePacer->setTargetFrameRate(FrameRate);
   }
 
 
@@ -464,7 +475,7 @@ namespace dxvk {
           cFrameId = m_frameId
         ] (DxvkContext* ctx) {
           ctx->beginLatencyTracking(cLatency, cFrameId + 1u);
-        });
+        }, true);
       }
     }
 
@@ -517,6 +528,7 @@ namespace dxvk {
     m_presenter->setFrameRateLimit(m_targetFrameRate, GetActualFrameLatency());
 
     m_latency = m_device->createLatencyTracker(m_presenter);
+    m_presenter->registerLatencyTracker(m_latency);
 
     Com<D3D11ReflexDevice> reflex = GetReflexDevice();
     reflex->RegisterLatencyTracker(m_latency);
@@ -596,8 +608,15 @@ namespace dxvk {
     if (hud) {
       hud->addItem<hud::HudClientApiItem>("api", 1, GetApiName());
 
-      if (m_latency)
+      if (m_latency) {
         m_latencyHud = hud->addItem<hud::HudLatencyItem>("latency", 4);
+        FramePacer* framePacer = dynamic_cast<FramePacer*>(m_latency.ptr());
+        if (framePacer) {
+          int32_t fpsItemPos = hud->getItemPos<hud::HudFpsItem>();
+          m_renderLatencyHud = hud->addItem<hud::HudRenderLatencyItem>("renderlatency", fpsItemPos+1);
+          m_latencyDetailsHud = hud->addItem<hud::HudLatencyDetailsItem>("latencydetails", fpsItemPos+2);
+        }
+      }
     }
 
     m_blitter = new DxvkSwapchainBlitter(m_device, std::move(hud));
diff --git a/src/d3d11/d3d11_swapchain.h b/src/d3d11/d3d11_swapchain.h
index 99f0945..ae46b58 100644
--- a/src/d3d11/d3d11_swapchain.h
+++ b/src/d3d11/d3d11_swapchain.h
@@ -125,7 +125,9 @@ namespace dxvk {
     dxvk::mutex               m_frameStatisticsLock;
     DXGI_VK_FRAME_STATISTICS  m_frameStatistics = { };
 
-    Rc<hud::HudLatencyItem>   m_latencyHud;
+    Rc<hud::HudLatencyItem>         m_latencyHud;
+    Rc<hud::HudRenderLatencyItem>   m_renderLatencyHud;
+    Rc<hud::HudLatencyDetailsItem>  m_latencyDetailsHud;
 
     Rc<DxvkImageView> GetBackBufferView();
 
diff --git a/src/d3d9/d3d9_device.cpp b/src/d3d9/d3d9_device.cpp
index c44533a..8061a15 100644
--- a/src/d3d9/d3d9_device.cpp
+++ b/src/d3d9/d3d9_device.cpp
@@ -6306,7 +6306,7 @@ namespace dxvk {
     ] (DxvkContext* ctx) {
       if (cTracker && cTracker->needsAutoMarkers())
         ctx->beginLatencyTracking(cTracker, cFrameId);
-    });
+    }, true);
   }
 
 
diff --git a/src/d3d9/d3d9_device.h b/src/d3d9/d3d9_device.h
index bf97206..4dfb1dd 100644
--- a/src/d3d9/d3d9_device.h
+++ b/src/d3d9/d3d9_device.h
@@ -1277,13 +1277,14 @@ namespace dxvk {
   private:
 
     template<bool AllowFlush = true, typename Cmd>
-    void EmitCs(Cmd&& command) {
+    void EmitCs(Cmd&& command, bool disableFlush=false) {
       if (unlikely(!m_csChunk->push(command))) {
         EmitCsChunk(std::move(m_csChunk));
         m_csChunk = AllocCsChunk();
 
         if constexpr (AllowFlush)
-          ConsiderFlush(GpuFlushType::ImplicitWeakHint);
+          if (!disableFlush)
+            ConsiderFlush(GpuFlushType::ImplicitWeakHint);
 
         m_csChunk->push(command);
       }
diff --git a/src/d3d9/d3d9_swapchain.cpp b/src/d3d9/d3d9_swapchain.cpp
index 1daaaa6..dfd29f0 100644
--- a/src/d3d9/d3d9_swapchain.cpp
+++ b/src/d3d9/d3d9_swapchain.cpp
@@ -5,6 +5,8 @@
 #include "d3d9_hud.h"
 #include "d3d9_window.h"
 
+#include "../dxvk/framepacer/dxvk_framepacer.h"
+
 namespace dxvk {
 
   static uint16_t MapGammaControlPoint(float x) {
@@ -935,6 +937,12 @@ namespace dxvk {
     if (m_latencyHud)
       m_latencyHud->accumulateStats(latencyStats);
 
+    if (m_renderLatencyHud)
+      m_renderLatencyHud->updateLatencyTracker(m_latencyTracker);
+
+    if (m_latencyDetailsHud)
+      m_latencyDetailsHud->updateLatencyTracker(m_latencyTracker);
+
     // Rotate swap chain buffers so that the back
     // buffer at index 0 becomes the front buffer.
     uint32_t rotatingBufferCount = m_backBuffers.size();
@@ -1004,7 +1012,7 @@ namespace dxvk {
       entry->second.presenter = CreatePresenter(m_window, entry->second.frameLatencySignal);
 
       if (m_presentParams.hDeviceWindow == m_window && m_latencyTracking)
-        m_latencyTracker = m_device->createLatencyTracker(entry->second.presenter);
+        m_latencyTracker = m_device->createLatencyTracker(entry->second.presenter, entry->second.frameId+1);
     }
 
     m_wctx = &entry->second;
@@ -1081,8 +1089,15 @@ namespace dxvk {
     if (hud) {
       m_apiHud = hud->addItem<hud::HudClientApiItem>("api", 1, GetApiName());
 
-      if (m_latencyTracking)
+      if (m_latencyTracking) {
         m_latencyHud = hud->addItem<hud::HudLatencyItem>("latency", 4);
+        FramePacer* framePacer = dynamic_cast<FramePacer*>(m_latencyTracker.ptr());
+        if (framePacer) {
+          int32_t fpsItemPos = hud->getItemPos<hud::HudFpsItem>();
+          m_renderLatencyHud = hud->addItem<hud::HudRenderLatencyItem>("renderlatency", fpsItemPos+1);
+          m_latencyDetailsHud = hud->addItem<hud::HudLatencyDetailsItem>("latencydetails", fpsItemPos+2);
+        }
+      }
 
       hud->addItem<hud::HudFixedFunctionShaders>("ffshaders", -1, m_parent);
       hud->addItem<hud::HudSWVPState>("swvp", -1, m_parent);
@@ -1132,6 +1147,9 @@ namespace dxvk {
     }
 
     m_wctx->presenter->setFrameRateLimit(frameRate, GetActualFrameLatency());
+    FramePacer* framePacer = dynamic_cast<FramePacer*>(m_latencyTracker.ptr());
+    if (framePacer != nullptr)
+      framePacer->setTargetFrameRate(frameRate);
     m_targetFrameRate = frameRate;
   }
 
diff --git a/src/d3d9/d3d9_swapchain.h b/src/d3d9/d3d9_swapchain.h
index c2248da..8cc54eb 100644
--- a/src/d3d9/d3d9_swapchain.h
+++ b/src/d3d9/d3d9_swapchain.h
@@ -183,8 +183,10 @@ namespace dxvk {
     bool                      m_latencyTracking = false;
     Rc<DxvkLatencyTracker>    m_latencyTracker = nullptr;
 
-    Rc<hud::HudClientApiItem> m_apiHud;
-    Rc<hud::HudLatencyItem>   m_latencyHud;
+    Rc<hud::HudClientApiItem>       m_apiHud;
+    Rc<hud::HudLatencyItem>         m_latencyHud;
+    Rc<hud::HudRenderLatencyItem>   m_renderLatencyHud;
+    Rc<hud::HudLatencyDetailsItem>  m_latencyDetailsHud;
 
     std::optional<VkHdrMetadataEXT> m_hdrMetadata;
     bool m_unlockAdditionalFormats = false;
diff --git a/src/dxvk/dxvk_compute.cpp b/src/dxvk/dxvk_compute.cpp
index 48b794f..fccea37 100644
--- a/src/dxvk/dxvk_compute.cpp
+++ b/src/dxvk/dxvk_compute.cpp
@@ -8,6 +8,7 @@
 #include "dxvk_device.h"
 #include "dxvk_graphics.h"
 #include "dxvk_pipemanager.h"
+#include "dxvk_state_cache.h"
 
 namespace dxvk {
   
@@ -17,6 +18,7 @@ namespace dxvk {
           DxvkComputePipelineShaders  shaders,
           DxvkShaderPipelineLibrary*  library)
   : m_device        (device),
+    m_stateCache    (&pipeMgr->m_stateCache),
     m_stats         (&pipeMgr->m_stats),
     m_library       (library),
     m_shaders       (std::move(shaders)),
diff --git a/src/dxvk/dxvk_compute.h b/src/dxvk/dxvk_compute.h
index 38fb044..d580867 100644
--- a/src/dxvk/dxvk_compute.h
+++ b/src/dxvk/dxvk_compute.h
@@ -12,8 +12,9 @@
 #include "dxvk_stats.h"
 
 namespace dxvk {
-  
+
   class DxvkDevice;
+  class DxvkStateCache;
   class DxvkPipelineManager;
   struct DxvkPipelineStats;
 
@@ -47,20 +48,20 @@ namespace dxvk {
     DxvkComputePipelineStateInfo state;
     VkPipeline                   handle = VK_NULL_HANDLE;
   };
-  
-  
+
+
   /**
    * \brief Compute pipeline
-   * 
+   *
    * Stores a compute pipeline object and the corresponding
    * pipeline layout. Unlike graphics pipelines, compute
    * pipelines do not need to be recompiled against any sort
    * of pipeline state.
    */
   class DxvkComputePipeline {
-    
+
   public:
-    
+
     DxvkComputePipeline(
             DxvkDevice*                 device,
             DxvkPipelineManager*        pipeMgr,
@@ -68,7 +69,7 @@ namespace dxvk {
             DxvkShaderPipelineLibrary*  library);
 
     ~DxvkComputePipeline();
-    
+
     /**
      * \brief Shaders used by the pipeline
      * \returns Shaders used by the pipeline
@@ -76,7 +77,7 @@ namespace dxvk {
     const DxvkComputePipelineShaders& shaders() const {
       return m_shaders;
     }
-    
+
     /**
      * \brief Queries pipeline layout
      * \returns Pipeline layout
@@ -95,19 +96,19 @@ namespace dxvk {
       constexpr uint32_t globalMask = (1u << MaxNumSpecConstants) - 1;
       return m_shaders.cs->metadata().specConstantMask & globalMask;
     }
-    
+
     /**
      * \brief Retrieves pipeline handle
-     * 
+     *
      * \param [in] state Pipeline state
      * \returns Pipeline handle
      */
     VkPipeline getPipelineHandle(
       const DxvkComputePipelineStateInfo& state);
-    
+
     /**
      * \brief Compiles a pipeline
-     * 
+     *
      * Asynchronously compiles the given pipeline
      * and stores the result for future use.
      * \param [in] state Pipeline state
@@ -126,8 +127,9 @@ namespace dxvk {
     }
 
   private:
-    
+
     DxvkDevice*                 m_device = nullptr;
+    DxvkStateCache*             m_stateCache = nullptr;
     DxvkPipelineStats*          m_stats = nullptr;
 
     DxvkShaderPipelineLibrary*  m_library = nullptr;
@@ -135,22 +137,22 @@ namespace dxvk {
 
     DxvkComputePipelineShaders  m_shaders;
     DxvkPipelineBindings        m_layout;
-    
+
     std::string                 m_debugName;
 
     alignas(CACHE_LINE_SIZE)
     dxvk::mutex                             m_mutex;
     sync::List<DxvkComputePipelineInstance> m_pipelines;
-    
+
     DxvkComputePipelineInstance* createInstance(
       const DxvkComputePipelineStateInfo& state);
-    
+
     DxvkComputePipelineInstance* findInstance(
       const DxvkComputePipelineStateInfo& state);
-    
+
     VkPipeline createPipeline(
       const DxvkComputePipelineStateInfo& state) const;
-    
+
     void destroyPipeline(
             VkPipeline                    pipeline);
 
@@ -161,5 +163,5 @@ namespace dxvk {
     std::string createDebugName() const;
 
   };
-  
+
 }
diff --git a/src/dxvk/dxvk_context.cpp b/src/dxvk/dxvk_context.cpp
index ead2408..3880967 100644
--- a/src/dxvk/dxvk_context.cpp
+++ b/src/dxvk/dxvk_context.cpp
@@ -109,7 +109,7 @@ namespace dxvk {
   void DxvkContext::beginLatencyTracking(
     const Rc<DxvkLatencyTracker>&     tracker,
           uint64_t                    frameId) {
-    if (tracker && (!m_latencyTracker || m_latencyTracker == tracker)) {
+    if (tracker && m_latencyTracker != tracker) {
       tracker->notifyCsRenderBegin(frameId);
 
       m_latencyTracker = tracker;
@@ -2653,7 +2653,7 @@ namespace dxvk {
     if (access == DxvkAccess::None) {
       // If the attachment is not accessed at all, we can set both the
       // load and store op to NONE if supported by the implementation.
-      bool hasLoadOpNone = m_device->features().khrLoadStoreOpNone;
+      bool hasLoadOpNone = m_device->features().extLoadStoreOpNone;
 
       attachment.loadOp = hasLoadOpNone
         ? VK_ATTACHMENT_LOAD_OP_NONE
@@ -6085,7 +6085,8 @@ namespace dxvk {
                          DxvkContextFlag::GpDirtyDepthBias));
 
     // Retrieve and bind actual Vulkan pipeline handle
-    auto pipelineInfo = m_state.gp.pipeline->getPipelineHandle(m_state.gp.state);
+    auto pipelineInfo = m_state.gp.pipeline->getPipelineHandle(m_state.gp.state,
+      this->checkAsyncCompilationCompat());
 
     if (unlikely(!pipelineInfo.handle))
       return false;
@@ -6724,7 +6725,7 @@ namespace dxvk {
   }
 
 
-  void DxvkContext::updateRenderTargets() {
+  void DxvkContext::updateRenderTargets(bool isDraw) {
     if (m_flags.test(DxvkContextFlag::GpDirtyRenderTargets)) {
       m_flags.clr(DxvkContextFlag::GpDirtyRenderTargets);
 
@@ -6765,6 +6766,11 @@ namespace dxvk {
 
       m_state.om.framebufferInfo = std::move(fbInfo);
 
+      if (isDraw) {
+        for (uint32_t i = 0; i < fbInfo.numAttachments(); i++)
+          fbInfo.getAttachment(i).view->setRtBindingFrameId(m_device->getCurrentFrameId());
+      }
+
       m_flags.set(DxvkContextFlag::GpDirtyPipelineState);
     } else if (m_flags.test(DxvkContextFlag::GpRenderPassNeedsFlush)) {
       // End render pass to flush pending resolves
@@ -6772,6 +6778,14 @@ namespace dxvk {
     }
   }
 
+  bool DxvkContext::checkAsyncCompilationCompat() const {
+    for (uint32_t i = 0; i < m_state.om.framebufferInfo.numAttachments(); i++) {
+      const auto& [view] = m_state.om.framebufferInfo.getAttachment(i);
+      if (!view->getRtBindingAsyncCompilationCompat())
+        return false;
+    }
+    return true;
+  }
 
   void DxvkContext::applyRenderTargetLoadLayouts() {
     for (uint32_t i = 0; i < MaxNumRenderTargets; i++)
@@ -7432,7 +7446,7 @@ namespace dxvk {
     // End render pass if there are pending resolves
     if (m_flags.any(DxvkContextFlag::GpDirtyRenderTargets,
                     DxvkContextFlag::GpRenderPassNeedsFlush))
-      this->updateRenderTargets();
+      this->updateRenderTargets(true);
 
     if (m_flags.test(DxvkContextFlag::GpXfbActive)) {
       // If transform feedback is active and there is a chance that we might
diff --git a/src/dxvk/dxvk_context.h b/src/dxvk/dxvk_context.h
index b365a2d..53ac424 100644
--- a/src/dxvk/dxvk_context.h
+++ b/src/dxvk/dxvk_context.h
@@ -1722,7 +1722,7 @@ namespace dxvk {
     DxvkFramebufferInfo makeFramebufferInfo(
       const DxvkRenderTargets&      renderTargets);
 
-    void updateRenderTargets();
+    void updateRenderTargets(bool isDraw = false);
     
     void applyRenderTargetLoadLayouts();
 
@@ -1855,6 +1855,8 @@ namespace dxvk {
     Rc<DxvkSampler> createBlitSampler(
             VkFilter                  filter);
 
+    [[nodiscard]] bool checkAsyncCompilationCompat() const;
+
     DxvkGraphicsPipeline* lookupGraphicsPipeline(
       const DxvkGraphicsPipelineShaders&  shaders);
 
diff --git a/src/dxvk/dxvk_device.cpp b/src/dxvk/dxvk_device.cpp
index 35df5ee..2e7b301 100644
--- a/src/dxvk/dxvk_device.cpp
+++ b/src/dxvk/dxvk_device.cpp
@@ -2,8 +2,7 @@
 #include "dxvk_instance.h"
 #include "dxvk_latency_builtin.h"
 #include "dxvk_latency_reflex.h"
-#include "dxvk_shader_cache.h"
-#include "dxvk_shader_ir.h"
+#include "framepacer/dxvk_framepacer.h"
 
 namespace dxvk {
   
@@ -544,15 +543,16 @@ namespace dxvk {
 
 
   Rc<DxvkLatencyTracker> DxvkDevice::createLatencyTracker(
-    const Rc<Presenter>&            presenter) {
+    const Rc<Presenter>&            presenter,
+    uint64_t                        firstFrameId ) {
     if (m_options.latencySleep == Tristate::False)
-      return nullptr;
+      return new FramePacer(m_options, firstFrameId);
 
     if (m_options.latencySleep == Tristate::Auto) {
       if (m_features.nvLowLatency2)
         return new DxvkReflexLatencyTrackerNv(presenter);
       else
-        return nullptr;
+        return new FramePacer(m_options, firstFrameId);
     }
 
     return new DxvkBuiltInLatencyTracker(presenter,
diff --git a/src/dxvk/dxvk_device.h b/src/dxvk/dxvk_device.h
index 9c4cfba..5cd60f6 100644
--- a/src/dxvk/dxvk_device.h
+++ b/src/dxvk/dxvk_device.h
@@ -590,7 +590,8 @@ namespace dxvk {
      * \param [in] presenter Presenter instance
      */
     Rc<DxvkLatencyTracker> createLatencyTracker(
-      const Rc<Presenter>&            presenter);
+      const Rc<Presenter>&            presenter,
+      uint64_t                        firstFrameId = 17);
 
     /**
      * \brief Presents a swap chain image
diff --git a/src/dxvk/dxvk_device_info.cpp b/src/dxvk/dxvk_device_info.cpp
index 0eadba5..af793bf 100644
--- a/src/dxvk/dxvk_device_info.cpp
+++ b/src/dxvk/dxvk_device_info.cpp
@@ -42,7 +42,7 @@ namespace dxvk {
     HANDLE_EXT(extVertexAttributeDivisor);         \
     HANDLE_EXT(khrExternalMemoryWin32);            \
     HANDLE_EXT(khrExternalSemaphoreWin32);         \
-    HANDLE_EXT(khrLoadStoreOpNone);                \
+    HANDLE_EXT(extLoadStoreOpNone);                \
     HANDLE_EXT(khrMaintenance5);                   \
     HANDLE_EXT(khrMaintenance6);                   \
     HANDLE_EXT(khrMaintenance7);                   \
@@ -862,7 +862,7 @@ namespace dxvk {
       ENABLE_EXT(khrExternalSemaphoreWin32, false),
 
       /* LOAD_OP_NONE for certain tiler optimizations */
-      ENABLE_EXT(khrLoadStoreOpNone, false),
+      ENABLE_EXT(extLoadStoreOpNone, false),
 
       /* Maintenance features, relied on in various parts of the code */
       ENABLE_EXT_FEATURE(khrMaintenance5, maintenance5, true),
diff --git a/src/dxvk/dxvk_device_info.h b/src/dxvk/dxvk_device_info.h
index 30c0fd6..95d4030 100644
--- a/src/dxvk/dxvk_device_info.h
+++ b/src/dxvk/dxvk_device_info.h
@@ -80,7 +80,7 @@ namespace dxvk {
     VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT         extVertexAttributeDivisor       = { VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES };
     VkBool32                                                  khrExternalMemoryWin32          = VK_FALSE;
     VkBool32                                                  khrExternalSemaphoreWin32       = VK_FALSE;
-    VkBool32                                                  khrLoadStoreOpNone              = VK_FALSE;
+    VkBool32                                                  extLoadStoreOpNone              = VK_FALSE;
     VkPhysicalDeviceMaintenance5FeaturesKHR                   khrMaintenance5                 = { VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_5_FEATURES_KHR };
     VkPhysicalDeviceMaintenance6FeaturesKHR                   khrMaintenance6                 = { VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_6_FEATURES_KHR };
     VkPhysicalDeviceMaintenance7FeaturesKHR                   khrMaintenance7                 = { VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_7_FEATURES_KHR };
@@ -137,7 +137,7 @@ namespace dxvk {
     VkExtensionProperties extVertexAttributeDivisor         = vk::makeExtension(VK_EXT_VERTEX_ATTRIBUTE_DIVISOR_EXTENSION_NAME);
     VkExtensionProperties khrExternalMemoryWin32            = vk::makeExtension(VK_KHR_EXTERNAL_MEMORY_WIN32_EXTENSION_NAME);
     VkExtensionProperties khrExternalSemaphoreWin32         = vk::makeExtension(VK_KHR_EXTERNAL_SEMAPHORE_WIN32_EXTENSION_NAME);
-    VkExtensionProperties khrLoadStoreOpNone                = vk::makeExtension(VK_KHR_LOAD_STORE_OP_NONE_EXTENSION_NAME);
+    VkExtensionProperties extLoadStoreOpNone                = vk::makeExtension(VK_EXT_LOAD_STORE_OP_NONE_EXTENSION_NAME);
     VkExtensionProperties khrMaintenance5                   = vk::makeExtension(VK_KHR_MAINTENANCE_5_EXTENSION_NAME);
     VkExtensionProperties khrMaintenance6                   = vk::makeExtension(VK_KHR_MAINTENANCE_6_EXTENSION_NAME);
     VkExtensionProperties khrMaintenance7                   = vk::makeExtension(VK_KHR_MAINTENANCE_7_EXTENSION_NAME);
diff --git a/src/dxvk/dxvk_graphics.cpp b/src/dxvk/dxvk_graphics.cpp
index dec4ef4..ae9d131 100644
--- a/src/dxvk/dxvk_graphics.cpp
+++ b/src/dxvk/dxvk_graphics.cpp
@@ -5,6 +5,7 @@
 #include "dxvk_device.h"
 #include "dxvk_graphics.h"
 #include "dxvk_pipemanager.h"
+#include "dxvk_state_cache.h"
 
 namespace dxvk {
 
@@ -995,6 +996,7 @@ namespace dxvk {
   : m_device        (device),
     m_manager       (pipeMgr),
     m_workers       (&pipeMgr->m_workers),
+    m_stateCache    (&pipeMgr->m_stateCache),
     m_stats         (&pipeMgr->m_stats),
     m_shaders       (std::move(shaders)),
     m_layout        (device, pipeMgr, buildPipelineLayout()),
@@ -1005,6 +1007,7 @@ namespace dxvk {
     m_vsIn  = m_shaders.vs != nullptr ? m_shaders.vs->metadata().inputs.computeMask() : 0u;
     m_fsOut = m_shaders.fs != nullptr ? m_shaders.fs->metadata().outputs.computeMask() : 0u;
     m_specConstantMask = this->computeSpecConstantMask();
+    gplAsyncCache = m_device->config().gplAsyncCache && env::getEnvVar("DXVK_GPLASYNCCACHE") != "0";
 
     if (m_shaders.gs != nullptr) {
       if (m_shaders.gs->metadata().flags.test(DxvkShaderFlag::HasTransformFeedback)) {
@@ -1056,7 +1059,8 @@ namespace dxvk {
 
 
   DxvkGraphicsPipelineHandle DxvkGraphicsPipeline::getPipelineHandle(
-    const DxvkGraphicsPipelineStateInfo& state) {
+    const DxvkGraphicsPipelineStateInfo& state,
+    const bool                           async) {
     DxvkGraphicsPipelineInstance* instance = this->findInstance(state);
 
     if (unlikely(!instance)) {
@@ -1064,11 +1068,22 @@ namespace dxvk {
       if (!this->validatePipelineState(state, true))
         return DxvkGraphicsPipelineHandle();
 
+      const bool useAsync = async && m_device->config().enableAsync && env::getEnvVar("DXVK_ASYNC") != "0";
+
       // Prevent other threads from adding new instances and check again
-      std::unique_lock<dxvk::mutex> lock(m_mutex);
+      std::unique_lock<dxvk::mutex> lock(useAsync ? m_asyncMutex : m_mutex);
       instance = this->findInstance(state);
 
       if (!instance) {
+        if (useAsync) {
+          m_async.store(true, std::memory_order_release);
+          lock.unlock();
+
+          m_workers->compileGraphicsPipeline(this, state, DxvkPipelinePriority::High);
+
+          return DxvkGraphicsPipelineHandle();
+        }
+
         // Keep pipeline object locked, at worst we're going to stall
         // a state cache worker and the current thread needs priority.
         bool canCreateBasePipeline = this->canCreateBasePipeline(state);
@@ -1081,6 +1096,11 @@ namespace dxvk {
         // If necessary, compile an optimized pipeline variant
         if (!instance->fastHandle.load())
           m_workers->compileGraphicsPipeline(this, state, DxvkPipelinePriority::Low);
+
+        // Only store pipelines in the state cache that cannot benefit
+        // from pipeline libraries, or if that feature is disabled.
+        if (!canCreateBasePipeline)
+          this->writePipelineStateToCache(state);
       }
     }
 
@@ -1103,7 +1123,7 @@ namespace dxvk {
 
       // Do not compile if this pipeline can be fast linked. This essentially
       // disables the state cache for pipelines that do not benefit from it.
-      if (this->canCreateBasePipeline(state))
+      if (!gplAsyncCache && !m_async.load(std::memory_order_acquire) && this->canCreateBasePipeline(state))
         return;
 
       // Prevent other threads from adding new instances and check again
@@ -1124,8 +1144,14 @@ namespace dxvk {
     instance->fastHandle.store(pipeline, std::memory_order_release);
 
     // Log pipeline state on error
-    if (!pipeline)
+    if (!pipeline) {
       this->logPipelineState(LogLevel::Error, state);
+      return;
+    }
+    
+     //Write pipeline to state cache
+     if (gplAsyncCache)
+       this->writePipelineStateToCache(state);
   }
 
 
@@ -1385,6 +1411,8 @@ namespace dxvk {
     if (handle)
       m_fastPipelines.insert({ key, handle });
 
+    m_async.store(false, std::memory_order_release);
+
     return handle;
   }
 
@@ -1628,6 +1656,19 @@ namespace dxvk {
   }
 
   
+  void DxvkGraphicsPipeline::writePipelineStateToCache(
+    const DxvkGraphicsPipelineStateInfo& state) const {
+    DxvkStateCacheKey key;
+    if (m_shaders.vs  != nullptr) key.vs = m_shaders.vs->getShaderKey();
+    if (m_shaders.tcs != nullptr) key.tcs = m_shaders.tcs->getShaderKey();
+    if (m_shaders.tes != nullptr) key.tes = m_shaders.tes->getShaderKey();
+    if (m_shaders.gs  != nullptr) key.gs = m_shaders.gs->getShaderKey();
+    if (m_shaders.fs  != nullptr) key.fs = m_shaders.fs->getShaderKey();
+
+    m_stateCache->addGraphicsPipeline(key, state);
+  }
+  
+  
   void DxvkGraphicsPipeline::logPipelineState(
           LogLevel                       level,
     const DxvkGraphicsPipelineStateInfo& state) const {
diff --git a/src/dxvk/dxvk_graphics.h b/src/dxvk/dxvk_graphics.h
index 9a6a892..657d580 100644
--- a/src/dxvk/dxvk_graphics.h
+++ b/src/dxvk/dxvk_graphics.h
@@ -15,6 +15,7 @@
 namespace dxvk {
   
   class DxvkDevice;
+  class DxvkStateCache;
   class DxvkPipelineManager;
   class DxvkPipelineWorkers;
 
@@ -550,11 +551,13 @@ namespace dxvk {
      * Retrieves a pipeline handle for the given pipeline
      * state. If necessary, a new pipeline will be created.
      * \param [in] state Pipeline state vector
+     * \param [in] async Compile asynchronously
      * \returns Pipeline handle and handle type
      */
     DxvkGraphicsPipelineHandle getPipelineHandle(
-      const DxvkGraphicsPipelineStateInfo&    state);
-    
+      const DxvkGraphicsPipelineStateInfo&    state,
+            bool                              async);
+
     /**
      * \brief Compiles a pipeline
      * 
@@ -598,6 +601,7 @@ namespace dxvk {
     DxvkDevice*                 m_device;    
     DxvkPipelineManager*        m_manager;
     DxvkPipelineWorkers*        m_workers;
+    DxvkStateCache*             m_stateCache;
     DxvkPipelineStats*          m_stats;
 
     DxvkGraphicsPipelineShaders m_shaders;
@@ -617,6 +621,13 @@ namespace dxvk {
 
     alignas(CACHE_LINE_SIZE)
     dxvk::mutex                                   m_mutex;
+    alignas(CACHE_LINE_SIZE)
+    dxvk::mutex                                   m_asyncMutex;
+
+    std::atomic<bool>                             m_async{false};
+    
+    bool                                          gplAsyncCache;
+
     sync::List<DxvkGraphicsPipelineInstance>      m_pipelines;
     uint32_t                                      m_useCount = 0;
 
@@ -674,6 +685,9 @@ namespace dxvk {
 
     DxvkPipelineLayoutBuilder buildPipelineLayout() const;
 
+    void writePipelineStateToCache(
+      const DxvkGraphicsPipelineStateInfo& state) const;
+
     void logPipelineState(
             LogLevel                       level,
       const DxvkGraphicsPipelineStateInfo& state) const;
diff --git a/src/dxvk/dxvk_graphics_state.h b/src/dxvk/dxvk_graphics_state.h
index 8601dd7..be8de1c 100644
--- a/src/dxvk/dxvk_graphics_state.h
+++ b/src/dxvk/dxvk_graphics_state.h
@@ -322,6 +322,119 @@ namespace dxvk {
 
 
   /**
+   * \brief Packed depth-stencil metadata
+   *
+   * Stores some flags and the depth-compare op in
+   * two bytes. Stencil ops are stored separately.
+   */
+  class DxvkDsInfo {
+
+  public:
+
+    DxvkDsInfo() = default;
+
+    DxvkDsInfo(
+            VkBool32 enableDepthTest,
+            VkBool32 enableDepthWrite,
+            VkBool32 enableDepthBoundsTest,
+            VkBool32 enableStencilTest,
+            VkCompareOp depthCompareOp)
+    : m_enableDepthTest       (uint16_t(enableDepthTest)),
+      m_enableDepthWrite      (uint16_t(enableDepthWrite)),
+      m_enableDepthBoundsTest (uint16_t(enableDepthBoundsTest)),
+      m_enableStencilTest     (uint16_t(enableStencilTest)),
+      m_depthCompareOp        (uint16_t(depthCompareOp)),
+      m_reserved              (0) { }
+    
+    VkBool32 enableDepthTest() const {
+      return VkBool32(m_enableDepthTest);
+    }
+
+    VkBool32 enableDepthWrite() const {
+      return VkBool32(m_enableDepthWrite);
+    }
+
+    VkBool32 enableDepthBoundsTest() const {
+      return VkBool32(m_enableDepthBoundsTest);
+    }
+
+    VkBool32 enableStencilTest() const {
+      return VkBool32(m_enableStencilTest);
+    }
+
+    VkCompareOp depthCompareOp() const {
+      return VkCompareOp(m_depthCompareOp);
+    }
+
+    void setEnableDepthBoundsTest(VkBool32 enableDepthBoundsTest) {
+      m_enableDepthBoundsTest = VkBool32(enableDepthBoundsTest);
+    }
+
+  private:
+
+    uint16_t m_enableDepthTest        : 1;
+    uint16_t m_enableDepthWrite       : 1;
+    uint16_t m_enableDepthBoundsTest  : 1;
+    uint16_t m_enableStencilTest      : 1;
+    uint16_t m_depthCompareOp         : 3;
+    uint16_t m_reserved               : 9;
+
+  };
+
+
+  /**
+   * \brief Packed stencil op
+   *
+   * Stores various stencil op parameters
+   * for one single face in four bytes.
+   */
+  class DxvkDsStencilOp {
+
+  public:
+
+    DxvkDsStencilOp() = default;
+
+    DxvkDsStencilOp(
+            VkStencilOp           failOp,
+            VkStencilOp           passOp,
+            VkStencilOp           depthFailOp,
+            VkCompareOp           compareOp,
+            uint8_t               compareMask,
+            uint8_t               writeMask)
+    : m_failOp      (uint32_t(failOp)),
+      m_passOp      (uint32_t(passOp)),
+      m_depthFailOp (uint32_t(depthFailOp)),
+      m_compareOp   (uint32_t(compareOp)),
+      m_reserved    (0),
+      m_compareMask (uint32_t(compareMask)),
+      m_writeMask   (uint32_t(writeMask)) { }
+    
+    VkStencilOpState state(bool write) const {
+      VkStencilOpState result;
+      result.failOp      = VkStencilOp(m_failOp);
+      result.passOp      = VkStencilOp(m_passOp);
+      result.depthFailOp = VkStencilOp(m_depthFailOp);
+      result.compareOp   = VkCompareOp(m_compareOp);
+      result.compareMask = m_compareMask;
+      result.writeMask   = write ? m_writeMask : 0;
+      result.reference   = 0;
+      return result;
+    }
+
+  private:
+
+    uint32_t m_failOp                 : 3;
+    uint32_t m_passOp                 : 3;
+    uint32_t m_depthFailOp            : 3;
+    uint32_t m_compareOp              : 3;
+    uint32_t m_reserved               : 4;
+    uint32_t m_compareMask            : 8;
+    uint32_t m_writeMask              : 8;
+
+  };
+
+
+  /**
    * \brief Packed output merger metadata
    *
    * Stores the logic op state in two bytes.
@@ -708,9 +821,12 @@ namespace dxvk {
     DxvkIlInfo              il;
     DxvkRsInfo              rs;
     DxvkMsInfo              ms;
+    DxvkDsInfo              ds;
     DxvkOmInfo              om;
     DxvkRtInfo              rt;
     DxvkScInfo              sc;
+    DxvkDsStencilOp         dsFront;
+    DxvkDsStencilOp         dsBack;
     DxvkOmAttachmentSwizzle omSwizzle         [DxvkLimits::MaxNumRenderTargets];
     DxvkOmAttachmentBlend   omBlend           [DxvkLimits::MaxNumRenderTargets];
     DxvkIlAttribute         ilAttributes      [DxvkLimits::MaxNumVertexAttributes];
diff --git a/src/dxvk/dxvk_image.h b/src/dxvk/dxvk_image.h
index 63cba28..3901bf0 100644
--- a/src/dxvk/dxvk_image.h
+++ b/src/dxvk/dxvk_image.h
@@ -275,6 +275,37 @@ namespace dxvk {
     }
 
     /**
+     * \brief Sets render target usage frame number
+     *
+     * The image view will track internally when
+     * it was last used as a render target. This
+     * info is used for async shader compilation.
+     * \param [in] frameId Frame number+     */
+    void setRtBindingFrameId(const uint32_t frameId) {
+      if (frameId != m_rtBindingFrameId) {
+        if (frameId == m_rtBindingFrameId + 1)
+          m_rtBindingFrameCount += 1;
+        else
+          m_rtBindingFrameCount = 0;
+
+        m_rtBindingFrameId = frameId;
+      }
+    }
+
+    /**
+     * \brief Checks for async pipeline compatibility
+     *
+     * Asynchronous pipeline compilation may be enabled if the
+     * render target has been drawn to in the previous frames.
+     * \param [in] frameId Current frame ID
+     * \returns \c true if async compilation is supported
+     */
+    [[nodiscard]] bool getRtBindingAsyncCompilationCompat() const {
+      return m_rtBindingFrameCount >= 2;
+    }
+
+
+    /**
      * \brief Checks whether this view overlaps with another one
      *
      * Two views overlap if they were created for the same
@@ -327,6 +358,9 @@ namespace dxvk {
 
     std::array<const DxvkDescriptor*, ViewCount> m_views = { };
 
+    uint32_t m_rtBindingFrameId    = 0;
+    uint32_t m_rtBindingFrameCount = 0;
+
     const DxvkDescriptor* createView(VkImageViewType type) const;
 
     void updateViews();
diff --git a/src/dxvk/dxvk_instance.cpp b/src/dxvk/dxvk_instance.cpp
index cec9e35..589075f 100644
--- a/src/dxvk/dxvk_instance.cpp
+++ b/src/dxvk/dxvk_instance.cpp
@@ -24,7 +24,7 @@ namespace dxvk {
 
   DxvkInstance::DxvkInstance(const DxvkInstanceImportInfo& args, DxvkInstanceFlags flags) {
     Logger::info(str::format("Game: ", env::getExeName()));
-    Logger::info(str::format("DXVK: ", DXVK_VERSION));
+    Logger::info(str::format("DXVK-GPLALL: ", DXVK_VERSION));
     Logger::info(str::format("Build: ", DXVK_TARGET, " ", DXVK_COMPILER, " ", DXVK_COMPILER_VERSION));
 
     wsi::init();
diff --git a/src/dxvk/dxvk_latency.h b/src/dxvk/dxvk_latency.h
index c9ac93c..f886e06 100644
--- a/src/dxvk/dxvk_latency.h
+++ b/src/dxvk/dxvk_latency.h
@@ -128,6 +128,11 @@ namespace dxvk {
     virtual void notifyCpuPresentEnd(
             uint64_t                  frameId) = 0;
 
+    virtual void notifySubmit(
+            uint64_t                  frameId) { }
+    virtual void notifyPresent(
+            uint64_t                  frameId) { }
+
     /**
      * \brief Called when a command list is submitted to the GPU
      *
@@ -174,6 +179,9 @@ namespace dxvk {
     virtual void notifyGpuExecutionEnd(
             uint64_t                  frameId) = 0;
 
+    virtual void notifyGpuPresentBegin(
+            uint64_t                  frameId) { }
+
     /**
      * \brief Called when presentation of a given frame finishes on the GPU
      *
diff --git a/src/dxvk/dxvk_options.cpp b/src/dxvk/dxvk_options.cpp
index 8c18f3b..3a6dd64 100644
--- a/src/dxvk/dxvk_options.cpp
+++ b/src/dxvk/dxvk_options.cpp
@@ -3,21 +3,28 @@
 namespace dxvk {
 
   DxvkOptions::DxvkOptions(const Config& config) {
+    gplAsyncCache = config.getOption<bool>("dxvk.gplAsyncCache", true);
+    enableAsync           = config.getOption<bool>    ("dxvk.enableAsync",            true);
     enableDebugUtils      = config.getOption<bool>    ("dxvk.enableDebugUtils",       false);
+    enableStateCache      = config.getOption<bool>    ("dxvk.enableStateCache",       true);
     enableMemoryDefrag    = config.getOption<Tristate>("dxvk.enableMemoryDefrag",     Tristate::Auto);
     numCompilerThreads    = config.getOption<int32_t> ("dxvk.numCompilerThreads",     0);
-    enableGraphicsPipelineLibrary = config.getOption<Tristate>("dxvk.enableGraphicsPipelineLibrary", Tristate::Auto);
+    enableGraphicsPipelineLibrary = config.getOption<Tristate>("dxvk.enableGraphicsPipelineLibrary", Tristate::False);
     enableDescriptorBuffer = config.getOption<Tristate>("dxvk.enableDescriptorBuffer", Tristate::Auto);
     trackPipelineLifetime = config.getOption<Tristate>("dxvk.trackPipelineLifetime",  Tristate::Auto);
     useRawSsbo            = config.getOption<Tristate>("dxvk.useRawSsbo",             Tristate::Auto);
     hud                   = config.getOption<std::string>("dxvk.hud", "");
     tearFree              = config.getOption<Tristate>("dxvk.tearFree",               Tristate::Auto);
-    latencySleep          = config.getOption<Tristate>("dxvk.latencySleep",           Tristate::Auto);
+    latencySleep          = config.getOption<Tristate>("dxvk.latencySleep",           Tristate::False);
     latencyTolerance      = config.getOption<int32_t> ("dxvk.latencyTolerance",       1000);
     disableNvLowLatency2  = config.getOption<Tristate>("dxvk.disableNvLowLatency2",   Tristate::Auto);
     hideIntegratedGraphics = config.getOption<bool>   ("dxvk.hideIntegratedGraphics", false);
     zeroMappedMemory      = config.getOption<bool>    ("dxvk.zeroMappedMemory",       false);
     allowFse              = config.getOption<bool>    ("dxvk.allowFse",               false);
+    framePace             = config.getOption<std::string>("dxvk.framePace",           "");
+    lowLatencyOffset      = config.getOption<int32_t> ("dxvk.lowLatencyOffset",       0);
+    lowLatencyAllowCpuFramesOverlap
+                          = config.getOption<bool>    ("dxvk.lowLatencyAllowCpuFramesOverlap", true);
     deviceFilter          = config.getOption<std::string>("dxvk.deviceFilter",        "");
     lowerSinCos           = config.getOption<Tristate>("dxvk.lowerSinCos",            Tristate::Auto);
     tilerMode             = config.getOption<Tristate>("dxvk.tilerMode",              Tristate::Auto);
diff --git a/src/dxvk/dxvk_options.h b/src/dxvk/dxvk_options.h
index 380f5ec..a629693 100644
--- a/src/dxvk/dxvk_options.h
+++ b/src/dxvk/dxvk_options.h
@@ -13,6 +13,9 @@ namespace dxvk {
     /// Enable debug utils
     bool enableDebugUtils = false;
 
+    /// Enable state cache
+    bool enableStateCache = true;
+
     /// Enable memory defragmentation
     Tristate enableMemoryDefrag = Tristate::Auto;
 
@@ -21,7 +24,7 @@ namespace dxvk {
     int32_t numCompilerThreads = 0;
 
     /// Enable graphics pipeline library
-    Tristate enableGraphicsPipelineLibrary = Tristate::Auto;
+    Tristate enableGraphicsPipelineLibrary = Tristate::False;
 
     /// Enable descriptor buffer
     Tristate enableDescriptorBuffer = Tristate::Auto;
@@ -29,6 +32,12 @@ namespace dxvk {
     /// Enables pipeline lifetime tracking
     Tristate trackPipelineLifetime = Tristate::Auto;
 
+    /// Enable async pipelines
+    bool enableAsync = true;
+    
+    // Enable state cache with gpl and fixes for async
+    bool gplAsyncCache;
+
     /// Shader-related options
     Tristate useRawSsbo = Tristate::Auto;
 
@@ -40,7 +49,9 @@ namespace dxvk {
     Tristate tearFree = Tristate::Auto;
 
     /// Enables latency sleep
-    Tristate latencySleep = Tristate::Auto;
+    /// Defaults to false in this build to activate the FramePacer,
+    /// especially for the case when the game doesn't support Reflex
+    Tristate latencySleep = Tristate::False;
 
     /// Latency tolerance, in microseconds
     int32_t latencyTolerance = 0u;
@@ -60,6 +71,18 @@ namespace dxvk {
     /// Allows full-screen exclusive mode on Windows
     bool allowFse = false;
 
+     /// Frame pacing
+    std::string framePace;
+
+    /// A value in microseconds to fine-tune the low-latency frame pacing.
+    /// Positive values make a frame begin later which might improve responsiveness.
+    /// Negative values make a frame begin earlier which might improve fps.
+    int32_t lowLatencyOffset;
+
+    /// Determines whether a frame is allowed to begin before finishing processing
+    /// the cpu-part of the previous one, when low-latency frame pacing is used.
+    bool lowLatencyAllowCpuFramesOverlap;
+
     /// Whether to enable tiler optimizations
     Tristate tilerMode = Tristate::Auto;
 
diff --git a/src/dxvk/dxvk_pipemanager.cpp b/src/dxvk/dxvk_pipemanager.cpp
index 4083fbc..f4f11a2 100644
--- a/src/dxvk/dxvk_pipemanager.cpp
+++ b/src/dxvk/dxvk_pipemanager.cpp
@@ -2,9 +2,10 @@
 
 #include "dxvk_device.h"
 #include "dxvk_pipemanager.h"
+#include "dxvk_state_cache.h"
 
 namespace dxvk {
-  
+
   DxvkPipelineWorkers::DxvkPipelineWorkers(
           DxvkDevice*                     device)
   : m_device(device) {
@@ -81,10 +82,17 @@ namespace dxvk {
 
   void DxvkPipelineWorkers::startWorkers() {
     if (!std::exchange(m_workersRunning, true)) {
-      // Use all available cores by default
+      // Get number of CPU logical threads
       uint32_t workerCount = dxvk::thread::hardware_concurrency();
 
+      // Use (number of CPU logical threads - 2) pipeline workers.
+      // Less stuttering when compiling shaders while playing,
+      // in comparison to using all CPU logical threads.
+      workerCount = workerCount - 2;
+
+      // Catching systems with less than 4 threads
       if (workerCount <  1) workerCount =  1;
+      // Catching systems with more than 64 threads
       if (workerCount > 64) workerCount = 64;
 
       // Reduce worker count on 32-bit to save adderss space
@@ -112,7 +120,7 @@ namespace dxvk {
         auto& worker = m_workers.emplace_back([this, priority] {
           runWorker(priority);
         });
-        
+
         worker.set_priority(ThreadPriority::Lowest);
       }
 
@@ -171,26 +179,27 @@ namespace dxvk {
   DxvkPipelineManager::DxvkPipelineManager(
           DxvkDevice*         device)
   : m_device    (device),
-    m_workers   (device) {
+    m_workers   (device),
+    m_stateCache(device, this, &m_workers) {
     Logger::info(str::format("DXVK: Graphics pipeline libraries ",
       (m_device->canUseGraphicsPipelineLibrary() ? "supported" : "not supported")));
 
     createNullFsPipelineLibrary()->compilePipeline();
   }
-  
-  
+
+
   DxvkPipelineManager::~DxvkPipelineManager() {
-    
+
   }
-  
-  
+
+
   DxvkComputePipeline* DxvkPipelineManager::createComputePipeline(
     const DxvkComputePipelineShaders& shaders) {
     if (shaders.cs == nullptr)
       return nullptr;
-    
+
     std::lock_guard<dxvk::mutex> lock(m_pipelineMutex);
-    
+
     auto pair = m_computePipelines.find(shaders);
     if (pair != m_computePipelines.end())
       return &pair->second;
@@ -206,13 +215,13 @@ namespace dxvk {
       std::tuple(m_device, this, shaders, library));
     return &iter.first->second;
   }
-  
-  
+
+
   DxvkGraphicsPipeline* DxvkPipelineManager::createGraphicsPipeline(
     const DxvkGraphicsPipelineShaders& shaders) {
     if (shaders.vs == nullptr)
       return nullptr;
-    
+
     std::lock_guard<dxvk::mutex> lock(m_pipelineMutex);
 
     auto pair = m_graphicsPipelines.find(shaders);
@@ -234,6 +243,16 @@ namespace dxvk {
       // Don't dispatch the pipeline library to a worker thread
       // since it should be compiled on demand anyway.
       vsLibrary = createPipelineLibraryLocked(vsKey);
+
+      // Register the pipeline library with the state cache
+      // so that subsequent runs can still compile it early
+      DxvkStateCacheKey shaderKeys;
+
+      shaderKeys.vs = shaders.vs->getShaderKey();
+      if (shaders.tcs != nullptr) shaderKeys.tcs = shaders.tcs->getShaderKey();
+      if (shaders.tes != nullptr) shaderKeys.tes = shaders.tes->getShaderKey();
+      if (shaders.gs  != nullptr) shaderKeys.gs  = shaders.gs->getShaderKey();
+      m_stateCache.addPipelineLibrary(shaderKeys);
     }
 
     DxvkShaderPipelineLibraryKey fsKey;
@@ -250,7 +269,7 @@ namespace dxvk {
     return &iter.first->second;
   }
 
-  
+
   DxvkShaderPipelineLibrary* DxvkPipelineManager::createShaderPipelineLibrary(
     const DxvkShaderPipelineLibraryKey& key) {
     std::lock_guard<dxvk::mutex> lock(m_pipelineMutex);
@@ -288,8 +307,8 @@ namespace dxvk {
       std::tuple(m_device, state));
     return &iter.first->second;
   }
-  
-  
+
+
   void DxvkPipelineManager::registerShader(
     const Rc<DxvkShader>&         shader) {
     DxvkShaderPipelineLibraryKey key;
@@ -297,9 +316,9 @@ namespace dxvk {
 
     auto library = createShaderPipelineLibrary(key);
     m_workers.compilePipelineLibrary(library, DxvkPipelinePriority::Normal);
+    m_stateCache.registerShader(shader);
   }
 
-
   void DxvkPipelineManager::requestCompileShader(
     const Rc<DxvkShader>&         shader) {
     // Notify immediately so that this only gets called
@@ -329,6 +348,7 @@ namespace dxvk {
 
   void DxvkPipelineManager::stopWorkerThreads() {
     m_workers.stopWorkers();
+    m_stateCache.stopWorkers();
   }
 
 
diff --git a/src/dxvk/dxvk_pipemanager.h b/src/dxvk/dxvk_pipemanager.h
index f98d484..e8fbc46 100644
--- a/src/dxvk/dxvk_pipemanager.h
+++ b/src/dxvk/dxvk_pipemanager.h
@@ -7,6 +7,7 @@
 
 #include "dxvk_compute.h"
 #include "dxvk_graphics.h"
+#include "dxvk_state_cache.h"
 
 namespace dxvk {
 
@@ -285,6 +286,7 @@ namespace dxvk {
     
     DxvkDevice*               m_device;
     DxvkPipelineWorkers       m_workers;
+    DxvkStateCache            m_stateCache;
     DxvkPipelineStats         m_stats;
     
     dxvk::mutex m_layoutMutex;
diff --git a/src/dxvk/dxvk_presenter.cpp b/src/dxvk/dxvk_presenter.cpp
index 76de00f..7314f2c 100644
--- a/src/dxvk/dxvk_presenter.cpp
+++ b/src/dxvk/dxvk_presenter.cpp
@@ -3,6 +3,7 @@
 #include "dxvk_device.h"
 #include "dxvk_presenter.h"
 
+#include "framepacer/dxvk_framepacer.h"
 #include "../wsi/wsi_window.h"
 
 namespace dxvk {
@@ -264,18 +265,11 @@ namespace dxvk {
       return;
 
     if (m_device->features().khrPresentWait.presentWait) {
-      bool canSignal = false;
-
-      { std::unique_lock lock(m_frameMutex);
-
-        m_lastSignaled = frameId;
-        canSignal = m_lastCompleted >= frameId;
-      }
-
-      if (canSignal)
-        m_signal->signal(frameId);
+      std::lock_guard lock(m_frameMutex);
+      m_lastSignaled = frameId;
+      m_frameCond.notify_one();
     } else {
-      m_fpsLimiter.delay();
+      m_fpsLimiter.delay(tracker);
       m_signal->signal(frameId);
 
       if (tracker)
@@ -603,6 +597,9 @@ namespace dxvk {
 
     m_presentMode = pickPresentMode(modes.size(), modes.data(), m_preferredSyncInterval);
 
+    FramePacer* pacer = dynamic_cast<FramePacer*>(m_latencyTracker.ptr());
+    if (pacer) pacer->getFramePacerMode()->setPresentMode(m_presentMode);
+
     // Check whether we can change present modes dynamically. This may
     // influence the image count as well as further swap chain creation.
     std::vector<VkPresentModeKHR> dynamicModes = {{
@@ -1080,9 +1077,16 @@ namespace dxvk {
           uint32_t                  numSupported,
     const VkPresentModeKHR*         pSupported,
           uint32_t                  syncInterval) {
-    std::array<VkPresentModeKHR, 2> desired = { };
+    std::array<VkPresentModeKHR, 3> desired = { };
     uint32_t numDesired = 0;
 
+    FramePacer* pacer = dynamic_cast<FramePacer*>(m_latencyTracker.ptr());
+    if (pacer) {
+      uint32_t desiredMode;
+      if (pacer->getFramePacerMode()->getDesiredPresentMode(desiredMode))
+        desired[numDesired++] = (VkPresentModeKHR) desiredMode;
+    }
+
     Tristate tearFree = m_device->config().tearFree;
 
     if (!syncInterval) {
@@ -1101,7 +1105,7 @@ namespace dxvk {
           return pSupported[j];
       }
     }
-    
+
     // Guaranteed to be available
     return VK_PRESENT_MODE_FIFO_KHR;
   }
@@ -1235,26 +1239,25 @@ namespace dxvk {
   void Presenter::runFrameThread() {
     env::setThreadName("dxvk-frame");
 
-    while (true) {
-      PresenterFrame frame = { };
+    std::unique_lock lock(m_frameMutex);
 
+    while (true) {
       // Wait for all GPU work for this frame to complete in order to maintain
       // ordering guarantees of the frame signal w.r.t. objects being released
-      { std::unique_lock lock(m_frameMutex);
-
-        m_frameCond.wait(lock, [this] {
-          return !m_frameQueue.empty();
-        });
+      m_frameCond.wait(lock, [this] {
+        return !m_frameQueue.empty() && m_frameQueue.front().frameId <= m_lastSignaled;
+      });
 
-        // Use a frame ID of 0 as an exit condition
-        frame = m_frameQueue.front();
+      // Use a frame ID of 0 as an exit condition
+      PresenterFrame frame = m_frameQueue.front();
 
-        if (!frame.frameId) {
-          m_frameQueue.pop();
-          return;
-        }
+      if (!frame.frameId) {
+        m_frameQueue.pop();
+        return;
       }
 
+      lock.unlock();
+
       // If the present operation has succeeded, actually wait for it to complete.
       // Don't bother with it on MAILBOX / IMMEDIATE modes since doing so would
       // restrict us to the display refresh rate on some platforms (XWayland).
@@ -1268,32 +1271,24 @@ namespace dxvk {
 
       // Signal latency tracker right away to get more accurate
       // measurements if the frame rate limiter is enabled.
-      if (frame.tracker) {
+      if (frame.tracker)
         frame.tracker->notifyGpuPresentEnd(frame.frameId);
-        frame.tracker = nullptr;
-      }
 
-      // Apply FPS limiter here to align it as closely with scanout as we can,
+      // Apply FPS limtier here to align it as closely with scanout as we can,
       // and delay signaling the frame latency event to emulate behaviour of a
       // low refresh rate display as closely as we can.
-      m_fpsLimiter.delay();
-
-      // Wake up any thread that may be waiting for the queue to become empty
-      bool canSignal = false;
-
-      { std::unique_lock lock(m_frameMutex);
-
-        m_frameQueue.pop();
-        m_frameDrain.notify_one();
-
-        m_lastCompleted = frame.frameId;
-        canSignal = m_lastSignaled >= frame.frameId;
-      }
+      m_fpsLimiter.delay(frame.tracker);
+      frame.tracker = nullptr;
 
       // Always signal even on error, since failures here
       // are transparent to the front-end.
-      if (canSignal)
-        m_signal->signal(frame.frameId);
+      m_signal->signal(frame.frameId);
+
+      // Wake up any thread that may be waiting for the queue to become empty
+      lock.lock();
+
+      m_frameQueue.pop();
+      m_frameDrain.notify_one();
     }
   }
 
diff --git a/src/dxvk/dxvk_presenter.h b/src/dxvk/dxvk_presenter.h
index 8e403b2..2e85d8e 100644
--- a/src/dxvk/dxvk_presenter.h
+++ b/src/dxvk/dxvk_presenter.h
@@ -259,6 +259,10 @@ namespace dxvk {
             uint32_t                timingCount,
             VkLatencyTimingsFrameReportNV* timings);
 
+
+    void registerLatencyTracker( const Rc<DxvkLatencyTracker>& tracker )
+      { m_latencyTracker = tracker; }
+
   private:
 
     Rc<DxvkDevice>              m_device;
@@ -315,7 +319,7 @@ namespace dxvk {
     std::queue<PresenterFrame>  m_frameQueue;
 
     uint64_t                    m_lastSignaled = 0u;
-    uint64_t                    m_lastCompleted = 0u;
+    Rc<DxvkLatencyTracker>      m_latencyTracker;
 
     alignas(CACHE_LINE_SIZE)
     FpsLimiter                  m_fpsLimiter;
diff --git a/src/dxvk/dxvk_queue.cpp b/src/dxvk/dxvk_queue.cpp
index 6d2d153..0ddf05c 100644
--- a/src/dxvk/dxvk_queue.cpp
+++ b/src/dxvk/dxvk_queue.cpp
@@ -1,5 +1,6 @@
 #include "dxvk_device.h"
 #include "dxvk_queue.h"
+#include "framepacer/dxvk_framepacer.h"
 
 namespace dxvk {
   
@@ -46,6 +47,8 @@ namespace dxvk {
           DxvkSubmitInfo            submitInfo,
           DxvkLatencyInfo           latencyInfo,
           DxvkSubmitStatus*         status) {
+    if (latencyInfo.tracker)
+      latencyInfo.tracker->notifySubmit(latencyInfo.frameId);
     std::unique_lock<dxvk::mutex> lock(m_mutex);
 
     m_finishCond.wait(lock, [this] {
@@ -66,6 +69,8 @@ namespace dxvk {
           DxvkPresentInfo           presentInfo,
           DxvkLatencyInfo           latencyInfo,
           DxvkSubmitStatus*         status) {
+    if (latencyInfo.tracker)
+      latencyInfo.tracker->notifyPresent(presentInfo.frameId);
     std::unique_lock<dxvk::mutex> lock(m_mutex);
 
     DxvkSubmitEntry entry = { };
@@ -274,7 +279,9 @@ namespace dxvk {
       } else if (entry.present.presenter != nullptr) {
         // Signal the frame and then immediately destroy the reference.
         // This is necessary since the front-end may want to explicitly
-        // destroy the presenter object. 
+        // destroy the presenter object.
+        if (entry.latency.tracker)
+          entry.latency.tracker->notifyGpuPresentBegin(entry.present.frameId);
         entry.present.presenter->signalFrame(entry.present.frameId, entry.latency.tracker);
         entry.present.presenter = nullptr;
       }
diff --git a/src/dxvk/dxvk_state_cache.cpp b/src/dxvk/dxvk_state_cache.cpp
new file mode 100644
index 0000000..bf669dc
--- /dev/null
+++ b/src/dxvk/dxvk_state_cache.cpp
@@ -0,0 +1,902 @@
+#include "dxvk_device.h"
+#include "dxvk_pipemanager.h"
+#include "dxvk_state_cache.h"
+
+namespace dxvk {
+
+  static const Sha1Hash       g_nullHash      = Sha1Hash::compute(nullptr, 0);
+  static const DxvkShaderKey  g_nullShaderKey = DxvkShaderKey();
+
+
+  /**
+   * \brief Packed entry header
+   */
+  struct DxvkStateCacheEntryHeader {
+    uint32_t entryType : 1;
+    uint32_t stageMask : 5;
+    uint32_t entrySize : 26;
+  };
+
+
+  /**
+   * \brief Version 8 entry header
+   */
+  struct DxvkStateCacheEntryHeaderV8 {
+    uint32_t stageMask : 8;
+    uint32_t entrySize : 24;
+  };
+
+  
+  /**
+   * \brief State cache entry data
+   *
+   * Stores data for a single cache entry and
+   * provides convenience methods to access it.
+   */
+  class DxvkStateCacheEntryData {
+    constexpr static size_t MaxSize = 1024;
+  public:
+
+    size_t size() const {
+      return m_size;
+    }
+
+    const char* data() const {
+      return m_data;
+    }
+
+    Sha1Hash computeHash() const {
+      return Sha1Hash::compute(m_data, m_size);
+    }
+
+    template<typename T>
+    bool read(T& data, uint32_t version) {
+      return read(data);
+    }
+
+    bool read(DxvkStateCacheKey& shaders, uint32_t version, VkShaderStageFlags stageFlags) {
+      DxvkShaderKey dummyKey;
+
+      std::array<std::pair<VkShaderStageFlagBits, DxvkShaderKey*>, 6> stages = {{
+        { VK_SHADER_STAGE_VERTEX_BIT,                   &shaders.vs },
+        { VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT,     &shaders.tcs },
+        { VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT,  &shaders.tes },
+        { VK_SHADER_STAGE_GEOMETRY_BIT,                 &shaders.gs },
+        { VK_SHADER_STAGE_FRAGMENT_BIT,                 &shaders.fs },
+        { VK_SHADER_STAGE_COMPUTE_BIT,                  &dummyKey },
+      }};
+
+      for (uint32_t i = 0; i < stages.size(); i++) {
+        if (stageFlags & stages[i].first) {
+          if (!read(*stages[i].second, version))
+            return false;
+        }
+      }
+
+      return true;
+    }
+
+    bool read(DxvkBindingMaskV10& data, uint32_t version) {
+      // v11 removes this field
+      if (version >= 11)
+        return true;
+
+      if (version < 9) {
+        DxvkBindingMaskV8 v8;
+        return read(v8);
+      }
+
+      return read(data);
+    }
+
+    bool read(DxvkRsInfo& data, uint32_t version) {
+      if (version < 13) {
+        DxvkRsInfoV12 v12;
+
+        if (!read(v12))
+          return false;
+
+        data = v12.convert();
+        return true;
+      }
+
+      if (version < 14) {
+        DxvkRsInfoV13 v13;
+
+        if (!read(v13))
+          return false;
+
+        data = v13.convert();
+        return true;
+      }
+
+      return read(data);
+    }
+
+    bool read(DxvkRtInfo& data, uint32_t version) {
+      // v12 introduced this field
+      if (version < 12)
+        return true;
+
+      return read(data);
+    }
+
+    bool read(DxvkIlBinding& data, uint32_t version) {
+      if (version < 10) {
+        DxvkIlBindingV9 v9;
+
+        if (!read(v9))
+          return false;
+
+        data = v9.convert();
+        return true;
+      }
+
+      if (!read(data))
+        return false;
+
+      // Format hasn't changed, but we introduced
+      // dynamic vertex strides in the meantime
+      if (version < 15)
+        data.setStride(0);
+
+      return true;
+    }
+
+
+    bool read(DxvkRenderPassFormatV11& data, uint32_t version) {
+      uint8_t sampleCount = 0;
+      uint8_t imageFormat = 0;
+      uint8_t imageLayout = 0;
+
+      if (!read(sampleCount)
+       || !read(imageFormat)
+       || !read(imageLayout))
+        return false;
+
+      data.sampleCount = VkSampleCountFlagBits(sampleCount);
+      data.depth.format = VkFormat(imageFormat);
+      data.depth.layout = unpackImageLayoutV11(imageLayout);
+
+      for (uint32_t i = 0; i < MaxNumRenderTargets; i++) {
+        if (!read(imageFormat)
+         || !read(imageLayout))
+          return false;
+
+        data.color[i].format = VkFormat(imageFormat);
+        data.color[i].layout = unpackImageLayoutV11(imageLayout);
+      }
+
+      return true;
+    }
+
+
+    template<typename T>
+    bool write(const T& data) {
+      if (m_size + sizeof(T) > MaxSize)
+        return false;
+      
+      std::memcpy(&m_data[m_size], &data, sizeof(T));
+      m_size += sizeof(T);
+      return true;
+    }
+
+    bool readFromStream(std::istream& stream, size_t size) {
+      if (size > MaxSize)
+        return false;
+
+      if (!stream.read(m_data, size))
+        return false;
+
+      m_size = size;
+      m_read = 0;
+      return true;
+    }
+
+  private:
+
+    size_t m_size = 0;
+    size_t m_read = 0;
+    char   m_data[MaxSize];
+
+    template<typename T>
+    bool read(T& data) {
+      if (m_read + sizeof(T) > m_size)
+        return false;
+
+      std::memcpy(&data, &m_data[m_read], sizeof(T));
+      m_read += sizeof(T);
+      return true;
+    }
+
+    static VkImageLayout unpackImageLayoutV11(
+            uint8_t                   layout) {
+      switch (layout) {
+        case 0x80: return VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL;
+        case 0x81: return VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL;
+        default: return VkImageLayout(layout);
+      }
+    }
+
+  };
+
+
+  template<typename T>
+  bool readCacheEntryTyped(std::istream& stream, T& entry) {
+    auto data = reinterpret_cast<char*>(&entry);
+    auto size = sizeof(entry);
+
+    if (!stream.read(data, size))
+      return false;
+    
+    Sha1Hash expectedHash = std::exchange(entry.hash, g_nullHash);
+    Sha1Hash computedHash = Sha1Hash::compute(entry);
+    return expectedHash == computedHash;
+  }
+
+
+  bool DxvkStateCacheKey::eq(const DxvkStateCacheKey& key) const {
+    return this->vs.eq(key.vs)
+        && this->tcs.eq(key.tcs)
+        && this->tes.eq(key.tes)
+        && this->gs.eq(key.gs)
+        && this->fs.eq(key.fs);
+  }
+
+
+  size_t DxvkStateCacheKey::hash() const {
+    DxvkHashState hash;
+    hash.add(this->vs.hash());
+    hash.add(this->tcs.hash());
+    hash.add(this->tes.hash());
+    hash.add(this->gs.hash());
+    hash.add(this->fs.hash());
+    return hash;
+  }
+
+
+  DxvkStateCache::DxvkStateCache(
+          DxvkDevice*           device,
+          DxvkPipelineManager*  pipeManager,
+          DxvkPipelineWorkers*  pipeWorkers)
+  : m_device      (device),
+    m_pipeManager (pipeManager),
+    m_pipeWorkers (pipeWorkers) {
+    std::string useStateCache = env::getEnvVar("DXVK_STATE_CACHE");
+    m_enable = useStateCache != "0" && useStateCache != "disable" &&
+      device->config().enableStateCache;
+
+    if (!m_enable)
+      return;
+
+    bool newFile = (useStateCache == "reset") || (!readCacheFile());
+
+    if (newFile) {
+      auto file = openCacheFileForWrite(true);
+
+      // Write all valid entries to the cache file in
+      // case we're recovering a corrupted cache file
+      for (auto& e : m_entries)
+        writeCacheEntry(file, e);
+    }
+  }
+  
+
+  DxvkStateCache::~DxvkStateCache() {
+    this->stopWorkers();
+  }
+
+
+  void DxvkStateCache::addPipelineLibrary(
+    const DxvkStateCacheKey&              shaders) {
+    if (!m_enable || shaders.vs.eq(g_nullShaderKey))
+      return;
+
+    // Do not add an entry that is already in the cache
+    auto entries = m_entryMap.equal_range(shaders);
+
+    for (auto e = entries.first; e != entries.second; e++) {
+      if (m_entries[e->second].type == DxvkStateCacheEntryType::PipelineLibrary)
+        return;
+    }
+
+    // Queue a job to write this pipeline to the cache
+    std::unique_lock<dxvk::mutex> lock(m_writerLock);
+
+    m_writerQueue.push({
+      DxvkStateCacheEntryType::PipelineLibrary, shaders,
+      DxvkGraphicsPipelineStateInfo(), g_nullHash });
+    m_writerCond.notify_one();
+
+    createWriter();
+  }
+
+
+  void DxvkStateCache::addGraphicsPipeline(
+    const DxvkStateCacheKey&              shaders,
+    const DxvkGraphicsPipelineStateInfo&  state) {
+    if (!m_enable || shaders.vs.eq(g_nullShaderKey))
+      return;
+
+    // Do not add an entry that is already in the cache
+    auto entries = m_entryMap.equal_range(shaders);
+
+    for (auto e = entries.first; e != entries.second; e++) {
+      if (m_entries[e->second].type == DxvkStateCacheEntryType::MonolithicPipeline
+       && m_entries[e->second].gpState == state)
+        return;
+    }
+
+    // Queue a job to write this pipeline to the cache
+    std::unique_lock<dxvk::mutex> lock(m_writerLock);
+
+    m_writerQueue.push({
+      DxvkStateCacheEntryType::MonolithicPipeline,
+      shaders, state, g_nullHash });
+    m_writerCond.notify_one();
+
+    createWriter();
+  }
+
+
+  void DxvkStateCache::registerShader(const Rc<DxvkShader>& shader) {
+    if (!m_enable)
+      return;
+
+    DxvkShaderKey key = shader->getShaderKey();
+
+    if (key.eq(g_nullShaderKey))
+      return;
+    
+    // Add the shader so we can look it up by its key
+    std::unique_lock<dxvk::mutex> entryLock(m_entryLock);
+    m_shaderMap.insert({ key, shader });
+
+    // Deferred lock, don't stall workers unless we have to
+    std::unique_lock<dxvk::mutex> workerLock;
+
+    auto pipelines = m_pipelineMap.equal_range(key);
+
+    for (auto p = pipelines.first; p != pipelines.second; p++) {
+      WorkerItem item;
+
+      if (!getShaderByKey(p->second.vs,  item.gp.vs)
+       || !getShaderByKey(p->second.tcs, item.gp.tcs)
+       || !getShaderByKey(p->second.tes, item.gp.tes)
+       || !getShaderByKey(p->second.gs,  item.gp.gs)
+       || !getShaderByKey(p->second.fs,  item.gp.fs))
+        continue;
+      
+      if (!workerLock)
+        workerLock = std::unique_lock<dxvk::mutex>(m_workerLock);
+      
+      m_workerQueue.push(item);
+    }
+
+    if (workerLock) {
+      m_workerCond.notify_all();
+      createWorker();
+    }
+  }
+
+
+  void DxvkStateCache::stopWorkers() {
+    { std::lock_guard<dxvk::mutex> workerLock(m_workerLock);
+      std::lock_guard<dxvk::mutex> writerLock(m_writerLock);
+
+      if (m_stopThreads.exchange(true))
+        return;
+
+      m_workerCond.notify_all();
+      m_writerCond.notify_all();
+    }
+
+    if (m_workerThread.joinable())
+      m_workerThread.join();
+    
+    if (m_writerThread.joinable())
+      m_writerThread.join();
+  }
+
+
+  DxvkShaderKey DxvkStateCache::getShaderKey(const Rc<DxvkShader>& shader) const {
+    return shader != nullptr ? shader->getShaderKey() : g_nullShaderKey;
+  }
+
+
+  bool DxvkStateCache::getShaderByKey(
+    const DxvkShaderKey&            key,
+          Rc<DxvkShader>&           shader) const {
+    if (key.eq(g_nullShaderKey))
+      return true;
+    
+    auto entry = m_shaderMap.find(key);
+    if (entry == m_shaderMap.end())
+      return false;
+
+    shader = entry->second;
+    return true;
+  }
+
+
+  void DxvkStateCache::mapPipelineToEntry(
+    const DxvkStateCacheKey&        key,
+          size_t                    entryId) {
+    m_entryMap.insert({ key, entryId });
+  }
+
+  
+  void DxvkStateCache::mapShaderToPipeline(
+    const DxvkShaderKey&            shader,
+    const DxvkStateCacheKey&        key) {
+    if (!shader.eq(g_nullShaderKey))
+      m_pipelineMap.insert({ shader, key });
+  }
+
+
+  void DxvkStateCache::compilePipelines(const WorkerItem& item) {
+    DxvkStateCacheKey key;
+    key.vs  = getShaderKey(item.gp.vs);
+    key.tcs = getShaderKey(item.gp.tcs);
+    key.tes = getShaderKey(item.gp.tes);
+    key.gs  = getShaderKey(item.gp.gs);
+    key.fs  = getShaderKey(item.gp.fs);
+
+    DxvkGraphicsPipeline* pipeline = nullptr;
+    auto entries = m_entryMap.equal_range(key);
+
+    for (auto e = entries.first; e != entries.second; e++) {
+      const auto& entry = m_entries[e->second];
+
+      switch (entry.type) {
+        case DxvkStateCacheEntryType::MonolithicPipeline: {
+          if (!pipeline)
+            pipeline = m_pipeManager->createGraphicsPipeline(item.gp);
+
+          m_pipeWorkers->compileGraphicsPipeline(pipeline, entry.gpState, DxvkPipelinePriority::Normal);
+        } break;
+
+        case DxvkStateCacheEntryType::PipelineLibrary: {
+          if (!m_device->canUseGraphicsPipelineLibrary() || item.gp.vs == nullptr)
+            break;
+
+          DxvkShaderPipelineLibraryKey libraryKey;
+          libraryKey.addShader(item.gp.vs);
+
+          if (item.gp.tcs != nullptr) libraryKey.addShader(item.gp.tcs);
+          if (item.gp.tes != nullptr) libraryKey.addShader(item.gp.tes);
+          if (item.gp.gs  != nullptr) libraryKey.addShader(item.gp.gs);
+
+          auto pipelineLibrary = m_pipeManager->createShaderPipelineLibrary(libraryKey);
+          m_pipeWorkers->compilePipelineLibrary(pipelineLibrary, DxvkPipelinePriority::Normal);
+        } break;
+      }
+    }
+  }
+
+
+  bool DxvkStateCache::readCacheFile() {
+    // Return success if the file was not found.
+    // This way we will only create it on demand.
+    std::ifstream ifile = openCacheFileForRead();
+
+    if (!ifile) {
+      Logger::debug("DXVK: No state cache file found");
+      return true;
+    }
+
+    // The header stores the state cache version,
+    // we need to regenerate it if it's outdated
+    DxvkStateCacheHeader newHeader;
+    DxvkStateCacheHeader curHeader;
+
+    if (!readCacheHeader(ifile, curHeader)) {
+      Logger::warn("DXVK: Failed to read state cache header");
+      return false;
+    }
+
+    // Discard caches of unsupported versions
+    if (curHeader.version < 8 || curHeader.version == 16
+     || curHeader.version > newHeader.version) {
+      Logger::warn("DXVK: State cache version not supported");
+      return false;
+    }
+
+    // Notify user about format conversion
+    if (curHeader.version != newHeader.version)
+      Logger::info(str::format("DXVK: Updating state cache version to v", newHeader.version));
+
+    // Read actual cache entries from the file.
+    // If we encounter invalid entries, we should
+    // regenerate the entire state cache file.
+    uint32_t numInvalidEntries = 0;
+
+    while (ifile) {
+      DxvkStateCacheEntry entry;
+
+      if (readCacheEntry(curHeader.version, ifile, entry)) {
+        size_t entryId = m_entries.size();
+        m_entries.push_back(entry);
+
+        mapPipelineToEntry(entry.shaders, entryId);
+
+        mapShaderToPipeline(entry.shaders.vs,  entry.shaders);
+        mapShaderToPipeline(entry.shaders.tcs, entry.shaders);
+        mapShaderToPipeline(entry.shaders.tes, entry.shaders);
+        mapShaderToPipeline(entry.shaders.gs,  entry.shaders);
+        mapShaderToPipeline(entry.shaders.fs,  entry.shaders);
+      } else if (ifile) {
+        numInvalidEntries += 1;
+      }
+    }
+
+    Logger::info(str::format(
+      "DXVK: Read ", m_entries.size(),
+      " valid state cache entries"));
+
+    if (numInvalidEntries) {
+      Logger::warn(str::format(
+        "DXVK: Skipped ", numInvalidEntries,
+        " invalid state cache entries"));
+      return false;
+    }
+    
+    // Rewrite entire state cache if it is outdated
+    return curHeader.version == newHeader.version;
+  }
+
+
+  bool DxvkStateCache::readCacheHeader(
+          std::istream&             stream,
+          DxvkStateCacheHeader&     header) const {
+    DxvkStateCacheHeader expected;
+
+    auto data = reinterpret_cast<char*>(&header);
+    auto size = sizeof(header);
+
+    if (!stream.read(data, size))
+      return false;
+    
+    for (uint32_t i = 0; i < 4; i++) {
+      if (expected.magic[i] != header.magic[i])
+        return false;
+    }
+    
+    return true;
+  }
+
+
+  bool DxvkStateCache::readCacheEntry(
+          uint32_t                  version,
+          std::istream&             stream, 
+          DxvkStateCacheEntry&      entry) const {
+    // Read entry metadata and actual data
+    DxvkStateCacheEntryHeader header;
+    DxvkStateCacheEntryData data;
+    VkShaderStageFlags stageMask;
+    Sha1Hash hash;
+
+    if (version >= 16) {
+      if (!stream.read(reinterpret_cast<char*>(&header), sizeof(header)))
+        return false;
+
+      stageMask = VkShaderStageFlags(header.stageMask);
+    } else {
+      DxvkStateCacheEntryHeaderV8 headerV8;
+
+      if (!stream.read(reinterpret_cast<char*>(&headerV8), sizeof(headerV8)))
+        return false;
+
+      header.entryType = uint32_t(DxvkStateCacheEntryType::MonolithicPipeline);
+      header.stageMask = headerV8.stageMask & VK_SHADER_STAGE_ALL_GRAPHICS;
+      header.entrySize = headerV8.entrySize;
+
+      stageMask = VkShaderStageFlags(headerV8.stageMask);
+    }
+
+    if (!stream.read(reinterpret_cast<char*>(&hash), sizeof(hash))
+     || !data.readFromStream(stream, header.entrySize))
+      return false;
+
+    // Validate hash, skip entry if invalid
+    if (hash != data.computeHash())
+      return false;
+
+    // Set up entry metadata
+    entry.type = DxvkStateCacheEntryType(header.entryType);
+
+    // Read shader hashes
+    auto entryType = DxvkStateCacheEntryType(header.entryType);
+    data.read(entry.shaders, version, stageMask);
+
+    if (entryType == DxvkStateCacheEntryType::PipelineLibrary)
+      return true;
+
+    DxvkBindingMaskV10 dummyBindingMask = { };
+
+    if (stageMask & VK_SHADER_STAGE_COMPUTE_BIT) {
+      if (!data.read(dummyBindingMask, version))
+        return false;
+    } else {
+      // Read packed render pass format
+      if (version < 12) {
+        DxvkRenderPassFormatV11 v11;
+        data.read(v11, version);
+        entry.gpState.rt = v11.convert();
+      }
+
+      // Read common pipeline state
+      if (!data.read(dummyBindingMask, version)
+       || !data.read(entry.gpState.ia, version)
+       || !data.read(entry.gpState.il, version)
+       || !data.read(entry.gpState.rs, version)
+       || !data.read(entry.gpState.ms, version)
+       || !data.read(entry.gpState.ds, version)
+       || !data.read(entry.gpState.om, version)
+       || !data.read(entry.gpState.rt, version)
+       || !data.read(entry.gpState.dsFront, version)
+       || !data.read(entry.gpState.dsBack, version))
+        return false;
+
+      if (entry.gpState.il.attributeCount() > MaxNumVertexAttributes
+       || entry.gpState.il.bindingCount() > MaxNumVertexBindings)
+        return false;
+
+      // Read render target swizzles
+      for (uint32_t i = 0; i < MaxNumRenderTargets; i++) {
+        if (!data.read(entry.gpState.omSwizzle[i], version))
+          return false;
+      }
+
+      // Read render target blend info
+      for (uint32_t i = 0; i < MaxNumRenderTargets; i++) {
+        if (!data.read(entry.gpState.omBlend[i], version))
+          return false;
+      }
+
+      // Read defined vertex attributes
+      for (uint32_t i = 0; i < entry.gpState.il.attributeCount(); i++) {
+        if (!data.read(entry.gpState.ilAttributes[i], version))
+          return false;
+      }
+
+      // Read defined vertex bindings
+      for (uint32_t i = 0; i < entry.gpState.il.bindingCount(); i++) {
+        if (!data.read(entry.gpState.ilBindings[i], version))
+          return false;
+      }
+    }
+
+    // Read non-zero spec constants
+    uint32_t specConstantMask = 0;
+
+    if (!data.read(specConstantMask, version))
+      return false;
+
+    for (uint32_t i = 0; i < MaxNumSpecConstants; i++) {
+      if (specConstantMask & (1 << i)) {
+        if (!data.read(entry.gpState.sc.specConstants[i], version))
+          return false;
+      }
+    }
+
+    // Compute shaders are no longer supported
+    if (stageMask & VK_SHADER_STAGE_COMPUTE_BIT)
+      return false;
+
+    return true;
+  }
+
+
+  void DxvkStateCache::writeCacheEntry(
+          std::ostream&             stream, 
+          DxvkStateCacheEntry&      entry) const {
+    DxvkStateCacheEntryData data;
+    VkShaderStageFlags stageMask = 0;
+
+    // Write shader hashes
+    std::array<std::pair<VkShaderStageFlagBits, const DxvkShaderKey*>, 5> stages = {{
+      { VK_SHADER_STAGE_VERTEX_BIT,                   &entry.shaders.vs },
+      { VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT,     &entry.shaders.tcs },
+      { VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT,  &entry.shaders.tes },
+      { VK_SHADER_STAGE_GEOMETRY_BIT,                 &entry.shaders.gs },
+      { VK_SHADER_STAGE_FRAGMENT_BIT,                 &entry.shaders.fs },
+    }};
+
+    for (uint32_t i = 0; i < stages.size(); i++) {
+      if (!stages[i].second->eq(g_nullShaderKey)) {
+        stageMask |= stages[i].first;
+        data.write(*stages[i].second);
+      }
+    }
+
+    if (entry.type != DxvkStateCacheEntryType::PipelineLibrary) {
+      // Write out common pipeline state
+      data.write(entry.gpState.ia);
+      data.write(entry.gpState.il);
+      data.write(entry.gpState.rs);
+      data.write(entry.gpState.ms);
+      data.write(entry.gpState.ds);
+      data.write(entry.gpState.om);
+      data.write(entry.gpState.rt);
+      data.write(entry.gpState.dsFront);
+      data.write(entry.gpState.dsBack);
+
+      // Write out render target swizzles and blend info
+      for (uint32_t i = 0; i < MaxNumRenderTargets; i++)
+        data.write(entry.gpState.omSwizzle[i]);
+
+      for (uint32_t i = 0; i < MaxNumRenderTargets; i++)
+        data.write(entry.gpState.omBlend[i]);
+
+      // Write out input layout for defined attributes
+      for (uint32_t i = 0; i < entry.gpState.il.attributeCount(); i++)
+        data.write(entry.gpState.ilAttributes[i]);
+
+      for (uint32_t i = 0; i < entry.gpState.il.bindingCount(); i++)
+        data.write(entry.gpState.ilBindings[i]);
+
+      // Write out all non-zero spec constants
+      uint32_t specConstantMask = 0;
+
+      for (uint32_t i = 0; i < MaxNumSpecConstants; i++)
+        specConstantMask |= entry.gpState.sc.specConstants[i] ? (1 << i) : 0;
+
+      data.write(specConstantMask);
+
+      for (uint32_t i = 0; i < MaxNumSpecConstants; i++) {
+        if (specConstantMask & (1 << i))
+          data.write(entry.gpState.sc.specConstants[i]);
+      }
+    }
+
+    // General layout: header -> hash -> data
+    DxvkStateCacheEntryHeader header;
+    header.entryType = uint32_t(entry.type);
+    header.stageMask = uint32_t(stageMask);
+    header.entrySize = data.size();
+
+    Sha1Hash hash = data.computeHash();
+
+    stream.write(reinterpret_cast<char*>(&header), sizeof(header));
+    stream.write(reinterpret_cast<char*>(&hash), sizeof(hash));
+    stream.write(data.data(), data.size());
+    stream.flush();
+  }
+
+
+  void DxvkStateCache::workerFunc() {
+    env::setThreadName("dxvk-worker");
+
+    while (!m_stopThreads.load()) {
+      WorkerItem item;
+
+      { std::unique_lock<dxvk::mutex> lock(m_workerLock);
+
+        if (m_workerQueue.empty()) {
+          m_workerCond.wait(lock, [this] () {
+            return m_workerQueue.size()
+                || m_stopThreads.load();
+          });
+        }
+
+        if (m_workerQueue.empty())
+          break;
+        
+        item = m_workerQueue.front();
+        m_workerQueue.pop();
+      }
+
+      compilePipelines(item);
+    }
+  }
+
+
+  void DxvkStateCache::writerFunc() {
+    env::setThreadName("dxvk-writer");
+
+    std::ofstream file;
+
+    while (!m_stopThreads.load()) {
+      DxvkStateCacheEntry entry;
+
+      { std::unique_lock<dxvk::mutex> lock(m_writerLock);
+
+        m_writerCond.wait(lock, [this] () {
+          return m_writerQueue.size()
+              || m_stopThreads.load();
+        });
+
+        if (m_writerQueue.size() == 0)
+          break;
+
+        entry = m_writerQueue.front();
+        m_writerQueue.pop();
+      }
+
+      if (!file.is_open())
+        file = openCacheFileForWrite(false);
+
+      writeCacheEntry(file, entry);
+    }
+  }
+
+
+  void DxvkStateCache::createWorker() {
+    if (!m_workerThread.joinable())
+      m_workerThread = dxvk::thread([this] () { workerFunc(); });
+  }
+
+
+  void DxvkStateCache::createWriter() {
+    if (!m_writerThread.joinable())
+      m_writerThread = dxvk::thread([this] () { writerFunc(); });
+  }
+
+
+  str::path_string DxvkStateCache::getCacheFileName() const {
+    std::string path = getCacheDir();
+
+    if (!path.empty() && *path.rbegin() != '/')
+      path += '/';
+    
+    std::string exeName = env::getExeBaseName();
+    path += exeName + ".dxvk-cache";
+    return str::topath(path.c_str());
+  }
+
+
+  std::ifstream DxvkStateCache::openCacheFileForRead() const {
+    return std::ifstream(getCacheFileName().c_str(), std::ios_base::binary);
+  }
+
+
+  std::ofstream DxvkStateCache::openCacheFileForWrite(bool recreate) const {
+    std::ofstream file;
+
+    if (!recreate) {
+      // Apparently there's no other way to check whether
+      // the file is empty after creating an ofstream
+      recreate = !openCacheFileForRead();
+    }
+
+    if (recreate) {
+      file = std::ofstream(getCacheFileName().c_str(),
+        std::ios_base::binary |
+        std::ios_base::trunc);
+
+      if (!file && env::createDirectory(getCacheDir())) {
+        file = std::ofstream(getCacheFileName().c_str(),
+          std::ios_base::binary |
+          std::ios_base::trunc);
+      }
+    } else {
+      file = std::ofstream(getCacheFileName().c_str(),
+        std::ios_base::binary |
+        std::ios_base::app);
+    }
+
+    if (!file)
+      return file;
+
+    if (recreate) {
+      Logger::info("DXVK: Creating new state cache file");
+
+      // Write header with the current version number
+      DxvkStateCacheHeader header;
+
+      auto data = reinterpret_cast<const char*>(&header);
+      auto size = sizeof(header);
+
+      file.write(data, size);
+    }
+
+    return file;
+  }
+
+
+  std::string DxvkStateCache::getCacheDir() const {
+    return env::getEnvVar("DXVK_STATE_CACHE_PATH");
+  }
+
+}
diff --git a/src/dxvk/dxvk_state_cache.h b/src/dxvk/dxvk_state_cache.h
new file mode 100644
index 0000000..0e72138
--- /dev/null
+++ b/src/dxvk/dxvk_state_cache.h
@@ -0,0 +1,169 @@
+#pragma once
+
+#include <atomic>
+#include <condition_variable>
+#include <fstream>
+#include <mutex>
+#include <queue>
+#include <unordered_map>
+#include <vector>
+
+#include "dxvk_state_cache_types.h"
+
+namespace dxvk {
+
+  class DxvkDevice;
+  class DxvkPipelineManager;
+  class DxvkPipelineWorkers;
+
+  /**
+   * \brief State cache
+   * 
+   * The shader state cache stores state vectors and
+   * render pass formats of all pipelines used in a
+   * game, which allows DXVK to compile them ahead
+   * of time instead of compiling them on the first
+   * draw.
+   */
+  class DxvkStateCache {
+
+  public:
+
+    DxvkStateCache(
+            DxvkDevice*           device,
+            DxvkPipelineManager*  pipeManager,
+            DxvkPipelineWorkers*  pipeWorkers);
+
+    ~DxvkStateCache();
+
+    /**
+     * \brief Adds pipeline library to the cache
+     *
+     * If the pipeline is not already cached, this
+     * will write a new pipeline to the cache file.
+     * \param [in] shaders Shader keys
+     */
+    void addPipelineLibrary(
+      const DxvkStateCacheKey&              shaders);
+
+    /**
+     * \brief Adds a graphics pipeline to the cache
+     * 
+     * If the pipeline is not already cached, this
+     * will write a new pipeline to the cache file.
+     * \param [in] shaders Shader keys
+     * \param [in] state Graphics pipeline state
+     */
+    void addGraphicsPipeline(
+      const DxvkStateCacheKey&              shaders,
+      const DxvkGraphicsPipelineStateInfo&  state);
+
+    /**
+     * \brief Registers a newly compiled shader
+     * 
+     * Makes the shader available to the pipeline
+     * compiler, and starts compiling all pipelines
+     * for which all shaders become available.
+     * \param [in] shader The shader to add
+     */
+    void registerShader(
+      const Rc<DxvkShader>&                 shader);
+
+    /**
+     * \brief Explicitly stops worker threads
+     */
+    void stopWorkers();
+
+  private:
+
+    using WriterItem = DxvkStateCacheEntry;
+
+    struct WorkerItem {
+      DxvkGraphicsPipelineShaders gp;
+    };
+
+    DxvkDevice*                       m_device;
+    DxvkPipelineManager*              m_pipeManager;
+    DxvkPipelineWorkers*              m_pipeWorkers;
+    bool                              m_enable = false;
+
+    std::vector<DxvkStateCacheEntry>  m_entries;
+    std::atomic<bool>                 m_stopThreads = { false };
+
+    dxvk::mutex                       m_entryLock;
+
+    std::unordered_multimap<
+      DxvkStateCacheKey, size_t,
+      DxvkHash, DxvkEq> m_entryMap;
+
+    std::unordered_multimap<
+      DxvkShaderKey, DxvkStateCacheKey,
+      DxvkHash, DxvkEq> m_pipelineMap;
+    
+    std::unordered_map<
+      DxvkShaderKey, Rc<DxvkShader>,
+      DxvkHash, DxvkEq> m_shaderMap;
+
+    dxvk::mutex                       m_workerLock;
+    dxvk::condition_variable          m_workerCond;
+    std::queue<WorkerItem>            m_workerQueue;
+    dxvk::thread                      m_workerThread;
+
+    dxvk::mutex                       m_writerLock;
+    dxvk::condition_variable          m_writerCond;
+    std::queue<WriterItem>            m_writerQueue;
+    dxvk::thread                      m_writerThread;
+
+    DxvkShaderKey getShaderKey(
+      const Rc<DxvkShader>&           shader) const;
+
+    bool getShaderByKey(
+      const DxvkShaderKey&            key,
+            Rc<DxvkShader>&           shader) const;
+    
+    void mapPipelineToEntry(
+      const DxvkStateCacheKey&        key,
+            size_t                    entryId);
+    
+    void mapShaderToPipeline(
+      const DxvkShaderKey&            shader,
+      const DxvkStateCacheKey&        key);
+
+    void compilePipelines(
+      const WorkerItem&               item);
+
+    bool readCacheFile();
+
+    bool readCacheHeader(
+            std::istream&             stream,
+            DxvkStateCacheHeader&     header) const;
+
+    bool readCacheEntry(
+            uint32_t                  version,
+            std::istream&             stream, 
+            DxvkStateCacheEntry&      entry) const;
+    
+    void writeCacheEntry(
+            std::ostream&             stream, 
+            DxvkStateCacheEntry&      entry) const;
+    
+    void workerFunc();
+
+    void writerFunc();
+
+    void createWorker();
+
+    void createWriter();
+
+    str::path_string getCacheFileName() const;
+
+    std::ifstream openCacheFileForRead() const;
+
+    std::ofstream openCacheFileForWrite(
+            bool                      recreate) const;
+
+    std::string getCacheDir() const;
+
+  };
+
+}
diff --git a/src/dxvk/dxvk_state_cache_types.h b/src/dxvk/dxvk_state_cache_types.h
new file mode 100644
index 0000000..e7ee3e5
--- /dev/null
+++ b/src/dxvk/dxvk_state_cache_types.h
@@ -0,0 +1,172 @@
+#pragma once
+
+#include "dxvk_compute.h"
+#include "dxvk_graphics.h"
+#include "dxvk_renderpass.h"
+
+namespace dxvk {
+
+  /**
+   * \brief State cache entry key
+   * 
+   * Stores the shader keys for all
+   * graphics shader stages. Used to
+   * look up cached state entries.
+   */
+  struct DxvkStateCacheKey {
+    DxvkShaderKey vs;
+    DxvkShaderKey tcs;
+    DxvkShaderKey tes;
+    DxvkShaderKey gs;
+    DxvkShaderKey fs;
+
+    bool eq(const DxvkStateCacheKey& key) const;
+
+    size_t hash() const;
+  };
+
+
+  /**
+   * \brief State entry type
+   */
+  enum class DxvkStateCacheEntryType : uint32_t {
+    MonolithicPipeline  = 0,
+    PipelineLibrary     = 1,
+  };
+
+  
+  /**
+   * \brief State entry
+   * 
+   * Stores the shaders used in a pipeline, as well
+   * as the full state vector, including its render
+   * pass format. This also includes a SHA-1 hash
+   * that is used as a check sum to verify integrity.
+   */
+  struct DxvkStateCacheEntry {
+    DxvkStateCacheEntryType       type;
+    DxvkStateCacheKey             shaders;
+    DxvkGraphicsPipelineStateInfo gpState;
+    Sha1Hash                      hash;
+  };
+
+
+  /**
+   * \brief State cache header
+   * 
+   * Stores the state cache format version. If an
+   * existing cache file is incompatible to the
+   * current version, it will be discarded.
+   */
+  struct DxvkStateCacheHeader {
+    char     magic[4]   = { 'D', 'X', 'V', 'K' };
+    uint32_t version    = 18;
+    uint32_t entrySize  = 0; /* no longer meaningful */
+  };
+
+  static_assert(sizeof(DxvkStateCacheHeader) == 12);
+
+  using DxvkBindingMaskV10 = DxvkBindingSet<384>;
+  using DxvkBindingMaskV8 = DxvkBindingSet<128>;
+
+  class DxvkIlBindingV9 {
+
+  public:
+
+    uint32_t m_binding                : 5;
+    uint32_t m_stride                 : 12;
+    uint32_t m_inputRate              : 1;
+    uint32_t m_reserved               : 14;
+    uint32_t m_divisor;
+
+    DxvkIlBinding convert() const {
+      return DxvkIlBinding(m_binding, m_stride,
+        VkVertexInputRate(m_inputRate), m_divisor);
+    }
+
+  };
+
+  /**
+   * \brief Old attachment format struct
+   */
+  struct DxvkAttachmentFormatV11 {
+    VkFormat      format = VK_FORMAT_UNDEFINED;
+    VkImageLayout layout = VK_IMAGE_LAYOUT_UNDEFINED;
+  };
+  
+  
+  /**
+   * \brief Old render pass format struct
+   */
+  struct DxvkRenderPassFormatV11 {
+    VkSampleCountFlagBits sampleCount;
+    DxvkAttachmentFormatV11 depth;
+    DxvkAttachmentFormatV11 color[MaxNumRenderTargets];
+
+    DxvkRtInfo convert() const {
+      VkImageAspectFlags readOnlyAspects = 0;
+      auto depthFormatInfo = lookupFormatInfo(depth.format);
+
+      if (depth.format && depthFormatInfo) {
+        readOnlyAspects = depthFormatInfo->aspectMask
+          & ~vk::getWritableAspectsForLayout(depth.layout);
+      }
+
+      std::array<VkFormat, MaxNumRenderTargets> colorFormats;
+      for (uint32_t i = 0; i < MaxNumRenderTargets; i++)
+        colorFormats[i] = color[i].format;
+
+      return DxvkRtInfo(MaxNumRenderTargets, colorFormats.data(),
+        depth.format, readOnlyAspects);
+    }
+  };
+
+  class DxvkRsInfoV12 {
+
+  public:
+
+    uint32_t m_depthClipEnable        : 1;
+    uint32_t m_polygonMode            : 2;
+    uint32_t m_cullMode               : 2;
+    uint32_t m_frontFace              : 1;
+    uint32_t m_viewportCount          : 5;
+    uint32_t m_sampleCount            : 5;
+    uint32_t m_conservativeMode       : 2;
+    uint32_t m_reserved               : 13;
+
+    DxvkRsInfo convert() const {
+      return DxvkRsInfo(
+        VkBool32(m_depthClipEnable),
+        VkPolygonMode(m_polygonMode),
+        VkSampleCountFlags(m_sampleCount),
+        VkConservativeRasterizationModeEXT(m_conservativeMode),
+        VK_FALSE, VK_LINE_RASTERIZATION_MODE_DEFAULT_EXT);
+    }
+
+  };
+
+
+  class DxvkRsInfoV13 {
+
+  public:
+
+    uint16_t m_depthClipEnable        : 1;
+    uint16_t m_polygonMode            : 2;
+    uint16_t m_cullMode               : 2;
+    uint16_t m_frontFace              : 1;
+    uint16_t m_sampleCount            : 5;
+    uint16_t m_conservativeMode       : 2;
+    uint16_t m_reserved               : 2;
+
+    DxvkRsInfo convert() const {
+      return DxvkRsInfo(
+        VkBool32(m_depthClipEnable),
+        VkPolygonMode(m_polygonMode),
+        VkSampleCountFlags(m_sampleCount),
+        VkConservativeRasterizationModeEXT(m_conservativeMode),
+        VK_FALSE, VK_LINE_RASTERIZATION_MODE_DEFAULT_EXT);
+    }
+
+  };
+
+}
diff --git a/src/dxvk/framepacer/dxvk_framepacer.cpp b/src/dxvk/framepacer/dxvk_framepacer.cpp
new file mode 100644
index 0000000..9bb52ca
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_framepacer.cpp
@@ -0,0 +1,108 @@
+#include "dxvk_framepacer.h"
+#include "dxvk_framepacer_mode_low_latency.h"
+#include "dxvk_framepacer_mode_min_latency.h"
+#include "dxvk_options.h"
+#include "../../util/util_flush.h"
+#include "../../util/util_env.h"
+#include "../../util/log/log.h"
+
+namespace dxvk {
+
+  int getRefreshRate( std::string s ) {
+    return std::abs( std::atoi( s.substr(16).c_str() ) );
+  }
+
+
+  FramePacer::FramePacer( const DxvkOptions& options, uint64_t firstFrameId )
+  : m_latencyMarkersStorage(firstFrameId) {
+    // We'll default to LOW_LATENCY in the draft-PR for now, for demonstration purposes,
+    // highlighting the generally much better input lag and time consistency.
+    // MAX_FRAME_LATENCY has advantages in some games that provide inconsistent
+    // cpu frametimes and is tuned for highest fps which can be relevant in benchmarks.
+    FramePacerMode::Mode mode = FramePacerMode::LOW_LATENCY;
+    int refreshRate = 0;
+
+    std::string configStr = env::getEnvVar("DXVK_FRAME_PACE");
+
+    if (configStr.find("max-frame-latency") != std::string::npos) {
+      mode = FramePacerMode::MAX_FRAME_LATENCY;
+    } else if (configStr.find("low-latency-vrr-") != std::string::npos) {
+      mode = FramePacerMode::LOW_LATENCY_VRR;
+      refreshRate = getRefreshRate(configStr);
+    } else if (configStr.find("low-latency") != std::string::npos) {
+      mode = FramePacerMode::LOW_LATENCY;
+    } else if (configStr.find("min-latency") != std::string::npos) {
+      mode = FramePacerMode::MIN_LATENCY;
+    } else if (options.framePace.find("max-frame-latency") != std::string::npos) {
+      mode = FramePacerMode::MAX_FRAME_LATENCY;
+    } else if (options.framePace.find("low-latency-vrr-") != std::string::npos) {
+      mode = FramePacerMode::LOW_LATENCY_VRR;
+      refreshRate = getRefreshRate(options.framePace);
+    } else if (options.framePace.find("low-latency") != std::string::npos) {
+      mode = FramePacerMode::LOW_LATENCY;
+    } else if (options.framePace.find("min-latency") != std::string::npos) {
+      mode = FramePacerMode::MIN_LATENCY;
+    } else if (!configStr.empty()) {
+      Logger::warn( str::format( "DXVK_FRAME_PACE=", configStr, " unknown" ));
+    } else if (!options.framePace.empty()) {
+      Logger::warn( str::format( "dxvk.framePace = ", options.framePace, " unknown" ));
+    }
+
+    switch (mode) {
+      case FramePacerMode::MAX_FRAME_LATENCY:
+        Logger::info( "Frame pace: max-frame-latency" );
+        m_mode = std::make_unique<FramePacerMode>(FramePacerMode::MAX_FRAME_LATENCY, &m_latencyMarkersStorage, firstFrameId);
+        break;
+
+      case FramePacerMode::LOW_LATENCY:
+        Logger::info( "Frame pace: low-latency" );
+        GpuFlushTracker::m_minPendingSubmissions = 1;
+        GpuFlushTracker::m_minChunkCount = 1;
+        m_mode = std::make_unique<LowLatencyMode>(mode, &m_latencyMarkersStorage, options, firstFrameId);
+        break;
+
+      case FramePacerMode::LOW_LATENCY_VRR:
+        Logger::info( "Frame pace: low-latency-vrr" );
+        GpuFlushTracker::m_minPendingSubmissions = 1;
+        GpuFlushTracker::m_minChunkCount = 1;
+        m_mode = std::make_unique<LowLatencyMode>(mode, &m_latencyMarkersStorage, options, firstFrameId, refreshRate);
+        break;
+
+      case FramePacerMode::MIN_LATENCY:
+        Logger::info( "Frame pace: min-latency" );
+        GpuFlushTracker::m_minPendingSubmissions = 1;
+        GpuFlushTracker::m_minChunkCount = 1;
+        m_mode = std::make_unique<MinLatencyMode>(mode, &m_latencyMarkersStorage, firstFrameId);
+        break;
+    }
+
+    for (auto& gpuStart: m_gpuStarts) {
+      gpuStart.store(0);
+    }
+
+    // be consistent that every frame has a gpuReady event from finishing the previous frame
+    LatencyMarkers* m = m_latencyMarkersStorage.getMarkers( firstFrameId );
+    auto now = high_resolution_clock::now();
+    m->gpuReady.push_back( now );
+    m_mode->notifyGpuReady( firstFrameId, now );
+    m_gpuStarts[ firstFrameId % m_gpuStarts.size() ] = gpuReadyBit;
+
+    LatencyMarkersTimeline& timeline = m_latencyMarkersStorage.m_timeline;
+    timeline.cpuFinished.store   ( firstFrameId-1 );
+    timeline.gpuStart.store      ( firstFrameId-1 );
+    timeline.gpuFinished.store   ( firstFrameId-1 );
+    timeline.frameFinished.store ( firstFrameId-1 );
+
+    m_mode->signalGpuStart       ( firstFrameId-1 );
+    m_mode->signalRenderFinished ( firstFrameId-1 );
+    m_mode->signalFrameFinished  ( firstFrameId-1 );
+    m_mode->signalCsFinished     ( firstFrameId );
+  }
+
+
+  FramePacer::~FramePacer() {
+    delete m_presentationStats.load();
+    delete m_gpuBufferStats.load();
+  }
+
+}
diff --git a/src/dxvk/framepacer/dxvk_framepacer.h b/src/dxvk/framepacer/dxvk_framepacer.h
new file mode 100644
index 0000000..34f5461
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_framepacer.h
@@ -0,0 +1,233 @@
+#pragma once
+
+#include "dxvk_framepacer_mode.h"
+#include "dxvk_latency_markers.h"
+#include "dxvk_latency_stats.h"
+#include "../dxvk_latency.h"
+#include "../../util/util_time.h"
+
+
+namespace dxvk {
+
+  struct DxvkOptions;
+
+  /* \brief Frame pacer interface managing the CPU - GPU synchronization.
+   *
+   * GPUs render frames asynchronously to the game's and dxvk's CPU-side work
+   * in order to improve fps-throughput. Aligning the cpu work to chosen time-
+   * points allows to tune certain characteristics of the video presentation,
+   * like smoothness and latency.
+   */
+
+  class FramePacer : public DxvkLatencyTracker {
+    using microseconds = std::chrono::microseconds;
+  public:
+
+    FramePacer( const DxvkOptions& options, uint64_t firstFrameId );
+    ~FramePacer();
+
+    void sleepAndBeginFrame(
+            uint64_t                  frameId,
+            double                    maxFrameRate) override {
+      // wait for finished rendering of a previous frame, typically the one before last
+      m_mode->waitRenderFinished(frameId);
+      // potentially wait some more if the cpu gets too much ahead
+      m_mode->startFrame(frameId);
+      m_latencyMarkersStorage.registerFrameStart(frameId);
+    }
+
+    void notifyGpuPresentEnd( uint64_t frameId ) override {
+      // the frame has been displayed to the screen
+      m_latencyMarkersStorage.registerFrameEnd(frameId);
+      m_mode->endFrame(frameId);
+      m_mode->signalFrameFinished(frameId);
+      m_gpuStarts[ (frameId-1) % m_gpuStarts.size() ].store(0);
+      trackStats(frameId);
+    }
+
+    void notifyCsRenderBegin( uint64_t frameId ) override {
+      auto now = high_resolution_clock::now();
+      LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+      m->csStart = std::chrono::duration_cast<microseconds>(now - m->start).count();
+    }
+
+    void notifyCsRenderEnd( uint64_t frameId ) override {
+      auto now = high_resolution_clock::now();
+      LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+      m->csFinished = std::chrono::duration_cast<microseconds>(now - m->start).count();
+      m_mode->signalCsFinished( frameId );
+    }
+
+    void notifySubmit( uint64_t frameId ) override {
+      LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+      m->gpuSubmit.push_back(high_resolution_clock::now());
+    }
+
+    void notifyPresent( uint64_t frameId ) override {
+      // dx to vk translation is finished
+      if (frameId != 0) {
+        auto now = high_resolution_clock::now();
+        LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+        LatencyMarkers* next = m_latencyMarkersStorage.getMarkers(frameId+1);
+        m->gpuSubmit.push_back(now);
+        m->cpuFinished = std::chrono::duration_cast<microseconds>(now - m->start).count();
+        next->gpuSubmit.clear();
+
+        m_latencyMarkersStorage.m_timeline.cpuFinished.store(frameId);
+      }
+    }
+
+    void notifyQueueSubmit( uint64_t frameId ) override {
+      auto now = high_resolution_clock::now();
+      LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+      m->gpuQueueSubmit.push_back(now);
+      queueSubmitCheckGpuStart(frameId, m, now);
+      m_mode->notifyQueueSubmit(frameId, now);
+    }
+
+    void notifyQueuePresentBegin( uint64_t frameId ) override {
+      if (frameId != 0) {
+        auto now = high_resolution_clock::now();
+        LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+        LatencyMarkers* next = m_latencyMarkersStorage.getMarkers(frameId+1);
+        m->gpuQueueSubmit.push_back(now);
+        m_mode->notifyQueueSubmit(frameId, now);
+        next->gpuQueueSubmit.clear();
+        queueSubmitCheckGpuStart(frameId, m, now);
+      }
+    }
+
+    void notifyGpuExecutionEnd( uint64_t frameId ) override {
+      auto now = high_resolution_clock::now();
+      LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+      m->gpuReady.push_back(now);
+      m_mode->notifyGpuReady(frameId, now);
+    }
+
+    virtual void notifyGpuPresentBegin( uint64_t frameId ) override {
+      // we get frameId == 0 for repeated presents (SyncInterval)
+      if (frameId != 0) {
+        auto now = high_resolution_clock::now();
+
+        LatencyMarkers* m = m_latencyMarkersStorage.getMarkers(frameId);
+        LatencyMarkers* next = m_latencyMarkersStorage.getMarkers(frameId+1);
+        m->gpuReady.push_back(now);
+        m_mode->notifyGpuReady(frameId, now);
+        m->gpuFinished = std::chrono::duration_cast<microseconds>(now - m->start).count();
+        next->gpuReady.clear();
+        next->gpuReady.push_back(now);
+        m_mode->notifyGpuReady(frameId+1, now);
+
+        gpuExecutionCheckGpuStart(frameId+1, next, now);
+
+        m_latencyMarkersStorage.m_timeline.gpuFinished.store(frameId);
+        m_mode->finishRender(frameId);
+        m_mode->signalRenderFinished(frameId);
+      }
+    }
+
+    FramePacerMode::Mode getMode() const {
+      return m_mode->m_mode;
+    }
+
+    FramePacerMode* getFramePacerMode() {
+      return m_mode.get();
+    }
+
+    void setTargetFrameRate( double frameRate ) {
+      m_mode->setTargetFrameRate(frameRate);
+    }
+
+    bool needsAutoMarkers() override {
+      return true;
+    }
+
+    LatencyMarkersStorage m_latencyMarkersStorage;
+
+
+    // not implemented methods
+
+
+    void notifyCpuPresentBegin( uint64_t frameId ) override { }
+    void notifyCpuPresentEnd( uint64_t frameId ) override { }
+    void notifyQueuePresentEnd( uint64_t frameId, VkResult status) override { }
+    void notifyGpuExecutionBegin( uint64_t frameId ) override { }
+    void discardTimings() override { }
+    DxvkLatencyStats getStatistics( uint64_t frameId ) override
+      { return DxvkLatencyStats(); }
+
+
+    // non-overriding methods
+
+
+    const LatencyStats* getGpuBufferStats() const
+      { return m_gpuBufferStats.load(); }
+
+    const LatencyStats* getPresentStats() const
+      { return m_presentationStats.load(); }
+
+    std::atomic< bool > m_enableGpuBufferTracking = { false };
+    std::atomic< bool > m_enableVSyncBufferTracking = { false };
+
+  private:
+
+    void signalGpuStart( uint64_t frameId, LatencyMarkers* m, const high_resolution_clock::time_point& t ) {
+      m->gpuStart = std::chrono::duration_cast<microseconds>(t - m->start).count();
+      m_latencyMarkersStorage.m_timeline.gpuStart.store(frameId);
+      m_mode->signalGpuStart(frameId);
+    }
+
+    void queueSubmitCheckGpuStart( uint64_t frameId, LatencyMarkers* m, const high_resolution_clock::time_point& t ) {
+      auto& gpuStart = m_gpuStarts[ frameId % m_gpuStarts.size() ];
+      uint16_t val = gpuStart.fetch_or(queueSubmitBit);
+      if (val == gpuReadyBit)
+        signalGpuStart( frameId, m, t );
+    }
+
+    void gpuExecutionCheckGpuStart( uint64_t frameId, LatencyMarkers* m, const high_resolution_clock::time_point& t ) {
+      auto& gpuStart = m_gpuStarts[ frameId % m_gpuStarts.size() ];
+      uint16_t val = gpuStart.fetch_or(gpuReadyBit);
+      if (val == queueSubmitBit)
+        signalGpuStart( frameId, m, t );
+    }
+
+    void trackStats( uint64_t frameId ) {
+      const LatencyMarkers* m = m_latencyMarkersStorage.getConstMarkers(frameId);
+
+      if (m_enableVSyncBufferTracking) {
+        if (!m_presentationStats)
+          m_presentationStats.store( new LatencyStats(3000) );
+        m_presentationStats.load()->push( m->end, m->presentFinished - m->gpuFinished );
+      }
+
+      if (m_enableGpuBufferTracking) {
+        if (!m_gpuBufferStats)
+          m_gpuBufferStats.store( new LatencyStats(3000) );
+
+        int64_t minDiff = std::numeric_limits<int64_t>::max();
+        size_t i = 0;
+        while (m->gpuSubmit.size() > i && m->gpuReady.size() > i) {
+          int64_t diff = std::chrono::duration_cast<microseconds>(
+            m->gpuReady[i] - m->gpuSubmit[i]).count();
+          diff = std::max( (int64_t) 0, diff );
+          minDiff = std::min( minDiff, diff );
+          ++i;
+        }
+
+        if (minDiff != std::numeric_limits<int64_t>::max())
+          m_gpuBufferStats.load()->push( m->end, minDiff );
+      }
+    }
+
+    std::unique_ptr<FramePacerMode> m_mode;
+
+    std::array< std::atomic< uint16_t >, 8 > m_gpuStarts = { };
+    static constexpr uint16_t queueSubmitBit = 1;
+    static constexpr uint16_t gpuReadyBit    = 2;
+
+    std::atomic<LatencyStats*> m_gpuBufferStats = { nullptr };
+    std::atomic<LatencyStats*> m_presentationStats = { nullptr };
+
+  };
+
+}
diff --git a/src/dxvk/framepacer/dxvk_framepacer_mode.h b/src/dxvk/framepacer/dxvk_framepacer_mode.h
new file mode 100644
index 0000000..768d745
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_framepacer_mode.h
@@ -0,0 +1,138 @@
+#pragma once
+
+#include "dxvk_latency_markers.h"
+#include "../../util/sync/sync_signal.h"
+#include "../../util/util_env.h"
+#include "../../util/util_time.h"
+
+namespace dxvk {
+
+  /*
+   * /brief Abstract frame pacer mode in order to support different strategies of synchronization.
+   */
+
+  class FramePacerMode {
+
+    using time_point = high_resolution_clock::time_point;
+
+  public:
+
+    enum Mode {
+      MAX_FRAME_LATENCY = 0,
+      LOW_LATENCY,
+      LOW_LATENCY_VRR,
+      MIN_LATENCY
+    };
+
+    FramePacerMode( Mode mode, LatencyMarkersStorage* markerStorage, uint64_t firstFrameId, uint32_t maxFrameLatency=1 )
+    : m_mode( mode ),
+      m_waitLatency( maxFrameLatency+1 ),
+      m_firstFrameId( firstFrameId ),
+      m_latencyMarkersStorage( markerStorage ) {
+      setFpsLimitFrametimeFromEnv();
+    }
+
+    virtual ~FramePacerMode() { }
+
+    virtual void startFrame( uint64_t frameId ) { }
+    virtual void endFrame( uint64_t frameId ) { }
+
+    virtual void finishRender( uint64_t frameId ) { }
+
+    virtual void notifyQueueSubmit( uint64_t frameId, time_point t ) { }
+    virtual void notifyGpuReady( uint64_t frameId, time_point t ) { }
+
+    virtual bool getDesiredPresentMode( uint32_t& presentMode ) const {
+      return false; }
+
+    void setPresentMode( uint32_t presentMode ) {
+      m_presentMode = presentMode; }
+
+    uint32_t getPresentMode() { return m_presentMode; }
+
+    void waitRenderFinished( uint64_t frameId ) {
+      if (m_mode) m_fenceGpuFinished.wait(frameId-m_waitLatency); }
+
+    void signalRenderFinished( uint64_t frameId ) {
+      if (m_mode) m_fenceGpuFinished.signal(frameId); }
+
+    void signalFrameFinished( uint64_t frameId ) {
+      if (m_mode) m_fenceFrameFinished.signal(frameId); }
+
+    void signalGpuStart( uint64_t frameId ) {
+      if (m_mode) m_fenceGpuStart.signal(frameId); }
+
+    void signalCsFinished( uint64_t frameId ) {
+      if (m_mode) m_fenceCsFinished.signal(frameId); }
+
+    void setTargetFrameRate( double frameRate ) {
+      if (!m_fpsLimitEnvOverride && frameRate > 1.0)
+        m_fpsLimitFrametime.store( 1'000'000/frameRate );
+    }
+
+    const Mode m_mode;
+
+    static bool getDoubleFromEnv( const char* name, double* result );
+    static bool getIntFromEnv( const char* name, int* result );
+
+  protected:
+
+    void setFpsLimitFrametimeFromEnv();
+
+    const uint32_t m_waitLatency;
+    const uint64_t m_firstFrameId;
+    LatencyMarkersStorage* m_latencyMarkersStorage;
+    std::atomic<uint32_t> m_presentMode;
+    std::atomic<int32_t> m_fpsLimitFrametime = { 0 };
+    bool m_fpsLimitEnvOverride = { false };
+
+    sync::Fence m_fenceGpuStart;
+    sync::Fence m_fenceGpuFinished;
+    sync::Fence m_fenceFrameFinished;
+    sync::Fence m_fenceCsFinished;
+
+  };
+
+
+
+  inline bool FramePacerMode::getDoubleFromEnv( const char* name, double* result ) {
+    std::string env = env::getEnvVar(name);
+    if (env.empty())
+      return false;
+
+    try {
+      *result = std::stod(env);
+      return true;
+    } catch (const std::invalid_argument&) {
+      return false;
+    }
+  }
+
+
+  inline bool FramePacerMode::getIntFromEnv( const char* name, int* result ) {
+    std::string env = env::getEnvVar(name);
+    if (env.empty())
+      return false;
+
+    try {
+      *result = std::stoi(env);
+      return true;
+    } catch (const std::invalid_argument&) {
+      return false;
+    }
+  }
+
+
+  inline void FramePacerMode::setFpsLimitFrametimeFromEnv() {
+    double fpsLimit;
+    if (!getDoubleFromEnv("DXVK_FRAME_RATE", &fpsLimit))
+      return;
+
+    m_fpsLimitEnvOverride = true;
+    if (fpsLimit < 1.0)
+      return;
+
+    m_fpsLimitFrametime = 1'000'000/fpsLimit;
+  }
+
+}
diff --git a/src/dxvk/framepacer/dxvk_framepacer_mode_low_latency.cpp b/src/dxvk/framepacer/dxvk_framepacer_mode_low_latency.cpp
new file mode 100644
index 0000000..8463621
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_framepacer_mode_low_latency.cpp
@@ -0,0 +1,22 @@
+#include "dxvk_framepacer_mode_low_latency.h"
+#include <vulkan/vulkan_core.h>
+
+namespace dxvk {
+
+  bool LowLatencyMode::getDesiredPresentMode( uint32_t& presentMode ) const {
+    if (m_mode != LOW_LATENCY_VRR)
+      return false;
+
+    presentMode = (uint32_t) VkPresentModeKHR::VK_PRESENT_MODE_FIFO_KHR;
+    return true;
+  }
+
+  int32_t LowLatencyMode::getLowLatencyOffset( const DxvkOptions& options ) {
+    int32_t offset = options.lowLatencyOffset;
+
+    offset = std::max( -10000, offset );
+    offset = std::min(  10000, offset );
+    return offset;
+  }
+
+}
diff --git a/src/dxvk/framepacer/dxvk_framepacer_mode_low_latency.h b/src/dxvk/framepacer/dxvk_framepacer_mode_low_latency.h
new file mode 100644
index 0000000..41bf729
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_framepacer_mode_low_latency.h
@@ -0,0 +1,393 @@
+#pragma once
+
+#include "dxvk_framepacer_mode.h"
+#include "dxvk_latency_stats.h"
+#include "dxvk_gpu_progress.h"
+#include "../dxvk_options.h"
+#include "../../util/log/log.h"
+#include "../../util/util_string.h"
+
+namespace dxvk {
+
+  /*
+   * This low-latency mode aims to reduce latency with minimal impact in fps.
+   * Effective when operating in the GPU-limit. Efficient to be used in the CPU-limit as well.
+   *
+   * Greatly reduces input lag variations when switching between CPU- and GPU-limit, and
+   * compared to the max-frame-latency approach, it has a much more stable input lag when
+   * GPU running times change dramatically, which can happen for example when rotating within a scene.
+   *
+   * The current implementation rather generates fluctuations alternating frame-by-frame
+   * depending on the game's and dxvk's CPU-time variations. This might be visible as a loss
+   * in smoothness in games which provide strongly varying frame times. Most games should be fine,
+   * but for example in 'God of War', we measured a prediction error of +/- 3 ms for the
+   * 99% percentiles and up to +/- 2 ms for the 95% percentiles, which is a bit too much.
+   * Smoothing may be a consideration in such a case, but unsuitable smoothing will degrade input feel,
+   * so it's not implemented for now, but more advanced smoothing techniques will be investigated
+   * in the future.
+   *
+   * In some situations however, this low-latency pacing actually presents smoother visuals
+   * than max-frame-latency, because when the prediction error is small, this jitter effect
+   * gets negligible, and it becomes apparent that the generated video progresses more cleanly
+   * in time with regards to medium-term time consistency. In other words, the video playback speed
+   * is more accurate and steady - for the same reasons why input lag consistency is improved.
+   *
+   * Fps limiting is tightly integrated into the frame pacing logic and is highly recommended
+   * to be used in place of most ingame limiters.
+   *
+   * A VRR mode that activates V-Sync is also provided to combine low latency with image clarity.
+   * It's achieved by predictively limiting at the present timeline, respecting v-blanks to
+   * avoid going into V-Sync buffering. This can further be tuned by using the fps limiter at the
+   * same time, which means there are basically two limiters active. The advantage of doing so
+   * is that the "normal" fps limiter isn't affected by prediction errors. Selecting a VRR refresh
+   * rate smaller than the monitor's refresh rate will lower the chance and/or lower the duration
+   * frames will go into V-Sync buffering.
+   *
+   * It further can be fine-tuned via the dxvk.lowLatencyOffset and
+   * dxvk.lowLatencyAllowCpuFramesOverlap config variables.
+   * Compared to maxFrameLatency = 3, render-latency reductions of up to 67% are achieved.
+   */
+
+  class LowLatencyMode : public FramePacerMode {
+    using microseconds = std::chrono::microseconds;
+    using time_point = high_resolution_clock::time_point;
+  public:
+
+    LowLatencyMode(Mode mode, LatencyMarkersStorage* storage, const DxvkOptions& options, uint64_t firstFrameId, int refreshRate = 0)
+    : FramePacerMode(mode, storage, firstFrameId),
+      m_lowLatencyOffset(getLowLatencyOffset(options)),
+      m_allowCpuFramesOverlap(options.lowLatencyAllowCpuFramesOverlap),
+      m_presentationStats(5000),
+      m_gpuProgress(storage) {
+      Logger::info( str::format("  lowLatencyOffset: ", m_lowLatencyOffset) );
+      Logger::info( str::format("  lowLatencyAllowCpuFramesOverlap: ", m_allowCpuFramesOverlap) );
+
+      if (refreshRate > 0) {
+        m_vrrRefreshInterval = 1'000'000 / refreshRate;
+        Logger::info( str::format("  vrr refresh rate: ", refreshRate) );
+      }
+
+    }
+
+    ~LowLatencyMode() {}
+
+    bool getDesiredPresentMode( uint32_t& presentMode ) const override;
+
+    void startFrame( uint64_t frameId ) override {
+
+      using std::chrono::duration_cast;
+
+      if (!m_allowCpuFramesOverlap)
+        m_fenceCsFinished.wait( frameId-1 );
+
+      m_fenceGpuStart.wait( frameId-1 );
+
+      if (m_mode == LOW_LATENCY_VRR)
+        m_fenceFrameFinished.wait( frameId-2 );
+
+      time_point now = high_resolution_clock::now();
+      const LatencyMarkers* m = m_latencyMarkersStorage->getConstMarkers(frameId-1);
+      uint64_t finishedId = m_latencyMarkersStorage->getTimeline()->gpuFinished.load();
+      if (finishedId <= m_firstFrameId+1)
+        return;
+
+      if (finishedId == frameId-1) {
+        // we are the only in-flight frame
+        int32_t delay = getFpsLimiterDelay( m, now );
+        sleepFor( now, delay );
+        return;
+      }
+
+      SyncProps props = getSyncPrediction();
+      int32_t targetGpuTime = props.optimizedGpuTime - props.cpuUntilGpuStart + m_lowLatencyOffset;
+
+      if (m_mode == LOW_LATENCY_VRR) {
+        int32_t vrrDelay = getVrrDelay( frameId, props, now );
+        int32_t vrrGpuTime = vrrDelay - std::max( m->gpuStart, props.cpuUntilGpuStart );
+        targetGpuTime = std::max( targetGpuTime, vrrGpuTime );
+      }
+
+      if (targetGpuTime <= 0) {
+        // we don't track gpu progress, because we start earlier than
+        // when the first submission might be processed by the gpu.
+        // this means, this path is mostly taken when being cpu limited.
+        int32_t gpuDelay = getGpuDelay( props, m, now );
+        int32_t delay = std::max( gpuDelay, getCpuDelay( props, m, now ) );
+        delay = std::max( delay, getFpsLimiterDelay( m, now ) );
+        delay = std::max( delay, getVrrDelay( frameId, props, now ) );
+
+        sleepFor( now, delay );
+        return;
+      }
+
+      time_point lastFrameFinish;
+
+      if (targetGpuTime < props.optimizedGpuTime) {
+        m_gpuProgress.waitUntil( frameId-1, targetGpuTime, props.cpuUntilGpuStart );
+        lastFrameFinish = high_resolution_clock::now()
+          + microseconds(props.optimizedGpuTime - targetGpuTime);
+      }
+      else {
+        if (m_mode == LOW_LATENCY_VRR) {
+          m_fenceFrameFinished.wait( frameId-1 );
+        } else {
+          m_fenceGpuFinished.wait( frameId-1 );
+          lastFrameFinish = high_resolution_clock::now();
+        }
+      }
+
+      props = getSyncPrediction();
+      now = high_resolution_clock::now();
+      int32_t cpuDelay = getCpuDelay( props, m, now );
+      int32_t delay = std::max( cpuDelay, getFpsLimiterDelay( m, now ) );
+      delay = std::max( delay, getVrrDelay( frameId, props, now, lastFrameFinish ) );
+      sleepFor( now, delay );
+
+    }
+
+
+    void notifyGpuReady( uint64_t frameId, time_point t ) override
+      { m_gpuProgress.notifyGpuReady( frameId, t ); }
+
+    void notifyQueueSubmit( uint64_t frameId, time_point t ) override
+      { m_gpuProgress.notifyQueueSubmit( frameId, t ); }
+
+
+    void finishRender( uint64_t frameId ) override {
+
+      using std::chrono::duration_cast;
+      m_gpuProgress.finishRender( frameId );
+      const LatencyMarkers* m = m_latencyMarkersStorage->getConstMarkers(frameId);
+
+      int32_t numLoop = (int32_t)(m->gpuReady.size())-1;
+      if (numLoop <= 1) {
+        m_props[frameId % m_props.size()] = SyncProps();
+        m_props[frameId % m_props.size()].isOutlier = true;
+        m_propsFinished.store( frameId );
+        return;
+      }
+
+      // estimates the optimal overlap for cpu/gpu work by optimizing gpu scheduling first
+      // such that the gpu doesn't go into idle for this frame, and then aligning cpu submits
+      // where gpuSubmit[i] <= gpuRun[i] for all i
+
+      std::vector<int32_t>& gpuRun = m_tempGpuRun;
+      gpuRun.clear();
+      int32_t optimizedGpuTime = 0;
+      gpuRun.push_back(optimizedGpuTime);
+
+      for (int i=0; i<numLoop; ++i) {
+        time_point _gpuRun = std::max( m->gpuReady[i], m->gpuQueueSubmit[i] );
+        int32_t duration = duration_cast<microseconds>( m->gpuReady[i+1] - _gpuRun ).count();
+        optimizedGpuTime += duration;
+        gpuRun.push_back(optimizedGpuTime);
+      }
+
+      int32_t alignment = duration_cast<microseconds>( m->gpuSubmit[numLoop-1] - m->gpuSubmit[0] ).count()
+        - gpuRun[numLoop-1];
+
+      int32_t offset = 0;
+      for (int i=numLoop-2; i>=0; --i) {
+        int32_t curSubmit = duration_cast<microseconds>( m->gpuSubmit[i] - m->gpuSubmit[0] ).count();
+        int32_t diff = curSubmit - gpuRun[i] - alignment;
+        diff = std::max( 0, diff );
+        offset += diff;
+        alignment += diff;
+      }
+
+
+      SyncProps& props = m_props[frameId % m_props.size()];
+      props.gpuSync = gpuRun[numLoop-1];
+      props.cpuUntilGpuSync = offset + duration_cast<microseconds>( m->gpuSubmit[numLoop-1] - m->start ).count();
+      props.cpuUntilGpuStart = props.cpuUntilGpuSync - props.gpuSync;
+      props.optimizedGpuTime = optimizedGpuTime;
+      props.csStart = m->csStart;
+      props.csFinished = m->csFinished;
+      props.isOutlier = isOutlier(frameId);
+
+      m_propsFinished.store( frameId );
+
+    }
+
+
+    void endFrame( uint64_t frameId ) override {
+
+      if (m_mode == LOW_LATENCY_VRR && frameId > m_firstFrameId+1) {
+        const LatencyMarkers* m1 = m_latencyMarkersStorage->getConstMarkers(frameId-1);
+        const LatencyMarkers* m2 = m_latencyMarkersStorage->getConstMarkers(frameId);
+
+        int32_t gpuFinishedInterval = std::chrono::duration_cast<microseconds>(
+          (m2->start + microseconds(m2->gpuFinished)) - (m1->start + microseconds(m1->gpuFinished))).count();
+
+        // only push values where we probably weren't running into v-sync buffering.
+        // otherwise we can get a presentation stats median drift due to feedback loop.
+        if (gpuFinishedInterval >= 0.99 * m_vrrRefreshInterval)
+          m_presentationStats.push( m2->end, m2->presentFinished - m2->gpuFinished );
+      }
+
+    }
+
+
+
+  private:
+
+    struct SyncProps {
+      int32_t optimizedGpuTime;   // gpu executing packed submits in one go
+      int32_t gpuSync;            // gpuStart to this sync point, in microseconds
+      int32_t cpuUntilGpuSync;
+      int32_t cpuUntilGpuStart;
+      int32_t csStart;
+      int32_t csFinished;
+      bool    isOutlier;
+    };
+
+
+    SyncProps getSyncPrediction() const {
+      // In the future we might use more samples to get a prediction.
+      // Possibly this will be optional, as until now, basing it on
+      // just the previous frame gave us the best mouse input feel.
+      // Simple averaging or median filtering is surely not the way
+      // to go, but more advanced methods will be investigated.
+      // Outlier removal has worked out really well though, so that's
+      // what we are using here.
+
+      SyncProps res = {};
+      uint64_t id = m_propsFinished;
+      if (id < m_firstFrameId+7)
+        return res;
+
+      for (size_t i=0; i<7; ++i) {
+        const SyncProps& props = m_props[ (id-i) % m_props.size() ];
+        if (!props.isOutlier) {
+          id = id-i;
+          break;
+        }
+      }
+
+      return m_props[ id % m_props.size() ];
+
+    };
+
+
+    bool isOutlier( uint64_t frameId ) const {
+
+      constexpr int32_t numLoop = 7;
+      int32_t totalCpuTime = 0;
+      for (int32_t i=1; i<numLoop; ++i) {
+        const SyncProps& props = m_props[ (frameId-i) % m_props.size() ];
+        totalCpuTime += props.cpuUntilGpuStart;
+      }
+
+      int32_t avgCpuTime = totalCpuTime / (numLoop-1);
+      const SyncProps& props = m_props[ frameId % m_props.size() ];
+      if (props.cpuUntilGpuStart > 1.3*avgCpuTime)
+        return true;
+
+      return false;
+
+    }
+
+
+    int32_t getGpuDelay( const SyncProps& props, const LatencyMarkers* m, time_point now ) const {
+
+      int32_t lastFrameStart = std::chrono::duration_cast<microseconds>( m->start - now ).count();
+      int32_t gpuReadyPrediction = lastFrameStart
+        + std::max( props.cpuUntilGpuStart, m->gpuStart )
+        + props.optimizedGpuTime;
+
+      int32_t gpuDelay = gpuReadyPrediction - props.cpuUntilGpuStart;
+      return gpuDelay + m_lowLatencyOffset;
+
+    }
+
+
+    int32_t getCpuDelay( const SyncProps& props, const LatencyMarkers* m, time_point now ) const {
+
+      if (!m_allowCpuFramesOverlap)
+        return 0;
+
+      // prevents the cs thread from creating additional latency.
+      // in the future, we should handle this a bit more sophisticatedly, allowing more overlap.
+      int32_t cpuReadyPrediction = std::chrono::duration_cast<microseconds>(
+          m->start + microseconds(props.csFinished) - now).count();
+      int32_t cpuDelay = cpuReadyPrediction - props.csStart;
+      return cpuDelay + m_lowLatencyOffset;
+
+    }
+
+
+    int32_t getFpsLimiterDelay( const LatencyMarkers* m, time_point now ) const {
+
+      int32_t frametime = std::chrono::duration_cast<microseconds>( now - m->start ).count();
+      return std::max( 0, m_fpsLimitFrametime.load() - frametime );
+
+    }
+
+
+    int32_t getVrrDelay( uint64_t frameId, const SyncProps& props, const time_point& now, const time_point& lastFrameFinish = time_point{} ) {
+
+      if (m_mode != LOW_LATENCY_VRR)
+        return 0;
+
+      // Presentation latency should be fairly stable, but drivers may report back
+      // different levels of latency (Nvidia reports very low latencies on x11 flip compared
+      // to Wayland). We take the median within a recent time window to adjust to that.
+
+      // Presentation latency may vary though for other reasons, like when compiling shaders
+      // on all cpu cores, we will get thread starvation and higher latency.
+
+      int32_t presentLatency = m_presentationStats.getMedian( frameId );
+      uint64_t frameFinishedId = m_latencyMarkersStorage->getTimeline()->frameFinished.load();
+      int32_t lastVBlank = std::chrono::duration_cast<microseconds> (
+        m_latencyMarkersStorage->getConstMarkers(frameFinishedId)->end - now).count()
+        - presentLatency;
+      int32_t targetVBlank = lastVBlank + (frameId-frameFinishedId) * m_vrrRefreshInterval;
+
+      // set last v-blank if we have more information about the last frame
+      if (frameFinishedId != frameId-1 && lastFrameFinish != time_point{} ) {
+        assert( frameFinishedId == frameId-2 );
+        int32_t vBlank = std::chrono::duration_cast<microseconds> (lastFrameFinish - now).count();
+        lastVBlank += m_vrrRefreshInterval;
+        lastVBlank = std::max( lastVBlank, vBlank );
+        targetVBlank = lastVBlank + m_vrrRefreshInterval;
+      }
+
+      int32_t expectedFrameLatency = props.cpuUntilGpuStart + props.optimizedGpuTime;
+      return targetVBlank - expectedFrameLatency;
+
+    }
+
+
+    void sleepFor( const Sleep::TimePoint t, int32_t delay ) {
+
+      if (delay <= 0)
+        return;
+
+      int32_t maxDelay = std::max( m_fpsLimitFrametime.load(), 20000 );
+      delay = std::min( delay, maxDelay );
+
+      Sleep::TimePoint t2 = t + microseconds(delay);
+      Sleep::sleepUntil( t, t2 );
+
+    }
+
+
+    int32_t getLowLatencyOffset( const DxvkOptions& options );
+    bool getLowLatencyAllowCpuFramesOverlap( const DxvkOptions& options );
+
+    const int32_t m_lowLatencyOffset;
+    const bool    m_allowCpuFramesOverlap;
+
+    int32_t m_vrrRefreshInterval = { 0 };
+    LatencyStats m_presentationStats;
+
+    std::array<SyncProps, 16> m_props = { };
+    std::atomic<uint64_t> m_propsFinished = { 0 };
+
+    std::vector<int32_t>  m_tempGpuRun;
+
+    GpuProgress m_gpuProgress;
+
+  };
+
+}
diff --git a/src/dxvk/framepacer/dxvk_framepacer_mode_min_latency.h b/src/dxvk/framepacer/dxvk_framepacer_mode_min_latency.h
new file mode 100644
index 0000000..7fc50fb
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_framepacer_mode_min_latency.h
@@ -0,0 +1,46 @@
+#pragma once
+
+#include "dxvk_framepacer_mode.h"
+
+namespace dxvk {
+
+  /*
+   * Minimal latency is achieved here by waiting for the previous
+   * frame to complete, which results in very much reduced fps.
+   * Generally not recommended, but helpful to get insights to fine-tune
+   * the low-latency mode, and possibly is useful for running games
+   * in the cpu limit.
+   */
+
+  class MinLatencyMode : public FramePacerMode {
+
+  public:
+
+    MinLatencyMode(Mode mode, LatencyMarkersStorage* storage, uint64_t firstFrameId)
+    : FramePacerMode(mode, storage, firstFrameId, 0) {}
+
+    ~MinLatencyMode() {}
+
+    void startFrame( uint64_t frameId ) override {
+
+      Sleep::TimePoint now = high_resolution_clock::now();
+      int32_t frametime = std::chrono::duration_cast<std::chrono::microseconds>(
+        now - m_lastStart ).count();
+      int32_t frametimeDiff = std::max( 0, m_fpsLimitFrametime.load() - frametime );
+      int32_t delay = std::max( 0, frametimeDiff );
+      int32_t maxDelay = std::max( m_fpsLimitFrametime.load(), 20000 );
+      delay = std::min( delay, maxDelay );
+
+      Sleep::TimePoint nextStart = now + std::chrono::microseconds(delay);
+      Sleep::sleepUntil( now, nextStart );
+      m_lastStart = nextStart;
+
+    }
+
+  private:
+
+    Sleep::TimePoint m_lastStart = { high_resolution_clock::now() };
+
+  };
+
+}
diff --git a/src/dxvk/framepacer/dxvk_gpu_progress.h b/src/dxvk/framepacer/dxvk_gpu_progress.h
new file mode 100644
index 0000000..c23bd3a
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_gpu_progress.h
@@ -0,0 +1,232 @@
+#pragma once
+
+#include <atomic>
+#include <stdint.h>
+#include "dxvk_latency_markers.h"
+#include "../../util/log/log.h"
+#include "../../util/util_string.h"
+
+
+namespace dxvk {
+
+  /*
+   * Keeps track of GPU submit processing in realtime to improve frame pacing.
+   * This has been shown in testing to reduce the variance for the prediction error
+   * (prediction vs. actual) with respect to when a frame will finish, as more
+   * recent information is available, compared to doing the prediction when the
+   * frame starts or when the GPU starts processing the first submit.
+   */
+
+  class GpuProgress {
+
+    using microseconds = std::chrono::microseconds;
+    using time_point = high_resolution_clock::time_point;
+
+  public:
+
+    GpuProgress( const LatencyMarkersStorage* storage )
+    : m_markerStorage(storage) { }
+
+
+    void notifyGpuReady( uint64_t frameId, time_point t ) {
+
+      Data* data = getData(frameId);
+      Submits expected = data->submits.load();
+      Submits desired;
+
+      if (expected.numSubmitsFinished != 0)
+        endSubmit( frameId, t );
+
+      do {
+        desired = expected;
+        desired.numSubmitsFinished++;
+      } while (!data->submits.compare_exchange_strong( expected, desired ));
+
+      if (desired.numSubmitsFinished <= desired.numSubmitsQueued)
+        startSubmit( frameId, desired.numSubmitsFinished, t );
+
+    }
+
+
+    void notifyQueueSubmit( uint64_t frameId, time_point t ) {
+
+      Data* data = getData(frameId);
+      Submits expected = data->submits.load();
+      Submits desired;
+
+      do {
+        desired = expected;
+        desired.numSubmitsQueued++;
+      } while (!data->submits.compare_exchange_strong( expected, desired ));
+
+      if (desired.numSubmitsFinished == desired.numSubmitsQueued)
+        startSubmit( frameId, desired.numSubmitsQueued, t );
+
+    }
+
+
+    void finishRender( uint64_t frameId ) {
+
+      Data* data = getData(frameId);
+      data->isFinished = true;
+
+      // frameId+1 should already have received a gpuReady notification
+      // so clear the frame after that within the ring buffer
+      Data* dataNext = getData(frameId+2);
+      dataNext->isFinished.store( false );
+      dataNext->gpuRuntime.store( GpuRuntime{} );
+      dataNext->submits.store( Submits{} );
+
+    }
+
+
+    void waitUntil( uint64_t frameId, int32_t targetGpuRuntime, int32_t cpuUntilGpuStart ) const {
+      // GPU progress is measured as if the submits would be processed as late as possible
+      // on the GPU while assuming the frame to be minimum latency since gpuStart.
+      // This is necessary for this to work reliably accross games.
+
+      using std::chrono::duration_cast;
+      const Data* data = getConstData(frameId);
+      const LatencyMarkers* m = m_markerStorage->getConstMarkers(frameId);
+
+      // Sleep until the earlierst possible time stamp
+
+      auto now = high_resolution_clock::now();
+      int32_t totalTime = duration_cast<microseconds>(now - m->start).count();
+      cpuUntilGpuStart = std::max( cpuUntilGpuStart, m->gpuStart );
+      int32_t sleepUntil = cpuUntilGpuStart + targetGpuRuntime;
+      int32_t sleepDelay = std::max( 0, sleepUntil - totalTime );
+
+      Sleep::TimePoint t = now + microseconds(sleepDelay);
+      Sleep::sleepUntil( now, t );
+
+      // For the remainder of the frame we check the progress by polling.
+      // Usually this will take far less than a millisecond, with the exception
+      // of very slow frames where GPU progress is stalled.
+
+      while (true) {
+
+        int32_t gpuRuntime = getGpuRuntime( frameId, cpuUntilGpuStart );
+        if (gpuRuntime >= targetGpuRuntime)
+          break;
+        if (data->isFinished)
+          break;
+        pause();
+
+      }
+
+    }
+
+
+    int32_t getGpuRuntime( uint64_t frameId, int32_t cpuUntilGpuStart ) const {
+
+      using std::chrono::duration_cast;
+      const Data* data = getConstData(frameId);
+      GpuRuntime gpuTime = data->gpuRuntime.load();
+      const LatencyMarkers* m = m_markerStorage->getConstMarkers(frameId);
+
+      auto now = high_resolution_clock::now();
+      int32_t curTime = duration_cast<microseconds>(now - m->start).count();
+
+      int32_t gpuRuntime = gpuTime.runtime;
+      if (gpuTime.curSubmitStart != 0)
+        gpuRuntime += curTime - gpuTime.curSubmitStart;
+
+      int32_t gpuIdle = curTime - gpuRuntime;
+      gpuRuntime -= std::max( 0, cpuUntilGpuStart - gpuIdle );
+      return gpuRuntime;
+
+    }
+
+
+  private:
+
+
+    void startSubmit( uint64_t frameId, uint16_t numSubmits, time_point t ) {
+      // This is analog to start = std::max( m->gpuReady[i], m->gpuQueueSubmit[i] )
+      // Testing has shown that the way we do it here might sometimes diverge from this - very slightly,
+      // depending on in which order the messages arrive here, but we cannot access
+      // the above variables safely here in real-time.
+
+      using std::chrono::duration_cast;
+      Data* data = getData(frameId);
+      const LatencyMarkers* m = m_markerStorage->getConstMarkers(frameId);
+      GpuRuntime gpuRuntime = data->gpuRuntime.load();
+
+      // this shouldn't happen, but if it does, we will get informed
+      if (unlikely(gpuRuntime.curSubmitStart != 0)) {
+        Logger::err( "internal error: GpuProgress startSubmit() before endSubmit()" );
+      }
+
+      // store the starting timestamp this way so we can use an atomic
+      int32_t submitStart = duration_cast<microseconds>(t - m->start).count();
+      gpuRuntime.curSubmitStart = submitStart;
+      data->gpuRuntime.store( gpuRuntime );
+
+    }
+
+
+    void endSubmit( uint64_t frameId, time_point t) {
+
+      using std::chrono::duration_cast;
+      const LatencyMarkers* m = m_markerStorage->getConstMarkers(frameId);
+      Data* data = getData(frameId);
+      GpuRuntime gpuRuntime = data->gpuRuntime.load();
+
+      int32_t submitEnd = duration_cast<microseconds>(t - m->start).count();
+      int32_t diff = submitEnd - gpuRuntime.curSubmitStart;
+      gpuRuntime.runtime += diff;
+      gpuRuntime.curSubmitStart = 0;
+
+      data->gpuRuntime.store(gpuRuntime);
+
+    }
+
+
+    static void pause() {
+
+      #if defined(DXVK_ARCH_X86)
+      _mm_pause();
+      #elif defined(DXVK_ARCH_ARM64)
+      __asm__ __volatile__ ("yield");
+      #else
+      /* Do nothing (busy-loop). Please add more #elif above here if
+       * your CPU architecture has a suitable pause/yield instruction */
+      #endif
+
+    }
+
+
+    struct Submits {
+      uint32_t numSubmitsQueued       = { 0 };
+      uint32_t numSubmitsFinished     = { 0 };
+    };
+
+    struct GpuRuntime {
+      int32_t curSubmitStart          = { 0 };
+      int32_t runtime                 = { 0 };
+    };
+
+    struct Data {
+      std::atomic<Submits> submits         = { };
+      std::atomic<GpuRuntime> gpuRuntime   = { };
+      std::atomic<bool> isFinished         = { false };
+    };
+
+    Data* getData( uint32_t frameId ) {
+      return &m_data[ frameId % NUM_DATA ];
+    }
+
+    const Data* getConstData( uint32_t frameId ) const {
+      return &m_data[ frameId % NUM_DATA ];
+    }
+
+    constexpr static int32_t NUM_DATA = 4;
+    std::array< Data, NUM_DATA > m_data = { };
+
+    const LatencyMarkersStorage* m_markerStorage;
+
+  };
+
+}
+
diff --git a/src/dxvk/framepacer/dxvk_latency_markers.h b/src/dxvk/framepacer/dxvk_latency_markers.h
new file mode 100644
index 0000000..35ee6db
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_latency_markers.h
@@ -0,0 +1,149 @@
+#pragma once
+
+#include <atomic>
+#include <vector>
+#include <array>
+#include <assert.h>
+#include "../../util/util_sleep.h"
+#include "../../util/log/log.h"
+#include "../../util/util_string.h"
+
+
+namespace dxvk {
+
+  class FramePacer;
+  class LatencyMarkersStorage;
+
+
+  struct LatencyMarkers {
+
+    using time_point = high_resolution_clock::time_point;
+
+    time_point start;
+    time_point end;
+
+    int32_t csStart;
+    int32_t csFinished;
+    int32_t cpuFinished;
+    int32_t gpuStart;
+    int32_t gpuFinished;
+    int32_t presentFinished;
+
+    std::vector<time_point> gpuReady;
+    std::vector<time_point> gpuSubmit;
+    std::vector<time_point> gpuQueueSubmit;
+
+  };
+
+
+  /*
+   * stores which information is accessible for which frame
+   */
+  struct LatencyMarkersTimeline {
+
+    std::atomic<uint64_t> cpuFinished   = { 0 };
+    std::atomic<uint64_t> gpuStart      = { 0 };
+    std::atomic<uint64_t> gpuFinished   = { 0 };
+    std::atomic<uint64_t> frameFinished = { 0 };
+
+  };
+
+
+  class LatencyMarkersReader {
+
+  public:
+
+    LatencyMarkersReader( const LatencyMarkersStorage* storage, uint32_t numEntries );
+    bool getNext( const LatencyMarkers*& result );
+
+  private:
+
+    const LatencyMarkersStorage* m_storage;
+    uint64_t m_index;
+
+  };
+
+
+  class LatencyMarkersStorage {
+    friend class LatencyMarkersReader;
+    friend class FramePacer;
+  public:
+
+    LatencyMarkersStorage( uint64_t firstFrameId )
+    : m_firstFrameId(firstFrameId) { }
+    ~LatencyMarkersStorage() { }
+
+    LatencyMarkersReader getReader( uint32_t numEntries ) const {
+      return LatencyMarkersReader(this, numEntries);
+    }
+
+    void registerFrameStart( uint64_t frameId ) {
+      if (unlikely(frameId <= m_timeline.frameFinished.load())) {
+        Logger::warn( str::format("internal error during registerFrameStart: expected frameId=",
+          m_timeline.frameFinished.load()+1, ", got: ", frameId) );
+      }
+      auto now = high_resolution_clock::now();
+
+      LatencyMarkers* markers = getMarkers(frameId);
+      markers->start = now;
+    }
+
+    void registerFrameEnd( uint64_t frameId ) {
+      if (unlikely(frameId <= m_timeline.frameFinished.load())) {
+        Logger::warn( str::format("internal error during registerFrameEnd: expected frameId=",
+          m_timeline.frameFinished.load()+1, ", got: ", frameId) );
+      }
+      auto now = high_resolution_clock::now();
+
+      LatencyMarkers* markers = getMarkers(frameId);
+      markers->presentFinished = std::chrono::duration_cast<std::chrono::microseconds>(
+        now - markers->start).count();
+      markers->end = now;
+
+      m_timeline.frameFinished.store(frameId);
+    }
+
+    const LatencyMarkersTimeline* getTimeline() const {
+      return &m_timeline;
+    }
+
+    const LatencyMarkers* getConstMarkers( uint64_t frameId ) const {
+      return &m_markers[frameId % m_numMarkers];
+    }
+
+
+  private:
+
+    LatencyMarkers* getMarkers( uint64_t frameId ) {
+      return &m_markers[frameId % m_numMarkers];
+    }
+
+    // simple modulo hash mapping is used for frameIds. They are expected to monotonically increase by one.
+    // select the size large enough, so we never come into a situation where the reader cannot keep up with the producer
+    static constexpr uint16_t m_numMarkers = 128;
+    const uint64_t m_firstFrameId;
+    std::array<LatencyMarkers, m_numMarkers> m_markers = { };
+    LatencyMarkersTimeline m_timeline;
+
+  };
+
+
+
+  inline LatencyMarkersReader::LatencyMarkersReader( const LatencyMarkersStorage* storage, uint32_t numEntries )
+  : m_storage(storage) {
+    m_index = 0;
+    if (m_storage->m_timeline.frameFinished.load() > numEntries + storage->m_firstFrameId + 2)
+      m_index = m_storage->m_timeline.frameFinished.load() - numEntries;
+  }
+
+
+  inline bool LatencyMarkersReader::getNext( const LatencyMarkers*& result ) {
+    if (m_index == 0 || m_index > m_storage->m_timeline.frameFinished.load())
+      return false;
+
+    result = &m_storage->m_markers[m_index % m_storage->m_numMarkers];
+    m_index++;
+    return true;
+  }
+
+}
diff --git a/src/dxvk/framepacer/dxvk_latency_stats.h b/src/dxvk/framepacer/dxvk_latency_stats.h
new file mode 100644
index 0000000..5ecdf70
--- /dev/null
+++ b/src/dxvk/framepacer/dxvk_latency_stats.h
@@ -0,0 +1,112 @@
+#pragma once
+
+#include <stdint.h>
+#include <array>
+#include <atomic>
+#include <deque>
+#include <assert.h>
+
+#include "../../util/util_time.h"
+
+
+namespace dxvk {
+
+  class LatencyStats {
+
+  public:
+
+    using time_point = high_resolution_clock::time_point;
+
+    LatencyStats( int32_t duration_ms ) : m_duration(duration_ms) { }
+
+    void push( time_point t, int32_t latency ) {
+
+      int32_t index = getBucketIndex(latency);
+
+      ++m_buckets[index];
+      ++m_numLatencies;
+
+      QueueItem item;
+      item.timeStamp = t;
+      item.latency   = latency;
+
+      m_queue.push_back(item);
+
+      // remove old items from the queue
+      while (!m_queue.empty() && m_queue.front().timeStamp
+        < high_resolution_clock::now() - std::chrono::milliseconds(m_duration) ) {
+        index = getBucketIndex(m_queue.front().latency);
+        --m_buckets[index];
+        --m_numLatencies;
+        m_queue.pop_front();
+      }
+
+    }
+
+
+    int32_t getMedian( uint64_t frameId ) {
+
+      // use a cache so we can efficiently call this multiple times per frame
+      if (frameId == 0 || m_cachedMedian.frameId == frameId)
+        return m_cachedMedian.median;
+
+      int32_t median = getPercentile(0.5);
+
+      m_cachedMedian.frameId = frameId;
+      m_cachedMedian.median  = median;
+
+      return median;
+
+    }
+
+
+    int32_t getPercentile( float p ) const {
+
+      assert( p >= 0 && p <= 1 );
+
+      uint64_t targetCount = m_numLatencies * p;
+      uint64_t count = 0;
+      size_t index = 0;
+      while (count < targetCount && index < m_buckets.size()) {
+        count += m_buckets[index];
+        ++index;
+      }
+
+      if (index > 0) --index;
+      return index * 8;
+
+    }
+
+
+  private:
+
+    int getBucketIndex( int32_t latency ) const {
+      assert( latency >= 0 );
+      size_t index = latency / 8;
+      return std::min( m_buckets.size()-1, index );
+    }
+
+    constexpr static int32_t maxLatency = 5000;
+    const int32_t m_duration;
+
+    std::array< std::atomic<int64_t>, 1+(maxLatency / 8) > m_buckets = { };
+    std::atomic< int64_t > m_numLatencies = { 0 };
+
+    struct QueueItem {
+      time_point timeStamp;
+      int32_t    latency;
+    };
+
+    // must only be accessed from one thread
+    std::deque< QueueItem > m_queue;
+
+    struct CachedMedian {
+      uint64_t frameId;
+      int32_t  median;
+    };
+
+    CachedMedian m_cachedMedian = { };
+
+  };
+
+}
diff --git a/src/dxvk/hud/dxvk_hud.h b/src/dxvk/hud/dxvk_hud.h
index 1b8f947..4e00ead 100644
--- a/src/dxvk/hud/dxvk_hud.h
+++ b/src/dxvk/hud/dxvk_hud.h
@@ -59,6 +59,11 @@ namespace dxvk::hud {
     Rc<T> addItem(const char* name, int32_t at, Args... args) {
       return m_hudItems.add<T>(name, at, std::forward<Args>(args)...);
     }
+
+    template<typename T>
+    int32_t getItemPos() {
+      return m_hudItems.getItemPos<T>();
+    }
     
     /**
      * \brief Creates the HUD
diff --git a/src/dxvk/hud/dxvk_hud_item.cpp b/src/dxvk/hud/dxvk_hud_item.cpp
index 0c1f431..5f63d8a 100644
--- a/src/dxvk/hud/dxvk_hud_item.cpp
+++ b/src/dxvk/hud/dxvk_hud_item.cpp
@@ -104,7 +104,7 @@ namespace dxvk::hud {
           HudRenderer&        renderer,
           HudPos              position) {
     position.y += 16;
-    renderer.drawText(16, position, 0xffffffffu, "DXVK " DXVK_VERSION);
+    renderer.drawText(16, position, 0xffffffffu, "DXVK-GPLALL " DXVK_VERSION);
 
     position.y += 8;
     return position;
@@ -147,8 +147,8 @@ namespace dxvk::hud {
       driverInfo = props.driverVersion.toString();
 
     m_deviceName = props.core.properties.deviceName;
-    m_driverName = str::format("Driver:  ", props.vk12.driverName);
-    m_driverVer = str::format("Version: ", driverInfo);
+    m_driverName = str::format("Drv: ", props.vk12.driverName);
+    m_driverVer = str::format("Inf: ", driverInfo);
   }
 
 
diff --git a/src/dxvk/hud/dxvk_hud_item.h b/src/dxvk/hud/dxvk_hud_item.h
index e75c460..83ad3ea 100644
--- a/src/dxvk/hud/dxvk_hud_item.h
+++ b/src/dxvk/hud/dxvk_hud_item.h
@@ -131,6 +131,15 @@ namespace dxvk::hud {
       return value;
     }
 
+    template<typename T>
+    int32_t getItemPos() {
+      for (int i=0; i<(int)m_items.size(); ++i) {
+        if (dynamic_cast<T*>(m_items[i].ptr()))
+          return i;
+      }
+      return -1;
+    }
+
   private:
 
     bool                                          m_enableFull = false;
@@ -244,6 +253,86 @@ namespace dxvk::hud {
   };
 
 
+   /**
+   * \brief HUD item to display render latency
+   */
+  class HudRenderLatencyItem : public HudItem {
+    constexpr static int64_t UpdateInterval = 500'000;
+  public:
+
+    HudRenderLatencyItem();
+
+    ~HudRenderLatencyItem();
+
+    void updateLatencyTracker( const Rc<DxvkLatencyTracker>& tracker ) {
+      m_tracker = tracker;
+    }
+
+    void update(dxvk::high_resolution_clock::time_point time);
+
+    HudPos render(
+      const Rc<DxvkCommandList>&ctx,
+      const HudPipelineKey&     key,
+      const HudOptions&         options,
+            HudRenderer&        renderer,
+            HudPos              position);
+
+  private:
+
+    Rc<DxvkLatencyTracker> m_tracker;
+
+    dxvk::high_resolution_clock::time_point m_lastUpdate
+      = dxvk::high_resolution_clock::now();
+
+    std::string m_latency;
+
+  };
+
+
+  /**
+   * \brief HUD item to display latency details, buffers, etc.
+   */
+  class HudLatencyDetailsItem : public HudItem {
+    constexpr static int64_t UpdateInterval = 500'000;
+  public:
+
+    HudLatencyDetailsItem();
+
+    ~HudLatencyDetailsItem();
+
+    void updateLatencyTracker( const Rc<DxvkLatencyTracker>& tracker ) {
+      m_tracker = tracker;
+    }
+
+    void update(dxvk::high_resolution_clock::time_point time);
+
+    HudPos render(
+      const Rc<DxvkCommandList>&ctx,
+      const HudPipelineKey&     key,
+      const HudOptions&         options,
+            HudRenderer&        renderer,
+            HudPos              position);
+
+  private:
+
+    Rc<DxvkLatencyTracker> m_tracker;
+
+    dxvk::high_resolution_clock::time_point m_lastUpdate
+      = dxvk::high_resolution_clock::now();
+
+    std::string m_gpuP50;
+    std::string m_gpuP75;
+    std::string m_gpuP95;
+    std::string m_gpuP99;
+
+    std::string m_presentP50;
+    std::string m_presentP75;
+    std::string m_presentP95;
+    std::string m_presentP99;
+
+  };
+
+
   /**
    * \brief HUD item to display the frame rate
    */
diff --git a/src/dxvk/hud/dxvk_hud_item_latency.cpp b/src/dxvk/hud/dxvk_hud_item_latency.cpp
new file mode 100644
index 0000000..8b3eb2b
--- /dev/null
+++ b/src/dxvk/hud/dxvk_hud_item_latency.cpp
@@ -0,0 +1,153 @@
+#include "dxvk_hud_item.h"
+#include "../framepacer/dxvk_framepacer.h"
+
+namespace dxvk::hud {
+
+  HudRenderLatencyItem::HudRenderLatencyItem() { }
+  HudRenderLatencyItem::~HudRenderLatencyItem() { }
+
+  void HudRenderLatencyItem::update(dxvk::high_resolution_clock::time_point time) {
+    const Rc<DxvkLatencyTracker> tracker = m_tracker;
+    const FramePacer* framePacer = dynamic_cast<FramePacer*>( tracker.ptr() );
+    if (!framePacer)
+      return;
+
+    auto elapsed = std::chrono::duration_cast<std::chrono::microseconds>(time - m_lastUpdate);
+
+    if (elapsed.count() >= UpdateInterval) {
+      m_lastUpdate = time;
+
+      LatencyMarkersReader reader = framePacer->m_latencyMarkersStorage.getReader(100);
+      const LatencyMarkers* markers;
+      uint32_t count = 0;
+      uint64_t totalLatency = 0;
+      while (reader.getNext(markers)) {
+        totalLatency += markers->gpuFinished;
+        ++count;
+      }
+
+      if (!count)
+        return;
+
+      uint64_t latency = totalLatency / count;
+      m_latency = str::format(latency / 1000, ".", (latency/100) % 10, " ms");
+    }
+  }
+
+
+  HudPos HudRenderLatencyItem::render(
+    const Rc<DxvkCommandList>&ctx,
+    const HudPipelineKey&     key,
+    const HudOptions&         options,
+          HudRenderer&        renderer,
+          HudPos              position) {
+
+    position.y += 12;
+    renderer.drawText(16, position, 0xff4040ffu, "Render latency:");
+    renderer.drawText(16, { position.x + 195, position.y },
+      0xffffffffu, m_latency);
+
+    position.y += 8;
+    return position;
+  }
+
+
+  HudLatencyDetailsItem::HudLatencyDetailsItem() { }
+  HudLatencyDetailsItem::~HudLatencyDetailsItem() { }
+
+  void HudLatencyDetailsItem::update(dxvk::high_resolution_clock::time_point time) {
+
+    const Rc<DxvkLatencyTracker> tracker = m_tracker;
+    FramePacer* framePacer = dynamic_cast<FramePacer*>( tracker.ptr() );
+    if (!framePacer)
+      return;
+
+    if (!framePacer->m_enableGpuBufferTracking)
+      framePacer->m_enableGpuBufferTracking.store(true);
+    if (!framePacer->m_enableVSyncBufferTracking && framePacer->getFramePacerMode()->getPresentMode() == VK_PRESENT_MODE_FIFO_KHR)
+      framePacer->m_enableVSyncBufferTracking.store(true);
+
+    auto elapsed = std::chrono::duration_cast<std::chrono::microseconds>(time - m_lastUpdate);
+
+    if (elapsed.count() >= UpdateInterval) {
+      m_lastUpdate = time;
+
+      const LatencyStats* gpuBufferStats = framePacer->getGpuBufferStats();
+      if (gpuBufferStats) {
+        int32_t p50 = gpuBufferStats->getPercentile(0.5);
+        int32_t p75 = gpuBufferStats->getPercentile(0.75);
+        int32_t p95 = gpuBufferStats->getPercentile(0.95);
+        int32_t p99 = gpuBufferStats->getPercentile(0.99);
+        m_gpuP50 = str::format(p50);
+        m_gpuP75 = str::format(p75);
+        m_gpuP95 = str::format(p95);
+        m_gpuP99 = str::format(p99);
+      }
+
+      if (framePacer->getFramePacerMode()->getPresentMode() == VK_PRESENT_MODE_FIFO_KHR
+        && (framePacer->getMode() || std::chrono::duration_cast<std::chrono::milliseconds>(
+          high_resolution_clock::now() - FpsLimiter::m_lastActive.load()).count() > 3000) ) {
+        const LatencyStats* presentStats = framePacer->getPresentStats();
+        if (presentStats) {
+          int32_t p50 = presentStats->getPercentile(0.5);
+          int32_t p75 = presentStats->getPercentile(0.75);
+          int32_t p95 = presentStats->getPercentile(0.95);
+          int32_t p99 = presentStats->getPercentile(0.99);
+          m_presentP50 = str::format(p50);
+          m_presentP75 = str::format(p75);
+          m_presentP95 = str::format(p95);
+          m_presentP99 = str::format(p99);
+        }
+      } else {
+        m_presentP50 = "";
+      }
+
+    }
+  }
+
+
+  HudPos HudLatencyDetailsItem::render(
+    const Rc<DxvkCommandList>&ctx,
+    const HudPipelineKey&     key,
+    const HudOptions&         options,
+          HudRenderer&        renderer,
+          HudPos              position) {
+
+    constexpr int w = 12;
+    position.y += 12;
+
+    renderer.drawText(16, position, 0xff40ffffu, "GPU Buffer (us):");
+    position.y += 16;
+    int x = 2 * w;
+
+    renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p50"); x += 4*w;
+    renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_gpuP50); x += (m_gpuP50.size()+1)*w;
+    renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p75"); x += 4*w;
+    renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_gpuP75); x += (m_gpuP75.size()+1)*w;
+    renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p95"); x += 4*w;
+    renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_gpuP95); x += (m_gpuP95.size()+1)*w;
+    renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p99"); x += 4*w;
+    renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_gpuP99);
+
+    if (!m_presentP50.empty()) {
+      position.y += 18;
+      renderer.drawText(16, position, 0xff40ffffu, "V-Sync Buffer (us):");
+      position.y += 16;
+      x = 2 * w;
+
+      renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p50"); x += 4*w;
+      renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_presentP50); x += (m_presentP50.size()+1)*w;
+      renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p75"); x += 4*w;
+      renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_presentP75); x += (m_presentP75.size()+1)*w;
+      renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p95"); x += 4*w;
+      renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_presentP95); x += (m_presentP95.size()+1)*w;
+      renderer.drawText(16, { position.x + x, position.y }, 0xff40ffffu, "p99"); x += 4*w;
+      renderer.drawText(16, { position.x + x, position.y }, 0xffffffffu, m_presentP99);
+    }
+
+    position.y += 8;
+    return position;
+  }
+
+
+}
diff --git a/src/dxvk/meson.build b/src/dxvk/meson.build
index 5812c1b..9b5e0b8 100644
--- a/src/dxvk/meson.build
+++ b/src/dxvk/meson.build
@@ -118,6 +118,7 @@ dxvk_src = [
   'dxvk_signal.cpp',
   'dxvk_sparse.cpp',
   'dxvk_staging.cpp',
+  'dxvk_state_cache.cpp',
   'dxvk_stats.cpp',
   'dxvk_swapchain_blitter.cpp',
   'dxvk_unbound.cpp',
@@ -126,7 +127,11 @@ dxvk_src = [
   'hud/dxvk_hud.cpp',
   'hud/dxvk_hud_font.cpp',
   'hud/dxvk_hud_item.cpp',
+  'hud/dxvk_hud_item_latency.cpp',
   'hud/dxvk_hud_renderer.cpp',
+
+  'framepacer/dxvk_framepacer.cpp',
+  'framepacer/dxvk_framepacer_mode_low_latency.cpp',
 ]
 
 if platform == 'windows'
diff --git a/src/util/config/config.cpp b/src/util/config/config.cpp
index d6c379b..5106a17 100644
--- a/src/util/config/config.cpp
+++ b/src/util/config/config.cpp
@@ -117,6 +117,10 @@ namespace dxvk {
     { R"(\\nioh\.exe$)", {{
       { "d3d9.deferSurfaceCreation",        "True" },
     }} },
+    /* Anno 2205: Random crashes with state cache */
+    { R"(\\anno2205\.exe$)", {{
+      { "dxvk.enableStateCache",            "False" },
+    }} },
     /* Anno 1800: Poor performance without this   */
     { R"(\\Anno1800\.exe$)", {{
       { "d3d11.cachedDynamicResources",        "c" },
@@ -1672,8 +1676,19 @@ namespace dxvk {
     // Open the file if it exists
     std::ifstream stream(str::topath(filePath.c_str()).c_str());
 
-    if (!stream && confLine.empty())
-      return config;
+    if (!stream && confLine.empty()) {
+      filePath = "/home/" + env::getEnvVar("USER") + "/.config/dxvk.conf";
+      stream.open(str::topath(filePath.c_str()).c_str());
+#ifdef _WIN32
+      if (!stream) {
+		    filePath = env::getEnvVar("APPDATA") + "/dxvk.conf";
+        stream.open(str::topath(filePath.c_str()).c_str());
+      }
+#endif
+
+		  if (!stream)
+			  return config;
+    }
 
     // Initialize parser context
     ConfigContext ctx;
diff --git a/src/util/util_flush.cpp b/src/util/util_flush.cpp
index 66b1e36..1a094bb 100644
--- a/src/util/util_flush.cpp
+++ b/src/util/util_flush.cpp
@@ -2,6 +2,10 @@
 
 namespace dxvk {
 
+  std::atomic<uint32_t> GpuFlushTracker::m_minPendingSubmissions = { 2 };
+  std::atomic<uint32_t> GpuFlushTracker::m_minChunkCount         = { 3 };
+  std::atomic<uint32_t> GpuFlushTracker::m_maxChunkCount         = { 20 };
+
   GpuFlushTracker::GpuFlushTracker(GpuFlushType maxType)
   : m_maxType(maxType) {
 
@@ -11,10 +15,6 @@ namespace dxvk {
           GpuFlushType          flushType,
           uint64_t              chunkId,
           uint32_t              lastCompleteSubmissionId) {
-    constexpr uint32_t minPendingSubmissions = 2;
-
-    constexpr uint32_t minChunkCount =  3u;
-    constexpr uint32_t maxChunkCount = 20u;
 
     // Do not flush if there is nothing to flush
     uint32_t chunkCount = uint32_t(chunkId - m_lastFlushChunkId);
@@ -42,13 +42,13 @@ namespace dxvk {
 
       case GpuFlushType::ImplicitStrongHint: {
         // Flush aggressively with a strong hint to reduce readback latency.
-        return chunkCount >= minChunkCount;
+        return chunkCount >= m_minChunkCount;
       }
 
       case GpuFlushType::ImplicitWeakHint: {
         // Aim for a higher number of chunks per submission with
         // a weak hint in order to avoid submitting too often.
-        if (chunkCount < 2 * minChunkCount)
+        if (chunkCount < 2 * m_minChunkCount)
           return false;
 
         // Actual heuristic is shared with synchronization commands
@@ -59,13 +59,13 @@ namespace dxvk {
         // required if the application is spinning on a query or resource.
         uint32_t pendingSubmissions = uint32_t(m_lastFlushSubmissionId - lastCompleteSubmissionId);
 
-        if (pendingSubmissions < minPendingSubmissions)
+        if (pendingSubmissions < m_minPendingSubmissions)
           return true;
 
         // Use the number of pending submissions to decide whether to flush. Other
         // than ignoring the minimum chunk count condition, we should treat this
         // the same as weak hints to avoid unnecessary synchronization.
-        uint32_t threshold = std::min(maxChunkCount, pendingSubmissions * minChunkCount);
+        uint32_t threshold = std::min(m_maxChunkCount.load(), pendingSubmissions * m_minChunkCount.load());
         return chunkCount >= threshold;
       }
 
diff --git a/src/util/util_flush.h b/src/util/util_flush.h
index fb069cf..6ea94f6 100644
--- a/src/util/util_flush.h
+++ b/src/util/util_flush.h
@@ -3,6 +3,7 @@
 #include <cstddef>
 #include <cstdint>
 #include <vector>
+#include <atomic>
 
 namespace dxvk {
 
@@ -77,6 +78,10 @@ namespace dxvk {
             uint64_t              chunkId,
             uint64_t              submissionId);
 
+    static std::atomic<uint32_t> m_minPendingSubmissions;
+    static std::atomic<uint32_t> m_minChunkCount;
+    static std::atomic<uint32_t> m_maxChunkCount;
+
   private:
 
     GpuFlushType  m_maxType               = GpuFlushType::ImplicitWeakHint;
diff --git a/src/util/util_fps_limiter.cpp b/src/util/util_fps_limiter.cpp
index 621e9a4..4a126ac 100644
--- a/src/util/util_fps_limiter.cpp
+++ b/src/util/util_fps_limiter.cpp
@@ -5,6 +5,7 @@
 #include "util_fps_limiter.h"
 #include "util_sleep.h"
 #include "util_string.h"
+#include "../dxvk/framepacer/dxvk_framepacer.h"
 
 #include "./log/log.h"
 
@@ -48,7 +49,14 @@ namespace dxvk {
   }
 
 
-  void FpsLimiter::delay() {
+  void FpsLimiter::delay(const Rc<DxvkLatencyTracker>& tracker) {
+    FramePacer* framePacer = dynamic_cast<FramePacer*>(tracker.ptr());
+    if (framePacer && framePacer->getMode()) {
+      return;
+    }
+
+    m_isActive.store(false);
+
     std::unique_lock<dxvk::mutex> lock(m_mutex);
     auto interval = m_targetInterval;
     auto latency = m_maxLatency;
@@ -71,8 +79,11 @@ namespace dxvk {
     // that can be written by setTargetFrameRate
     lock.unlock();
 
-    if (t1 < m_nextFrame)
+    if (t1 < m_nextFrame) {
+      m_isActive.store(true);
+      m_lastActive.store(high_resolution_clock::now());
       Sleep::sleepUntil(t1, m_nextFrame);
+    }
 
     m_nextFrame = (t1 < m_nextFrame + interval)
       ? m_nextFrame + interval
diff --git a/src/util/util_fps_limiter.h b/src/util/util_fps_limiter.h
index 7c33a55..48e3736 100644
--- a/src/util/util_fps_limiter.h
+++ b/src/util/util_fps_limiter.h
@@ -7,6 +7,8 @@
 #include "util_time.h"
 
 namespace dxvk {
+
+  class DxvkLatencyTracker;
   
   /**
    * \brief Frame rate limiter
@@ -38,7 +40,7 @@ namespace dxvk {
      * and the time since the last call to \ref delay is
      * shorter than the target interval.
      */
-    void delay();
+    void delay(const Rc<DxvkLatencyTracker>& tracker);
 
     /**
      * \brief Queries environment override
@@ -46,6 +48,10 @@ namespace dxvk {
      */
     static std::optional<double> getEnvironmentOverride();
 
+    inline static std::atomic<bool> m_isActive = { false };
+    inline static std::atomic<high_resolution_clock::time_point>
+      m_lastActive = { high_resolution_clock::now() };
+
   private:
 
     using TimePoint = dxvk::high_resolution_clock::time_point;
